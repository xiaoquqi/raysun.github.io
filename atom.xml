<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>老孙正经胡说</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://sunqi.site/"/>
  <updated>2021-11-19T02:46:24.339Z</updated>
  <id>http://sunqi.site/</id>
  
  <author>
    <name>孙琦(Ray)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Windows系统迁移上云后如何激活？</title>
    <link href="http://sunqi.site/2021/11/19/Windows%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB%E4%B8%8A%E4%BA%91%E5%90%8E%E5%A6%82%E4%BD%95%E6%BF%80%E6%B4%BB%EF%BC%9F/"/>
    <id>http://sunqi.site/2021/11/19/Windows%E7%B3%BB%E7%BB%9F%E8%BF%81%E7%A7%BB%E4%B8%8A%E4%BA%91%E5%90%8E%E5%A6%82%E4%BD%95%E6%BF%80%E6%B4%BB%EF%BC%9F/</id>
    <published>2021-11-19T00:06:32.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>使用整机迁移方式(Re-Host)将Windows迁移至云平台后，由于底层的硬件发生改变，导致Windows序列号失效，需要重新进行激活。对于企业用户，如何保护既有投资，使用合理的方式对系统激活而不产生额外费用呢？本文基于项目中的最佳实践，为您详细进行解读。</p><a id="more"></a><h1 id="为什么迁移后授权失效？"><a href="#为什么迁移后授权失效？" class="headerlink" title="为什么迁移后授权失效？"></a>为什么迁移后授权失效？</h1><p>根据微软的解释：在安装Windows时，数字许可证本身与设备的硬件相关联。如果你对设备进行重大的硬件更改（例如更换母板），Windows将无法找到与设备匹配的许可证，因此你需要重新激活Windows才能使其正常运行。</p><p>根据云原生迁移工具HyperMotion的迁移原理，基于底层块级别技术进行复制，在系统拉起后，底层硬件变更为云平台的虚拟设备，导致硬件变更，造成了授权失效的情况发生。同时，由于云平台的机制，这种改变是必须的，所以并没有方法从虚拟化底层避免这一问题的发生。所以在公有云和私有云迁移或容灾时，就需要使用不同方法加以应对。</p><h1 id="公有云"><a href="#公有云" class="headerlink" title="公有云"></a>公有云</h1><p>根据目前的公开文档，绝大多数的公有云使用KMS方式对Windows采用自动化激活的方式。</p><p><img src="/images/pasted-280.png" alt="upload successful"></p><p>也可以在开机通过设定脚本的方式，实现自动化激活。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cscript &#x2F;nologo %windir%&#x2F;system32&#x2F;slmgr.vbs -skms kms.tencentyun.com:1688</span><br><span class="line">cscript &#x2F;nologo %windir%&#x2F;system32&#x2F;slmgr.vbs -ato</span><br></pre></td></tr></table></figure><p>华为云也是类似的方法，都是通过云内部的KMS实现批量激活。</p><p><img src="/images/pasted-281.png" alt="upload successful"></p><h2 id="保留原有授权"><a href="#保留原有授权" class="headerlink" title="保留原有授权"></a>保留原有授权</h2><p>这种方法目前只在AWS相关文档看到，这个方式叫做License Mobility，但是需要联系到原有授权的经销商才可以提交相关申请。</p><p><img src="/images/pasted-282.png" alt="upload successful"></p><h1 id="私有云"><a href="#私有云" class="headerlink" title="私有云"></a>私有云</h1><p>私有云的客户大多数为企业客户，一般都会购买过正版批量授权，对于授权的可激活次数是有一定宽松条件的。需要明确的一个先决条件，企业用户必须购买了正版的批量授权，零售版不在我们讨论范围内。</p><p>首先先要明确一个概念，授权和可激活次数是两个完全不同的概念，授权的数量是一定的，而激活次数是灵活的。也正是利用这一点，可以解决我们在业务系统迁移后，授权激活的问题。解决问题的思路如下：</p><ul><li>假如用户一共购买了10套Windows Server，那么在Windows批量授权中心，用户可激活的次数应该为50次</li><li>用户已经安装了10套Windows Server，并且已经激活，此时用户需要进行迁移</li><li>利用HyperMotion的热迁移能力，在保证业务连续性的前提下，将Windows从VMware环境以无代理方式迁移至了云平台上</li><li>用户希望利用HyperMotion的迁移验证功能，快速建立仿真环境，我们将10台Windows全部在云平台进行启动（原业务正常运行）</li><li>此时启动的Windows由于虚拟化底层发生改变，Windows都是未激活状态（Windows 2012如果在联网状况下，会自动尝试激活），但是并不影响业务系统验证</li><li>客户在验证后，确认业务可用，准备进行系统割接</li><li>经过最终的增量同步，原有业务系统关机，在正式的VPC内启动业务系统，并保持IP地址不变</li><li>业务系统割接后，Windows仍然属于未激活状态，我们在联网状态下，使用原有的序列号再次进行激活</li><li>完成业务系统迁移，同时Windows激活</li></ul><p>如果激活次数达到上限后，该如何处理呢？通过咨询微软400，对于企业用户的批量授权，激活次数是可以免费扩充的，只需要在该链接（<a href="https://support.microsoft.com/en-us/supportrequestform/2afa6f15-b710-db46-909a-8346017c802f?sl=en&amp;sc=US）" target="_blank" rel="noopener">https://support.microsoft.com/en-us/supportrequestform/2afa6f15-b710-db46-909a-8346017c802f?sl=en&amp;sc=US）</a> 提交申请，大概在5个工作日左右微软完成核实后，用户可以登陆自身的“微软的批量许可中心”查询可激活的次数，或者直接通过400电话咨询想过扩充方式。但是前提是您的激活次数达到上限才可以。</p><p><img src="/images/pasted-283.png" alt="upload successful"></p><p>整体的流程请见下图：</p><p><img src="/images/pasted-284.png" alt="upload successful"></p><h1 id="Windows不激活会自动重启吗？"><a href="#Windows不激活会自动重启吗？" class="headerlink" title="Windows不激活会自动重启吗？"></a>Windows不激活会自动重启吗？</h1><p>根据微软400电话反馈，由于正版保护的策略，Windows会出现一些随机事件，重启只是其中的一种，但并不是100%出现，目前肯定出现的问题是定期出现的是激活提醒。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul><li>公有云环境，推荐使用公有云自身提供的KMS服务</li><li>私有云环境，如果你购买了企业的批量授权，并不用担心授权激活问题，微软会帮你解决激活问题</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;使用整机迁移方式(Re-Host)将Windows迁移至云平台后，由于底层的硬件发生改变，导致Windows序列号失效，需要重新进行激活。对于企业用户，如何保护既有投资，使用合理的方式对系统激活而不产生额外费用呢？本文基于项目中的最佳实践，为您详细进行解读。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>如何在苹果日历订阅钉钉日历？</title>
    <link href="http://sunqi.site/2021/11/11/%E5%A6%82%E4%BD%95%E5%9C%A8%E8%8B%B9%E6%9E%9C%E6%97%A5%E5%8E%86%E8%AE%A2%E9%98%85%E9%92%89%E9%92%89%E6%97%A5%E5%8E%86%EF%BC%9F/"/>
    <id>http://sunqi.site/2021/11/11/%E5%A6%82%E4%BD%95%E5%9C%A8%E8%8B%B9%E6%9E%9C%E6%97%A5%E5%8E%86%E8%AE%A2%E9%98%85%E9%92%89%E9%92%89%E6%97%A5%E5%8E%86%EF%BC%9F/</id>
    <published>2021-11-11T02:03:10.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>通常我会使用苹果日历来管理我的所有行程，这样在不同苹果设备上就能实现互联互通，大多数的软件通过日历订阅或者CalDAV方式提供了对苹果日历的支持。很多公司开始使用钉钉作为自己的企业级IM工具，但是钉钉自带的日历却无法显示在苹果日历中，只能反向的由钉钉显示苹果日历的内容，非常不方便。今天无意间发现，钉钉的日历可以支持CalDAV方式了，所以赶紧在苹果的设备上进行了测试，终于可以实现苹果同步钉钉的日程了，以下就为大家分享一下。</p><a id="more"></a><h1 id="从钉钉获取CalDAV的配置"><a href="#从钉钉获取CalDAV的配置" class="headerlink" title="从钉钉获取CalDAV的配置"></a>从钉钉获取CalDAV的配置</h1><p>进入钉钉后，打开日历，进入设置。</p><p><img src="/images/pasted-272.png" alt="upload successful"></p><p>这里的用户名、密码和地址等信息需要复制到后面的苹果日历中。</p><p><img src="/images/pasted-273.png" alt="upload successful"></p><h1 id="在手机日历中添加CalDAV"><a href="#在手机日历中添加CalDAV" class="headerlink" title="在手机日历中添加CalDAV"></a>在手机日历中添加CalDAV</h1><p>进入手机设置，进入日历，添加账户。</p><p><img src="/images/pasted-274.png" alt="upload successful"></p><p>选择其他中，添加日历CalDAV账户。</p><p><img src="/images/pasted-275.png" alt="upload successful"></p><p>配置完成后，就应该能够从系统日历中看到钉钉的日历了。</p><h1 id="在Mac上添加CalDAV"><a href="#在Mac上添加CalDAV" class="headerlink" title="在Mac上添加CalDAV"></a>在Mac上添加CalDAV</h1><p>通过这种方式添加CalDAV无法在苹果设备之间进行同步，如果需要Mac侧也受到相关信息，还需要单独进行配置。</p><p>在Mac上打开日历，在日历菜单中，点击“账户”，进入后右侧划到最下面，点击“添加其他账户…”</p><p><img src="/images/pasted-278.png" alt="upload successful"></p><p>类似在手机上的流程，选择添加CalDAV，添加钉钉的鉴权信息，就完成了添加。</p><p><img src="/images/pasted-279.png" alt="upload successful"></p><p>这是在日历显示的样子，如果你在钉钉还订阅了其他日历，也会自动通过这种方式同步过来显示，非常方便。</p><p><img src="/images/pasted-277.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通常我会使用苹果日历来管理我的所有行程，这样在不同苹果设备上就能实现互联互通，大多数的软件通过日历订阅或者CalDAV方式提供了对苹果日历的支持。很多公司开始使用钉钉作为自己的企业级IM工具，但是钉钉自带的日历却无法显示在苹果日历中，只能反向的由钉钉显示苹果日历的内容，非常不方便。今天无意间发现，钉钉的日历可以支持CalDAV方式了，所以赶紧在苹果的设备上进行了测试，终于可以实现苹果同步钉钉的日程了，以下就为大家分享一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>如何清理/boot分区下的内容?</title>
    <link href="http://sunqi.site/2021/11/06/%E5%A6%82%E4%BD%95%E6%B8%85%E7%90%86-boot%E5%88%86%E5%8C%BA%E4%B8%8B%E7%9A%84%E5%86%85%E5%AE%B9/"/>
    <id>http://sunqi.site/2021/11/06/%E5%A6%82%E4%BD%95%E6%B8%85%E7%90%86-boot%E5%88%86%E5%8C%BA%E4%B8%8B%E7%9A%84%E5%86%85%E5%AE%B9/</id>
    <published>2021-11-06T08:26:51.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>CentOS运行时间长了，随着系统更新，/boot分区空间会越来越小，因为存留低版本内核相关文件没有得到及时清理，所以需要手动进行清理，但是由于内核文件重要性，如果清理方法不当就会导致系统无法启动。</p><a id="more"></a><h1 id="查询已经安装内核"><a href="#查询已经安装内核" class="headerlink" title="查询已经安装内核"></a>查询已经安装内核</h1><p>首先查询一下已经安装的内核信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -q kernel</span><br></pre></td></tr></table></figure><p>例如得到如下列表：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kernel-3.10.0-862.el7.x86_64</span><br><span class="line">kernel-3.10.0-1062.4.3.el7.x86_64</span><br><span class="line">kernel-3.10.0-1062.9.1.el7.x86_64</span><br></pre></td></tr></table></figure><h1 id="查询正在使用的内核"><a href="#查询正在使用的内核" class="headerlink" title="查询正在使用的内核"></a>查询正在使用的内核</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -a</span><br></pre></td></tr></table></figure><p>例如得到如下信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Linux compute201 3.10.0-1062.4.3.el7.x86_64 #1 SMP Wed Nov 13 23:58:53 UTC 2019 x86_64 x86_64 x86_64 GNU&#x2F;Linux</span><br></pre></td></tr></table></figure><h1 id="删除无用的内核"><a href="#删除无用的内核" class="headerlink" title="删除无用的内核"></a>删除无用的内核</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rpm -e kernel-3.10.0-862.el7.x86_64</span><br><span class="line">rpm -e kernel-3.10.0-1062.9.1.el7.x86_64</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CentOS运行时间长了，随着系统更新，/boot分区空间会越来越小，因为存留低版本内核相关文件没有得到及时清理，所以需要手动进行清理，但是由于内核文件重要性，如果清理方法不当就会导致系统无法启动。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>容灾渐进式云迁移</title>
    <link href="http://sunqi.site/2021/09/22/%E5%AE%B9%E7%81%BE%E6%B8%90%E8%BF%9B%E5%BC%8F%E4%BA%91%E8%BF%81%E7%A7%BB/"/>
    <id>http://sunqi.site/2021/09/22/%E5%AE%B9%E7%81%BE%E6%B8%90%E8%BF%9B%E5%BC%8F%E4%BA%91%E8%BF%81%E7%A7%BB/</id>
    <published>2021-09-22T04:08:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>2021年8月27日，天津“国资云”的一纸政令一下子成为整个云计算市场的热搜。同时，相同措辞的的政令，在各地国资委都已经出现。</p><p>上云迁移已经成为全社会各行业普遍的共识，“上不上云”已经无须讨论，“怎么上云”成为企业用户关注的重点。纵观整个云迁移市场，”上云方法论“几乎无异，但是在云平台建设初期，往往疏于云迁移成本的预算，等云平台建设完成后，才意识到问题的严重性。此时，只能从现有的资金中挤占出非常有限的预算进行云迁移，却又面临着用于上云资金投入与用户预期不符的情况。最终导致的结果就是，云平台资源的巨大浪费，平台长时间处于闲置状态。对于云平台厂商，在初期项目中往往“亏本赚吆喝”，一切指望后期项目中磨刀霍霍，由于始终无法用于生产，云平台规模也无法扩大，导致一期的投入血本无归。</p><p>云迁移是一个复杂的系统工程，并不是一个工具就解决的。要秉承一套科学的方法论，在用户、云平台和迁移方的三方协作下，才能顺利完成。目前在云迁移过程中，最大痛点来自于前期调研阶段，这是后续过程的基础，但是在实践中又面临诸多阻力，例如：用户不配合、系统陈旧、业务系统无人运维方等诸多问题，导致无法开展后续流程。本文主要介绍基于容灾演练的理念，利用渐进式云迁移的思路和方法，将一部分调研工作后置，解决在上云前调研中的难点，通过构建”仿真“环境，在实践中完成调研中最困难的部分，加速云迁移的过程。</p><a id="more"></a><h1 id="云迁移之调研痛点分析"><a href="#云迁移之调研痛点分析" class="headerlink" title="云迁移之调研痛点分析"></a>云迁移之调研痛点分析</h1><p>调研是云迁移实施前非常重要的一个环节，调研也决定了后续整个项目落地的进度和最终的效果。调研基本分为两个部分：</p><h2 id="技术调研"><a href="#技术调研" class="headerlink" title="技术调研"></a>技术调研</h2><p>技术调研核心目的是通过对源端主机和综合环境信息进行采集，找出适当的迁移方法，也就是AWS倡导的”6R”迁移策略。技术调研部分最重要的一个环节就是以单台主机为单位，通过收集计算、存储、网络等基础资源，合理对上云后的架构进行规划，以便来判断使用何种工具进行迁移。技术调研非常重要，因为这是决定是否可以迁移以及成本非常重要的一环。</p><h2 id="业务调研"><a href="#业务调研" class="headerlink" title="业务调研"></a>业务调研</h2><p>业务调研是以用户为主导，以技术调研的基础，对业务系统归属、关联性等进行分析，明确业务系统运维负责人和使用方，对于上云后发生的变更，还要明确变更的内容及执行人等信息。业务系统调研本身并不涉及过多技术内容，更多的是以现有的业务系统统计信息为基础，就可以很快得出结论，但是在实际的项目执行过程中，这部分往往是阻力最大的部分。</p><h2 id="痛点分析"><a href="#痛点分析" class="headerlink" title="痛点分析"></a>痛点分析</h2><p>首先，责任归属问题。负责云平台建设和迁移的部门往往是底层基础支撑部门，例如：在传统的政企中的信息部、系统部等，而受影响的部门却是业务部门。而由于迁移过程中触发的上层业务系统变更，无疑给这些业务部门增加了额外工作。所以在实际走访调研过程中，不配合基本是常态，问题超过三个，就会出现了不耐烦、推三阻四或顾左右而言他的情况。稍微配合一点的，就是登陆系统后告诉你，双手一摊，”你自己看吧“。上云是一个自顶向下的过程，用户领导层的决心和执行力是项目成败的关键。</p><p>第二，数据安全。由于不清楚云迁移的风险，用户过分担心迁移过程后的数据安全性和业务连续性，要求迁移前进行大量前期的方案整理和调研工作。前期”空想“的内容太多，最终导致项目迟迟无法启动。</p><p>第三，业务无运维。用户的业务系统并不是一天建成的，这其中的跨度可能历经数十年的时间。从实际项目情况看，能够将自己业务系统梳理清晰的客户并不是很多，更别说是上云后要变更哪些内容，甚至一些陈旧的业务系统，连原厂商都找不到，而且这样的情况还不在少数（背后的原因大家可以自行脑补）。这也间接导致了第一点问题，没有人敢为此承担责任。在实际项目中，经常有些业务系统没有人敢重启，因为谁也不知道系统重启后业务还能不能用，因此没人愿意承担由此产生的后果。</p><p>第四，调研对人员专业性要求高。通常认为调研的难度往往与咨询划等号，天然认为调研人员往往需要具备较高的技术宽度，见多识广，接触过不同类型的业务系统架构，这样的门槛往往让许多传统集成商在转型云MSP时望而却步，根本不知道该从哪里开始。在实际项目中，调研工作往往依靠Excel统计，事实证明，填表人的想象力和创造力超乎你的想象，填回来的信息五花八门。如果靠人力去完成，用户的资金投入根本无法覆盖调研过程的成本，而且耗时耗力、周期长，很难避免错误的产生。</p><h1 id="用容灾思路解决上云迁移痛点"><a href="#用容灾思路解决上云迁移痛点" class="headerlink" title="用容灾思路解决上云迁移痛点"></a>用容灾思路解决上云迁移痛点</h1><p>与传统物理环境下的迁移不同，云的“软件定义一切”的特性，决定了云资源的可编排性和最终一致性。在之前《云原生趋势下的迁移与容灾思考》我曾经提到过，云计算平台解决了云上资源的可编排性，而云迁移与云容灾则是将云的编排性和数据结合在一起，形成了云上数据的管理平台。正因为如此，云间数据流转成为常态化需求，业务系统在不同云间运行成为可能，同时也进一步模糊了云上迁移与容灾的边界。</p><p>针对上述出现的痛点，我们在项目实践中通过容灾渐进式云迁移方式构建”仿真“环境，将一部分前期调研工作后置，通过容灾演练来解决前期调研中需要业务人员“空想”和“烦躁”的局面。使用技术调研标准化和工具化来保证调研结果的准确性，让迁移项目能够快速和顺利的推进。</p><h2 id="容灾渐进式迁移"><a href="#容灾渐进式迁移" class="headerlink" title="容灾渐进式迁移"></a>容灾渐进式迁移</h2><p>前面提到，业务调研中最大的阻力其实来自于”人“，技术手段解决不了”人“的问题，但是可以将工作难度降低，间接清除阻力。所以在最佳实践中，我们决定将部分调研工作后置，具体的做法如下：</p><p>业务调研阶段，需要明确业务系统组成范围，即哪些主机构成了一个完整的业务系统，因为这决定了迁移的顺序和方案的规划，这个环节还是必不可少的，而且基本上对于用户没有太大的难度。接下来，需要明确业务运维负责人（业务变更）和业务负责人（业务验证），对于没有业务运维负责人的老旧系统，可以考虑不迁移或者淘汰，如果用户执意迁移，则要明确运维边界（通常涉及商务问题）。而对于业务关联性、系统变更等复杂的业务问题，则后置在迁移验证阶段完成，在仿真环境完成。</p><p>目前，国内大部分政企客户的迁移中，主机级别迁移占绝大多数，基本上都会采用块级别整机迁移的方案来保持迁移的一致性。上面提到，云的可编排性让我们可以利用容灾演练的方式在云端重复仿真一个真实的”生产“环境，解决业务调研中，”受制于人“的部分。让业务运维人员和使用方都有充足的时间对系统的变更及稳定性做出验证，一方面杜绝了在调研前期的空想，另外一方面也能够将责任划分清晰。要实现这样的目标，在选择迁移工具时，要具备以下特征：</p><p>首先，迁移工具自身与云平台要进行过充分的对接，不能只是简单的对接一两个启动主机的接口，要充分利用云平台的卷快照、主机启动时的存储类型、网络等接口特性，例如：租户级别的卷转移、密码、密钥管理、指定IP、卷启动等特性，即实现利用数据副本还原生产环境的效果。这样原有增量同步仍然能够继续，保证后续割接顺利进行。当业务系统达到一定数量时，没有高度自动化的云上数据编排能力，是无法完成仿真环境的创建的，手动创建的工作量超出你的想象，而且极其容易造成错误，只有高度自动化的能力才能保证仿真环境构建的准确性和一致性。</p><p>第二，充分利用云上虚拟网络隔离的特性，构建近似真实的仿真环境，而不影响正常的业务系统运行。最好的方式，就是通过构建与真实环境相同的网络地址段（与原有网络隔离，避免造成数据污染），将业务系统按照原有IP地址恢复至该网段内，这样仿真环境就真正的建立好了。迁移工具在演练阶段要保证每台主机数据的完整性、系统的正常运行，而此后就可以让业务系统的运维方在仿真环境中进行业务变更验证，并将步骤记录，而业务系统负责人在仿真环境从业务维度进一步验证。解决之前空想状态下的调研工作，也让业务方能够安心进行验证后迁移。</p><p>最后，实现最终的迁移实施报告，在规定的时间窗口内，完成最终的业务割接上云。</p><h2 id="技术调研标准化与工具化"><a href="#技术调研标准化与工具化" class="headerlink" title="技术调研标准化与工具化"></a>技术调研标准化与工具化</h2><p>技术调研是调研工作中技术要求最强的部分，也是最重要的部分，这部分并不是依靠经验，而是通过标准化的技术方案，形成流程的标准化。</p><p>在最早从事一家银行云迁移项目中，我们主要采用人工统计方式进行调研。使用Excel模板形式，发送给业务方进行填写，但是随着调研的推进，无论我们的模板做了多少种样例，填写回来的数据总是千奇百怪，有一半的数据是不可用的。后来我们成立专门的调研专家组，由我方（一人）和用户业务专家（两人）共同组建，由我方技术人员负责技术部分调研，由业务专家组负责调研关联性、停机窗口、迁移后变更信息等与用户业务相关的部分。在这种情况下，调研20套业务系统（主机数量在50台以上），大约在三天左右时间。虽然这样能有效提高调研结果的准确性，但是仍然有技术调研结果不准确，导致在迁移过程中临时变更方案的情况出现。</p><p>通过项目磨炼，我们经过对调研过程的总结，形成了标准化的技术调研方案，进而将该方案形成研发需求，开发出调研及分析工具。调研工具的原理非常简单，主要分为三个主要功能：</p><p>功能一，通过网络扫描所有存活的主机，通过对nmap的封装，能够对用户局域网内存活的所有主机进行针对性扫描，同时扫描出开放的端口等信息。该步骤作为详细采集前的准备数据。</p><p>功能二，基于第一步扫描的结果，由用户业务方提供主机和密码等信息，如果是VMWare，则只需要提供vCenter或ESXi的用户名和密码，程序执行后将自动获取必要的主机详细信息，为进一步分析提供依据。</p><p>功能三，基于功能二的详细输出，根据迁移工具的特点进行详细分析，最终得出准确的技术调研报告，其中包含迁移方法及预估的数据同步时间。</p><p>通过以上方式，在技术调研部分我们逐步形成了标准化和工具化，而上述调研工具我们也将逐步开源(github.com/hostminer)。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>相较于传统环境，云上环境更能模拟出”仿真“环境，而云的可编排性又为数据统一的管理提供了保障，充分利用云原生接口及资源的特性，能够让我们通过技术手段间接的解决业务上的问题，从而加速项目的推进和实施工作。以上就是我们在实践中总结出对迁移中业务调研难点的解决方案，这种方式特别适合于加速传统的政企客户上云，解决用户的后顾之忧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2021年8月27日，天津“国资云”的一纸政令一下子成为整个云计算市场的热搜。同时，相同措辞的的政令，在各地国资委都已经出现。&lt;/p&gt;
&lt;p&gt;上云迁移已经成为全社会各行业普遍的共识，“上不上云”已经无须讨论，“怎么上云”成为企业用户关注的重点。纵观整个云迁移市场，”上云方法论“几乎无异，但是在云平台建设初期，往往疏于云迁移成本的预算，等云平台建设完成后，才意识到问题的严重性。此时，只能从现有的资金中挤占出非常有限的预算进行云迁移，却又面临着用于上云资金投入与用户预期不符的情况。最终导致的结果就是，云平台资源的巨大浪费，平台长时间处于闲置状态。对于云平台厂商，在初期项目中往往“亏本赚吆喝”，一切指望后期项目中磨刀霍霍，由于始终无法用于生产，云平台规模也无法扩大，导致一期的投入血本无归。&lt;/p&gt;
&lt;p&gt;云迁移是一个复杂的系统工程，并不是一个工具就解决的。要秉承一套科学的方法论，在用户、云平台和迁移方的三方协作下，才能顺利完成。目前在云迁移过程中，最大痛点来自于前期调研阶段，这是后续过程的基础，但是在实践中又面临诸多阻力，例如：用户不配合、系统陈旧、业务系统无人运维方等诸多问题，导致无法开展后续流程。本文主要介绍基于容灾演练的理念，利用渐进式云迁移的思路和方法，将一部分调研工作后置，解决在上云前调研中的难点，通过构建”仿真“环境，在实践中完成调研中最困难的部分，加速云迁移的过程。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>关闭Ceph exclusive-lock功能</title>
    <link href="http://sunqi.site/2021/08/02/%E5%85%B3%E9%97%ADCeph-exclusive-lock%E5%8A%9F%E8%83%BD/"/>
    <id>http://sunqi.site/2021/08/02/%E5%85%B3%E9%97%ADCeph-exclusive-lock%E5%8A%9F%E8%83%BD/</id>
    <published>2021-08-02T15:18:47.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>当OpenStack计算和存储一体节点强制重启后，会导致虚拟机无法启动，卡在I/O error上，究其原因是由于底层rbd设备的exclusive-lock造成的。有两种解决方案，一种是临时性的解除exclusive-lock client，一种则是关闭rbd的exclusive-lock。</p><a id="more"></a><h1 id="解除exclusive-lock-client"><a href="#解除exclusive-lock-client" class="headerlink" title="解除exclusive-lock client"></a>解除exclusive-lock client</h1><p>查看exclusive-lock client(pool的名字为volumes)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@compute201 ~]# rbd lock ls volumes&#x2F;volume-cad6425c-4453-4489-b2d1-45050b062bd2</span><br><span class="line">There is 1 exclusive lock on this image.</span><br><span class="line">Locker           ID                   Address</span><br><span class="line">client.14440803  auto 93942189655296  10.0.100.202:0&#x2F;1431194814</span><br></pre></td></tr></table></figure><p>尝试删除client</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd lock remove volumes&#x2F;volume-cad6425c-4453-4489-b2d1-45050b062bd2 &quot;auto 93942189655296&quot; client.14440803</span><br></pre></td></tr></table></figure><p>最后尝试重启相应的虚拟机，此时应该可以正常进入系统。</p><h1 id="关闭exclusive-lock功能"><a href="#关闭exclusive-lock功能" class="headerlink" title="关闭exclusive-lock功能"></a>关闭exclusive-lock功能</h1><p>通过查看rbd info，获取当前卷是否开启了exclusive-lock</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@compute201 ~]# rbd info volumes&#x2F;volume-cad6425c-4453-4489-b2d1-45050b062bd2</span><br><span class="line">rbd image &#39;volume-cad6425c-4453-4489-b2d1-45050b062bd2&#39;:</span><br><span class="line">size 50 GiB in 12800 objects</span><br><span class="line">order 22 (4 MiB objects)</span><br><span class="line">snapshot_count: 0</span><br><span class="line">id: dc59383d97f124</span><br><span class="line">block_name_prefix: rbd_data.dc59383d97f124</span><br><span class="line">format: 2</span><br><span class="line">features: layering, exclusive-lock, object-map, fast-diff, deep-flatten</span><br><span class="line">op_features:</span><br><span class="line">flags:</span><br><span class="line">create_timestamp: Fri Jun 18 16:28:44 2021</span><br><span class="line">access_timestamp: Mon Jun 21 15:17:38 2021</span><br><span class="line">modify_timestamp: Mon Aug  2 23:07:58 2021</span><br><span class="line">parent: images&#x2F;9e8a401b-d407-4946-b94c-f24b94ce0f02@snap</span><br><span class="line">overlap: 8 GiB</span><br></pre></td></tr></table></figure><p>关闭exclusive-lock功能，这里必须要和object-map或journaling一起关闭才能生效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rbd feature disable volumes&#x2F;volume-cad6425c-4453-4489-b2d1-45050b062bd2 exclusive-lock,object-map</span><br></pre></td></tr></table></figure><p>再次查看功能列表，features只剩下layering和deep-flattern</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@compute201 ~]# rbd info volumes&#x2F;volume-cad6425c-4453-4489-b2d1-45050b062bd2</span><br><span class="line">rbd image &#39;volume-cad6425c-4453-4489-b2d1-45050b062bd2&#39;:</span><br><span class="line">size 50 GiB in 12800 objects</span><br><span class="line">order 22 (4 MiB objects)</span><br><span class="line">snapshot_count: 0</span><br><span class="line">id: dc59383d97f124</span><br><span class="line">block_name_prefix: rbd_data.dc59383d97f124</span><br><span class="line">format: 2</span><br><span class="line">features: layering, deep-flatten</span><br><span class="line">op_features:</span><br><span class="line">flags:</span><br><span class="line">create_timestamp: Fri Jun 18 16:28:44 2021</span><br><span class="line">access_timestamp: Mon Jun 21 15:17:38 2021</span><br><span class="line">modify_timestamp: Mon Aug  2 23:35:33 2021</span><br><span class="line">parent: images&#x2F;9e8a401b-d407-4946-b94c-f24b94ce0f02@snap</span><br><span class="line">overlap: 8 GiB</span><br></pre></td></tr></table></figure><p>批量关闭所有卷的exclusive-lock</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(rbd ls -p volumes); do rbd feature disable volumes&#x2F;$i exclusive-lock,object-map; done</span><br></pre></td></tr></table></figure><h1 id="关闭新创建卷的exclusive-lock功能"><a href="#关闭新创建卷的exclusive-lock功能" class="headerlink" title="关闭新创建卷的exclusive-lock功能"></a>关闭新创建卷的exclusive-lock功能</h1><p>如果是用Ceph Deploy进行的部署，则需要将配置文件分发到各个节点，在ceph.conf中增加rbd_default_features，写明你创建的卷需要哪几种属性。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[global]</span><br><span class="line">fsid &#x3D; 74fcb885-c0f9-4c31-a8fe-89a7f0122434</span><br><span class="line">public_network &#x3D; 10.0.100.0&#x2F;24</span><br><span class="line">mon_initial_members &#x3D; compute201</span><br><span class="line">mon_host &#x3D; 10.0.100.201</span><br><span class="line">auth_cluster_required &#x3D; cephx</span><br><span class="line">auth_service_required &#x3D; cephx</span><br><span class="line">auth_client_required &#x3D; cephx</span><br><span class="line">rbd_default_features &#x3D; &quot;layering, deep-flatten&quot;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ceph-deploy --overwrite-conf config  push compute201 compute202 compute203</span><br></pre></td></tr></table></figure><p>此时再使用rbd create创建的卷默认就是这两种属性了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@compute201 ~]# rbd create -p volumes test --size 10G</span><br><span class="line">[root@compute201 ~]# rbd info volumes&#x2F;test</span><br><span class="line">rbd image &#39;test&#39;:</span><br><span class="line">size 10 GiB in 2560 objects</span><br><span class="line">order 22 (4 MiB objects)</span><br><span class="line">snapshot_count: 0</span><br><span class="line">id: 16ef5c2dacd2da</span><br><span class="line">block_name_prefix: rbd_data.16ef5c2dacd2da</span><br><span class="line">format: 2</span><br><span class="line">features: layering, deep-flatten</span><br><span class="line">op_features:</span><br><span class="line">flags:</span><br><span class="line">create_timestamp: Mon Aug  2 23:57:23 2021</span><br><span class="line">access_timestamp: Mon Aug  2 23:57:23 2021</span><br><span class="line">modify_timestamp: Mon Aug  2 23:57:23 2021</span><br></pre></td></tr></table></figure><p>最后还需要对OpenStack各个模块的ceph进行更新，如果使用kolla更新，则替换所有配置文件，并重启容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cp &#x2F;etc&#x2F;ceph&#x2F;ceph.conf &#x2F;etc&#x2F;kolla&#x2F;config&#x2F;nova&#x2F;ceph.conf</span><br><span class="line">cp &#x2F;etc&#x2F;ceph&#x2F;ceph.conf &#x2F;etc&#x2F;kolla&#x2F;config&#x2F;cinder&#x2F;ceph.conf</span><br><span class="line"></span><br><span class="line">kolla-ansible -i multinode reconfigure</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当OpenStack计算和存储一体节点强制重启后，会导致虚拟机无法启动，卡在I/O error上，究其原因是由于底层rbd设备的exclusive-lock造成的。有两种解决方案，一种是临时性的解除exclusive-lock client，一种则是关闭rbd的exclusive-lock。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>利用Tushare对一夜持股法进行回归验证</title>
    <link href="http://sunqi.site/2021/07/01/%E5%88%A9%E7%94%A8Tushare%E5%AF%B9%E6%8A%96%E9%9F%B3%E8%82%A1%E7%A5%A8%E6%8A%95%E8%B5%84%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%9B%9E%E5%BD%92%E9%AA%8C%E8%AF%81/"/>
    <id>http://sunqi.site/2021/07/01/%E5%88%A9%E7%94%A8Tushare%E5%AF%B9%E6%8A%96%E9%9F%B3%E8%82%A1%E7%A5%A8%E6%8A%95%E8%B5%84%E6%96%B9%E6%B3%95%E8%BF%9B%E8%A1%8C%E5%9B%9E%E5%BD%92%E9%AA%8C%E8%AF%81/</id>
    <published>2021-07-01T10:23:09.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>最近在抖音看到很多金融博主在推荐一些投资股票的心得，可以说是五花八门，再看评论区，更是千奇百怪，大部分人都在说没用，但又拿不出什么证据来。事实是检验真理的唯一标准，我觉得对于此类投资观点，最好的方式进行用历史数据去验证，因为历史总是重复的，如果是对的，那么对于未来的投资也算是找到了一条生财之道。</p><a id="more"></a><h1 id="关于一夜持股法"><a href="#关于一夜持股法" class="headerlink" title="关于一夜持股法"></a>关于一夜持股法</h1><p>简单来说，一夜持股法是利用两天之间的追涨来获取收益，即第一天尾盘买入股票，第二天趁着涨势再卖掉，降低盘中震荡对于价格的冲击，如此反复操作，获取收益。</p><p>在原文视频中，作者给出了这种操作的八个条件：</p><ul><li>在收盘前，即下午2点半左右看盘</li><li>在当天的股票中，利用软件筛选出涨幅在3%-5%的股票</li><li>再根据量比排名，找出大于1的股票</li><li>再根据换手率排名，选出换手率在5%-10%的股票，换手率太高可能有庄家出货嫌疑，换手率太低第二天缺乏上攻的动力</li><li>再根据流通盘排名，筛选出50亿-200亿之间的股票，股票流通盘太大，拉动需要大量资金</li><li>查看K线图，删除成交量忽高忽低的，只留下成交量持续放大的股票</li><li>观察K线形态，如果在重要均线下方，或者近期冲高回落有套牢盘的全部删掉，只留下K线上方没有任何压力的，第二天冲高概率才大</li><li>观察当天分时图，股价全天必须在分时图均线价格上方，那么意味着所有人都吃到了涨幅，第二天冲高有动力；股票价格必须要强于当天的大盘分时图，选择逆势而上的强势股</li><li>均线在下午2点半左右，创出新高，股价回落均线</li></ul><h1 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h1><p>看到以上八个苛刻的条件，可能大部分还没找到股票，当天交易估计就结束了，别说交易了。说实话我刚看到这个视频时候，也是将信将疑，所以决定用程序对过去一年的历史数据进行校验。如果有效，再通过程序实现一个自动化交易的算法，完成自动化交易。</p><h2 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h2><p>首先我们来分析一下我们需要哪些数据源：</p><ul><li>股票列表，包括涨幅、量比、换手率、流通盘</li><li>股票K线数据，包括重要的均线</li><li>股票分时图</li></ul><h2 id="回归验证"><a href="#回归验证" class="headerlink" title="回归验证"></a>回归验证</h2><p>我们主要针对2020年1月到2020年12月的数据，以及2021年上半年的数据进行回归交易，回归验证的流程为：</p><ul><li>我们假设有10万本金进行上述交易</li><li>我们先根据上述条件进行股票过滤，如果当天能够筛选出股票，将资金平均分为3份，购买股票</li><li>卖出策略有很多种，我们先采取最简单的策略进行回归，我们假定在第二天上午10点30分将股票全部卖出</li><li>运行程序进行模拟，并计算总收益</li></ul><h2 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h2><p>我们需要大量的历史交易数据，通过对网上资料的搜索，我发现tushare是目前提供最全的金融SDK，不仅仅是股票，还包括其他很多金融产品。tushare分为两个版本，一个为普通版本，一个为专业版本。普通版本虽然功能还能使用，但是逐步在废弃。专业版本是依靠积分机制来获取不同接口权限的，可以通过对社区贡献或者直接捐钱获取积分，不过这也不难理解，毕竟一个社区的良性发展需要资金支持。</p><p>Tushare旧版本的文档在这里：<a href="http://tushare.org/fundamental.html" target="_blank" rel="noopener">http://tushare.org/fundamental.html</a><br>全新版本的文档在：<a href="https://waditu.com/document/1" target="_blank" rel="noopener">https://waditu.com/document/1</a></p><p>旧版本有很多接口已经废弃了，使用的时候会有提示。而新版本则需要先申请token，再进行使用，根据你的积分不同，你调用的接口和频度是不同的。同时tushare返回的格式直接就是pandas的DateFrame类型，可以直接进行排序或者过滤等数据操作，非常方便。目前对于一夜持股法的验证还在继续中，也欢迎有兴趣的同学参与。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近在抖音看到很多金融博主在推荐一些投资股票的心得，可以说是五花八门，再看评论区，更是千奇百怪，大部分人都在说没用，但又拿不出什么证据来。事实是检验真理的唯一标准，我觉得对于此类投资观点，最好的方式进行用历史数据去验证，因为历史总是重复的，如果是对的，那么对于未来的投资也算是找到了一条生财之道。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>从阿里云峰会看Serverless现状与发展趋势</title>
    <link href="http://sunqi.site/2021/05/30/%E9%98%BF%E9%87%8C%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
    <id>http://sunqi.site/2021/05/30/%E9%98%BF%E9%87%8C%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-05-30T23:48:00.000Z</published>
    <updated>2021-11-19T02:46:24.343Z</updated>
    
    <content type="html"><![CDATA[<p>2021年5月28日至29日两天，阿里云开发者峰会在国家会议中心盛大举行，会议上阿里云在端侧、边侧、云侧，为开发者提供了自由的发挥空间，让阿里云“被集成”的理念再一次深入人心。</p><a id="more"></a><p><img src="/images/pasted-261.png" alt="upload successful"></p><p>本次峰会中，我最为关注的部分是云原生部分，在经历了纯IaaS层作为底座的云计算1.0时代后，以云原生服务为底座的2.0时代，会逐步成为系统构建的核心。在云原生领域中，无服务化Serverless又是云计算的发展的未来。阿里云的函数计算是我最早的接触的无服务架构的重要服务。在《Serverless发展历史》一文中我也曾经提到过，阿里云早在2016年就发布了自己的函数计算服务，仅比AWS Lambda仅仅晚了两年的时间。</p><p>作为Serverless的使用者，我更多的是从开发者角度来研究无服务化的可用性，而每家云厂商对于Serverless方向往往有全局性和整体的规划，其中就有很多我们看不到的内容。本篇Blog也从多个维度来聊一聊关于开发者眼中的阿里云Serverless。</p><h1 id="阿里云Serverless概述"><a href="#阿里云Serverless概述" class="headerlink" title="阿里云Serverless概述"></a>阿里云Serverless概述</h1><p>阿里云Serverless的官方链接是：serverless.aliyun.com，网站中的内容主要是对阿里云函数计算、Serverless平台以及应用场景进行了介绍，最后是完整的入门手册全面介绍函数计算。</p><p>从阿里云Serverless我们能了解到围绕在函数计算服务的生态服务。其中对象存储、API网关比较常见。日志服务便于函数计算服务的调试和跟踪。至于批量计算和函数计算的关系，我理解是批量计算调用函数计算，按量计费的方式，但是在控制台上并没有非常明显的入口或者提示。</p><p><img src="/images/pasted-209.png" alt="upload successful"></p><p>另外，按照阿里云提供的Serverless能力来说，还应该包含Serverless容器服务ASK，Serverless应用引擎SAE以及用于函数计算编排的工作流服务等。在阿里云的服务目录可以搜索到这些服务，但是在Serverless首页上并没有过多的去宣传这些服务和应用场景。</p><h1 id="函数服务"><a href="#函数服务" class="headerlink" title="函数服务"></a>函数服务</h1><p>从2020年到2021年，阿里云函数服务还是发生了很大的变化，例如在触发器上增加了至少五种类型。触发器的种类决定了函数计算应用场景的丰富程度。这是2020年初的触发器截图：</p><p><img src="/images/pasted-211.png" alt="upload successful"></p><p>这是2021年的触发器截图，通过对比，可以很明显看到函数服务在一年时间里，增加了五种触发器类型（API网关、loT、云监控、消息队列Kafaka和事件总线触发器）。触发器的增多，</p><p><img src="/images/pasted-213.png" alt="upload successful"></p><p>以云监控触发器为例，比如你的ECS由人为引起了重启，你可以触发你的函数计算去处理自动化运维操作。通过云监控中的事件进行触发配置，不过这里不太方便的一点，新的几个触发器配置起来都不太方便，都需要通过查询文档才能知道跳转到哪个平台进行关联性配置，用户体验方面有待提升。通过这种手段，函数计算的可观测性得到了提高。</p><p><img src="/images/pasted-221.png" alt="upload successful"></p><p>在我们实际的生产环境中，阿里云函数计算已经稳定运行了一年多的时间，通过对函数计算的使用，节约了线上系统的成本，研发人员在开发和维护时也更加方便。至少有三种业务场景使用到了函数计算：</p><ul><li>提供二维码申请迁移产品License页面，用户提交申请后自动将请求转发至钉钉流程中</li><li>迁移SaaS产品中，自动进行License审批，通过函数计算服务提供了REST API服务</li><li>通过函数计算作为路由转发层，对外向第三方系统提供REST API接口，作为接受请求的服务端，之后再将请求转发至多个系统中</li></ul><p><img src="/images/pasted-207.png" alt="upload successful"></p><h1 id="轻量级Serverless应用构建——Serverless-Devs"><a href="#轻量级Serverless应用构建——Serverless-Devs" class="headerlink" title="轻量级Serverless应用构建——Serverless Devs"></a>轻量级Serverless应用构建——Serverless Devs</h1><p>函数计算除了在最佳实践中成为连接云原生服务组件之间最后一公里的服务，在单独构建轻应用上也具备非常大的优势，特别是面向业务属性很强的应用时。这是阿里云官方给出的一张Serverless IT架构模式，这里重点突出了以函数计算为轴心的无服务化轻应用构建的基本框架。</p><p><img src="/images/pasted-208.png" alt="upload successful"></p><p>但是在构建此类应用过程中，开发者往往遇到诸多问题，例如：管理困难，调试困难、关联服务多、部署繁琐等诸多问题。同时在混合云上，由于每个云厂商提供了各自不同的工具，很难使用一套工具来管理不同云上的Serverless应用。在本次峰会上，我也非常欣喜的看到，阿里云提供了一套全新的Serverless开发者工具平台——Serverless Devs，解决了上述提到的开发痛点。目前Serverless Devs工具支持编排阿里云函数计算、Serverless工作流、NAS服务、资源编排、权限管理、VPC、日志服务，基本可以满足日常开发需求。</p><p><img src="/images/pasted-262.png" alt="upload successful"></p><p>从上图我们看到，Serverless Devs目前已经支持了主流的五大公有云。同时提供了大量的不同语言的框架模板，加速应用开发。Serverless Devs目前的官网地址是<a href="http://www.serverless-devs.com，有大量的学习资料供开发者使用。" target="_blank" rel="noopener">www.serverless-devs.com，有大量的学习资料供开发者使用。</a></p><p><img src="/images/pasted-263.png" alt="upload successful"></p><p>目前该项目在Github上获得了582星，还处于起步阶段，所以有兴趣的开发者也可以参与到项目贡献中。</p><h1 id="OAM-KubeVela"><a href="#OAM-KubeVela" class="headerlink" title="OAM/KubeVela"></a>OAM/KubeVela</h1><p>虽然以函数服务为核心的轻应用能够满足很多业务场景，但是对于复杂的应用架构支持上还存在天然的不足。谈到这一点不得先说一说OAM(Open Application Model)，一个用于描述应用程序与其实现解耦的规范。简单来说，OAM就是让Dev和Ops职责变得更为清晰。</p><p><img src="/images/pasted-264.png" alt="upload successful"></p><p>当然OAM作为一种规范，并不是强制使用Kubernetes，但是目前几大公有云厂商推出的基于OAM的实现基本都是基于K8S。KubeVela就是基于这一规范，由阿里巴巴和微软共同开源的项目。</p><p><img src="/images/pasted-267.png" alt="upload successful"></p><p>对于应用开发人员来讲，KubeVela是一个非常低心智负担的云原生应用管理平台，核心功能是让开发人员方便快捷地在 Kubernetes 上定义与交付现代微服务应用，无需了解任何Kubernetes本身相关的细节。</p><p><img src="/images/pasted-265.png" alt="upload successful"></p><p>通过对底层基础架构层的进一步抽象，基于容器环境的系统可以在多云之间自由移动，降低厂商锁定的风险。</p><p><img src="/images/pasted-266.png" alt="upload successful"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>作为云计算未来发展方向的Serverless已经成为各大云厂商的必争之地，从本次峰会上看，阿里云在这方面也是全力投入。通过底层技术不断迭代，为阿里的云钉一体化发展战略提供了强大的技术保障，也让云边协同的能力得以发挥。</p><p>对于普通开发者来说，云计算的趋势已经不可逆转，而云原生已经成为未来工作必须掌握的技能之一，也是缓解“35岁危机”最有效的自我升级的方式。</p><p><img src="/images/pasted-268.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;2021年5月28日至29日两天，阿里云开发者峰会在国家会议中心盛大举行，会议上阿里云在端侧、边侧、云侧，为开发者提供了自由的发挥空间，让阿里云“被集成”的理念再一次深入人心。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>利用阿里云Serverless Kubernetes构建任务运行环境</title>
    <link href="http://sunqi.site/2021/05/26/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91Serverless-Kubernetes%E6%9E%84%E5%BB%BA%E7%8E%AF%E5%A2%83/"/>
    <id>http://sunqi.site/2021/05/26/%E5%A6%82%E4%BD%95%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91Serverless-Kubernetes%E6%9E%84%E5%BB%BA%E7%8E%AF%E5%A2%83/</id>
    <published>2021-05-26T22:18:51.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>Kubernetes是容器编排首选平台，现在各大云商也都推出了自己的Kubernetes服务。但是搭建Kubernetes环境往往在初始节点上需要很多云主机支持，三个Master节点实现HA，三个Node作为计算节点，成本开销比较大。后来阿里云推出了部分托管版本的Kubernetes，即Master节点托管给阿里云，用户只需要根据需求创建Node节点，大大节省了开销。但是如果用户连Node节点都不想创建，希望做到真正的按需分配怎么办呢？那么，你可以使用阿里云基于容器平台ECI构建的全托管版本的Kubernetes，即Kubernetes Serverless版本。这种环境下，用户可以完全忽略Master和Node节点，你的所有服务都会自动运行在ECI容器实例中，而费用则根据你的容器实际运行的时间和存储占用收取。这种方式适合有限时间内的任务运行方式，大大节约计算资源费用支出。</p><a id="more"></a><h1 id="服务创建"><a href="#服务创建" class="headerlink" title="服务创建"></a>服务创建</h1><p>在服务目录找到Serverless容器服务ASK，进入后创建集群。</p><p><img src="/images/pasted-245.png" alt="upload successful"></p><p>顶部选择创建ASK集群，这种才是不需要创建master和node节点的模式。</p><p><img src="/images/pasted-246.png" alt="upload successful"></p><p>根据提示选择地域、版本和网络等信息。目前Kubernetes版本支持1.20.4和1.18.8两个版本，可以根据实际情况选择。另外如果你的集群有访问外网的需求，需要在选择网络的时候，确保你的VPC绑定了NAT网关，并正确配置了路由规则。</p><p>Serverless Kubernetes本身并不收取任何费用，都是通过调用的资源进行收费，在无使用的情况下，仅仅API Server使用的SLB会收取少量的费用，根据业务需求，适当选择SLB规格。如果需求不大，可以选择一个最小的。默认一天的价格大概在1.2元左右。另外，日志服务可以关闭掉，否则后期增长过快，也是一笔不小的开支。</p><p><img src="/images/pasted-247.png" alt="upload successful"></p><p>配置完成后，点击创建，等待完成后，和正常的Kubernetes环境一样使用。</p><p><img src="/images/pasted-248.png" alt="upload successful"></p><p>云商提供的Kubernetes所有操作都可以通过页面点击完成，即使你不会写yaml也可以使用这个集群。</p><h1 id="存储创建"><a href="#存储创建" class="headerlink" title="存储创建"></a>存储创建</h1><p>使用Kubernetes时需要对存储管理需要有一个认知，这里我只按照需求场景来分析一下，我们在实际使用中往往涉及到两种类型的数据：静态数据（例如配置文件）和动态数据（应用使用过程中产生的数据）。</p><h2 id="静态数据"><a href="#静态数据" class="headerlink" title="静态数据"></a>静态数据</h2><p>通常我使用“配置项”来对我的配置文件进行管理，配置项是一个键值对，最终在启动容器时，会以目录方式映射到容器内某个目录中。如果你对安全性有要求，还可以使用保密字典存放相关信息。</p><p><img src="/images/pasted-249.png" alt="upload successful"></p><h2 id="动态数据"><a href="#动态数据" class="headerlink" title="动态数据"></a>动态数据</h2><p>动态数据的管理通过“存储”目录进行配置，最终映射到容器内的存储叫存储声明，而存储声明的背后是存储卷(Persistent Volume)或者存储类(Storage Class)。</p><p><img src="/images/pasted-250.png" alt="upload successful"></p><p>这是Kubernetes官网对相关概念的诠释：</p><blockquote><p>StorageClass 为管理员提供了描述存储 “类” 的方法。 不同的类型可能会映射到不同的服务质量等级或备份策略，或是由集群管理员制定的任意策略。 Kubernetes 本身并不清楚各种类代表的什么。这个类的概念在其他存储系统中有时被称为 “配置文件”。</p><p>持久卷（PersistentVolume，PV）是集群中的一块存储，可以由管理员事先供应，或者 使用存储类（Storage Class）来动态供应。 持久卷是集群资源，就像节点也是集群资源一样。PV 持久卷和普通的 Volume 一样，也是使用 卷插件来实现的，只是它们拥有独立于任何使用 PV 的 Pod 的生命周期。 此 API 对象中记述了存储的实现细节，无论其背后是 NFS、iSCSI 还是特定于云平台的存储系统。</p></blockquote><p>后端存储可以支持多种类型，例如：云盘、NAS或者对象存储，如果使用存储类还可以支持Ceph RBD、GlusterFS。可以根据应用的特点选择后端存储类型。存储类的配置稍微复杂，所以这里直接使用NAS作为后端存储。</p><h3 id="NAS服务配置"><a href="#NAS服务配置" class="headerlink" title="NAS服务配置"></a>NAS服务配置</h3><p>NAS按量付费的模式，非常适合存储空间动态变化较大的场景，如果能选择合适的资源包，能做到成本最优。</p><p><img src="/images/pasted-251.png" alt="upload successful"></p><p>NAS分为通用型和极速型，这里我们分别选择容量型和性能型。</p><p><img src="/images/pasted-252.png" alt="upload successful"></p><h3 id="存储卷配置"><a href="#存储卷配置" class="headerlink" title="存储卷配置"></a>存储卷配置</h3><p>回到Kubernetes存储管理中，创建存储卷，选择NAS，总量方面是指这个存储的可用量，默认通用型性能型NAS配额是1PB，而容量型是10PB，这里根据实际情况填写就可以了。另外需要选择挂载点信息。</p><p><img src="/images/pasted-253.png" alt="upload successful"></p><h1 id="任务创建"><a href="#任务创建" class="headerlink" title="任务创建"></a>任务创建</h1><p>下面就可以正式启动容器了，这里之所以选择任务方式创建，是要有效的控制执行次数。当然这和你的业务类型有很大的关系。</p><p><img src="/images/pasted-254.png" alt="upload successful"></p><p>第一步是基本信息填写，没有太特殊的。</p><p><img src="/images/pasted-255.png" alt="upload successful"></p><p>第二步是主要配置，如果你的镜像仓库就是托管在阿里云容器服务内，建议使用vpc地址，这样避免产生不必要的流量。</p><p><img src="/images/pasted-256.png" alt="upload successful"></p><p>下面就是对于存储的配置，在我的conf中包含两个文件，一个是oss的连接信息，另外一个secret words文件。这样每次执行完成后，会自动的将文件上传至OSS中。</p><p>另外选择我们刚刚配置的NAS存储。</p><p><img src="/images/pasted-257.png" alt="upload successful"></p><p>第三步可以控制并发运行的数量。比如，我们希望并行的执行10个任务，则成功运行Pod数和并行运行的Pod数都设置成10，超时时间根据实际应用情况可以设置长一些，重启策略设置为不重启。</p><p><img src="/images/pasted-258.png" alt="upload successful"></p><p>最后点击创建，任务就可以执行了。</p><p><img src="/images/pasted-259.png" alt="upload successful"></p><p>最后，通过点击任务详情，查看日志，查看任务详情。</p><p><img src="/images/pasted-260.png" alt="upload successful"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>使用Kubernetes Serverless特别适合按需使用的任务场景，配合各种资源包，能够大幅度降低成本，同时做到高并发。相关代码已经托管到github上，有兴趣的朋友可以一起共同完善，我的github账号为xiaoquqi。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes是容器编排首选平台，现在各大云商也都推出了自己的Kubernetes服务。但是搭建Kubernetes环境往往在初始节点上需要很多云主机支持，三个Master节点实现HA，三个Node作为计算节点，成本开销比较大。后来阿里云推出了部分托管版本的Kubernetes，即Master节点托管给阿里云，用户只需要根据需求创建Node节点，大大节省了开销。但是如果用户连Node节点都不想创建，希望做到真正的按需分配怎么办呢？那么，你可以使用阿里云基于容器平台ECI构建的全托管版本的Kubernetes，即Kubernetes Serverless版本。这种环境下，用户可以完全忽略Master和Node节点，你的所有服务都会自动运行在ECI容器实例中，而费用则根据你的容器实际运行的时间和存储占用收取。这种方式适合有限时间内的任务运行方式，大大节约计算资源费用支出。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>公有云奇亚币(Chia)挖矿存储性能与成本分析</title>
    <link href="http://sunqi.site/2021/05/15/%E5%85%AC%E6%9C%89%E4%BA%91%E5%A5%87%E4%BA%9A%E5%B8%81-Chia-%E6%8C%96%E7%9F%BF%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E4%B8%8E%E6%88%90%E6%9C%AC%E5%88%86%E6%9E%90/"/>
    <id>http://sunqi.site/2021/05/15/%E5%85%AC%E6%9C%89%E4%BA%91%E5%A5%87%E4%BA%9A%E5%B8%81-Chia-%E6%8C%96%E7%9F%BF%E5%AD%98%E5%82%A8%E6%80%A7%E8%83%BD%E4%B8%8E%E6%88%90%E6%9C%AC%E5%88%86%E6%9E%90/</id>
    <published>2021-05-15T00:15:18.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇Blog中，主要针对使用NVMe云主机和Serverless两种方式进行了对比，通过对比我们可以看到，程序在运行时对于CPU、内存和网络要求并不高，在耕地过程中甚至可以无网情况下进行。那么问题的核心就来到了存储层面，通过观察，NVMe磁盘性能远远没有发挥到极致，那么是否有更经济同时又能保障一定效率的方法呢？</p><a id="more"></a><h1 id="测试场景"><a href="#测试场景" class="headerlink" title="测试场景"></a>测试场景</h1><p>为了测试简便，本次测试使用了云主机，直接选择高性能云硬盘作为临时盘，而NAS存储作为临时最终存储，对象存储作为最终资源的存储。主要配置为：</p><ul><li>云主机规格：4核16G CentOS 7.5 64位 5Mbps按流量计费网络</li><li>磁盘：800GiB (41800 IOPS)</li></ul><p>本次测试的目标是，在一定时间内，同时进行三个耕地，最后统计完成时间和成本。</p><h1 id="测试结论"><a href="#测试结论" class="headerlink" title="测试结论"></a>测试结论</h1><h2 id="时间成本"><a href="#时间成本" class="headerlink" title="时间成本"></a>时间成本</h2><h3 id="任务一"><a href="#任务一" class="headerlink" title="任务一"></a>任务一</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Starting phase 1&#x2F;4: Forward Propagation into tmp files... Fri May 14 08:43:12 2021</span><br><span class="line">Computing table 1</span><br><span class="line">F1 complete, time: 518.681 seconds. CPU (59.49%) Fri May 14 08:51:50 2021</span><br><span class="line">......</span><br><span class="line">Time for phase 4 &#x3D; 1201.084 seconds. CPU (61.850%) Fri May 14 21:41:05 2021</span><br><span class="line">Approximate working space used (without final file): 269.269 GiB</span><br><span class="line">Final File size: 101.315 GiB</span><br><span class="line">Total time &#x3D; 46673.510 seconds. CPU (82.100%) Fri May 14 21:41:05 2021</span><br><span class="line">Copied final file from &quot;&#x2F;plots-tmp&#x2F;1&#x2F;plot-k32-2021-05-14-08-43-557d4b8d88279c4a6044080fd819bc93bbe1c0b74d51b1fecc120fca1358fa2b.plot.2.tmp&quot; to &quot;&#x2F;plots-final&#x2F;plot-k32-2021-05-14-08-43-557d4b8d88279c4a6044080fd819bc93bbe1c0b74d51b1fecc120fca1358fa2b.plot.2.tmp&quot;</span><br><span class="line">Copy time &#x3D; 1549.110 seconds. CPU (9.160%) Fri May 14 22:07:03 2021</span><br></pre></td></tr></table></figure><h3 id="任务二"><a href="#任务二" class="headerlink" title="任务二"></a>任务二</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Starting phase 1&#x2F;4: Forward Propagation into tmp files... Fri May 14 08:43:42 2021</span><br><span class="line">Computing table 1</span><br><span class="line">F1 complete, time: 535.486 seconds. CPU (56.69%) Fri May 14 08:52:38 2021</span><br><span class="line">......</span><br><span class="line">Time for phase 4 &#x3D; 1084.804 seconds. CPU (67.540%) Fri May 14 22:01:37 2021</span><br><span class="line">Approximate working space used (without final file): 269.358 GiB</span><br><span class="line">Final File size: 101.363 GiB</span><br><span class="line">Total time &#x3D; 47874.679 seconds. CPU (80.640%) Fri May 14 22:01:37 2021</span><br><span class="line">Copied final file from &quot;&#x2F;plots-tmp&#x2F;2&#x2F;plot-k32-2021-05-14-08-43-279a5ec90eb78e42f19cd53c3fa6499c91b182539556fd1c9700793b18dc38b7.plot.2.tmp&quot; to &quot;&#x2F;plots-final&#x2F;plot-k32-2021-05-14-08-43-279a5ec90eb78e42f19cd53c3fa6499c91b182539556fd1c9700793b18dc38b7.plot.2.tmp&quot;</span><br><span class="line">Copy time &#x3D; 1406.686 seconds. CPU (9.020%) Fri May 14 22:25:04 2021</span><br></pre></td></tr></table></figure><h3 id="任务三"><a href="#任务三" class="headerlink" title="任务三"></a>任务三</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Starting phase 1&#x2F;4: Forward Propagation into tmp files... Fri May 14 08:44:11 2021</span><br><span class="line">Computing table 1</span><br><span class="line">F1 complete, time: 560.029 seconds. CPU (53.53%) Fri May 14 08:53:31 2021</span><br><span class="line">.....</span><br><span class="line">Time for phase 4 &#x3D; 1032.731 seconds. CPU (71.880%) Fri May 14 22:07:25 2021</span><br><span class="line">Approximate working space used (without final file): 269.441 GiB</span><br><span class="line">Final File size: 101.407 GiB</span><br><span class="line">Total time &#x3D; 48193.223 seconds. CPU (80.600%) Fri May 14 22:07:25 2021</span><br><span class="line">Copied final file from &quot;&#x2F;plots-tmp&#x2F;3&#x2F;plot-k32-2021-05-14-08-44-d1bbf61fafb6284291bd3e2c181b3b0dea1853b5138f6f41a330ef814781cebe.plot.2.tmp&quot; to &quot;&#x2F;plots-final&#x2F;plot-k32-2021-05-14-08-44-d1bbf61fafb6284291bd3e2c181b3b0dea1853b5138f6f41a330ef814781cebe.plot.2.tmp&quot;</span><br><span class="line">Copy time &#x3D; 1182.271 seconds. CPU (10.580%) Fri May 14 22:27:11 2021</span><br></pre></td></tr></table></figure><h3 id="统计分析"><a href="#统计分析" class="headerlink" title="统计分析"></a>统计分析</h3><table><thead><tr><th>任务</th><th>生成时间(小时)</th><th>拷贝时间（小时）</th><th>总体耗时（小时)</th></tr></thead><tbody><tr><td>任务一</td><td>12.96</td><td>0.43</td><td>13.39</td></tr><tr><td>任务二</td><td>13.3</td><td>0.39</td><td>13.69</td></tr><tr><td>任务三</td><td>13.4</td><td>0.33</td><td>13.73</td></tr></tbody></table><p>通过分析可知，在这个规格上，并发完成三次耕地的成本约为14小时以内。</p><h2 id="系统资源分析"><a href="#系统资源分析" class="headerlink" title="系统资源分析"></a>系统资源分析</h2><h3 id="临时磁盘性能"><a href="#临时磁盘性能" class="headerlink" title="临时磁盘性能"></a>临时磁盘性能</h3><p><img src="/images/pasted-241.png" alt="upload successful"></p><p><img src="/images/pasted-243.png" alt="upload successful"></p><h3 id="主机性能"><a href="#主机性能" class="headerlink" title="主机性能"></a>主机性能</h3><p><img src="/images/pasted-242.png" alt="upload successful"></p><h3 id="网络性能"><a href="#网络性能" class="headerlink" title="网络性能"></a>网络性能</h3><p><img src="/images/pasted-244.png" alt="upload successful"></p><h2 id="费用"><a href="#费用" class="headerlink" title="费用"></a>费用</h2><ul><li>云主机费用：1.14 元/小时</li><li>临时硬盘费用：1.68 元/小时</li><li>总体费用：39 元，平均一块地的成本为13 元</li></ul><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>从费用角度来说，这种部署架构的成本与Serverless相差不大，但是构建的复杂性上要低于Serverless方式，适合对于技术不甚了解的朋友进行挖矿尝鲜。</p><p>另外从性能角度看，在并发环境下，磁盘性能差异性逐渐被放大，这时磁盘越快的确对并发挖矿的速度越有帮助。不过个人觉得这其实就是和应用架构的逻辑是一样的，虽然纵向扩展能够提高单体并发性，但是横向扩展能够通过时间换数量，最终在结果上取得优势，毕竟奇亚币是以数量取胜的。</p><p>但是这也引发了我另外的思考，分布式系统要解决的是管理问题，如果想提高并发挖矿能力，对于挖矿的控制就变得非常重要了。当然，这对于搞云计算的人来说并不复杂，利用各种自动化手段可以轻易实现最佳的成本控制。虽然官方也提供了一些手段，但是从成本最优的角度看，还远远不足，所有有兴趣的小伙伴可以一起来做一个开源项目满足这方面的需求。</p><p>最后有兴趣的朋友可以入群讨论：</p><p><img src="/images/pasted-239.png" alt="upload successful"></p><p>如果加群失败，请添加个人微信号入群</p><p><img src="/images/pasted-240.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上一篇Blog中，主要针对使用NVMe云主机和Serverless两种方式进行了对比，通过对比我们可以看到，程序在运行时对于CPU、内存和网络要求并不高，在耕地过程中甚至可以无网情况下进行。那么问题的核心就来到了存储层面，通过观察，NVMe磁盘性能远远没有发挥到极致，那么是否有更经济同时又能保障一定效率的方法呢？&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Serverless奇亚币(Chia)挖矿与成本分析</title>
    <link href="http://sunqi.site/2021/04/29/Linux%E5%A5%87%E4%BA%9A%E5%B8%81-Chia-%E6%8C%96%E7%9F%BF%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://sunqi.site/2021/04/29/Linux%E5%A5%87%E4%BA%9A%E5%B8%81-Chia-%E6%8C%96%E7%9F%BF%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</id>
    <published>2021-04-29T05:09:39.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>奇亚币Chia是最近非常火的新币种，火爆到什么程度呢？火爆到大容量的硬盘都被卖光了。另外一点Chia的创始人就是BT的创始人，依靠的是硬盘容量挖矿，号称绿色挖矿。虽然一直对区块链行业不是很了解，但是仍然想凑个热闹，想尝试一下Serverless是不是能挖矿。</p><p>目前挖矿这件事情在国内还是有所禁忌的，毕竟是有违低碳环保的宗旨，同时，也有人质疑虚拟货币是不是一场资本骗局。笔者对于这些问题并没有太多研究，本文主要从技术维度对Serverless挖矿的技术实现和成本进行分析。</p><a id="more"></a><h1 id="Chia架构分析"><a href="#Chia架构分析" class="headerlink" title="Chia架构分析"></a>Chia架构分析</h1><p>之前确实没有太关注过币圈，只是简单的了解区块链的基本概念，也不曾参与过挖矿，只是简单的知道比特币必须要依靠性能强大的GPU能力。而Chia币恰好相反，不必依赖昂贵的显卡能力，而单纯消耗的存储能力。公有云的存储，特别是对象存储一向具有很大的价格优势，所以这也为公有云资源进行挖矿提供了可能性。</p><p>先来简单分析一下Chia的架构，通过分析可知对于竞猜过程，并不需要钱包参与，因为对于plot数据，创建时已经指定了两个公钥，也就是plot已经是专属“彩票”,兑奖时,直接打给的彩票的创建公钥对应的账户地址(待稍后测试确认)，对于Wallet并没有参与竞猜,所以不需要部署，对于farmer部分只需要部署，Full node，Farmer， Harvester三种，具体每个服务部署多少，取决于负载，也就是 plots的数量级。</p><p><img src="/images/pasted-227.png" alt="upload successful"></p><h1 id="Chia云主机架构挖矿"><a href="#Chia云主机架构挖矿" class="headerlink" title="Chia云主机架构挖矿"></a>Chia云主机架构挖矿</h1><h2 id="部署架构"><a href="#部署架构" class="headerlink" title="部署架构"></a>部署架构</h2><p>之前看到过利用公有云进行挖矿的案例，甚至AWS官方竟然推出了标准化文档。这些解决方案中主要利用的是云主机加上本地的NVMe存储实现高性能挖矿。</p><p><img src="/images/pasted-232.png" alt="upload successful"></p><p>在这个方案中，临时空间使用的是NVMe本地盘，而最终的持久化空间则是利用对象存储，但是由于对象存储的访问接口限制，需要利用用户态模块将对象存储以文件目录挂载给各个节点，用于最终数据的写入。但是在实际测试中，用户态的模块其实并不稳定，经常出现Input/Output Error的情况，经过与云商工单系统确认，该问题属于硬伤，只能再增加一层缓存层（比如NAS），利用对象存储的上传工具上传。</p><h2 id="时间分析"><a href="#时间分析" class="headerlink" title="时间分析"></a>时间分析</h2><p>分享一下实际的测试结果，我们云主机的规格4核32G，本地NVMe磁盘894G，最大的IOPS可以达到250000。为了测试准确性，我们使用k=32，其他为默认参数进行验证。总体生成耗时8.8小时，拷贝至最终存储11.6分钟，转存至对象存储大约耗时14分钟，总体耗时为9小时12分钟。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Approximate working space used (without final file): 269.315 GiB</span><br><span class="line">Final File size: 101.340 GiB</span><br><span class="line">Total time &#x3D; 31748.852 seconds. CPU (117.300%) Wed May 12 14:27:27 2021</span><br><span class="line">Copied final file from &quot;&#x2F;plots-tmp&#x2F;plot-k32-2021-05-12-05-38-79875f7a80d07fb658c68fd441e3c3befec4a30e2c6c9c21ee79fe815d0c4e36.plot.2.tmp&quot; to &quot;&#x2F;plots-final&#x2F;plot-k32-2021-05-12-05-38-79875f7a80d07fb658c68fd441e3c3befec4a30e2c6c9c21ee79fe815d0c4e36.plot.2.tmp&quot;</span><br><span class="line">Copy time &#x3D; 692.271 seconds. CPU (27.600%) Wed May 12 14:39:00 2021</span><br></pre></td></tr></table></figure><h2 id="资源消耗"><a href="#资源消耗" class="headerlink" title="资源消耗"></a>资源消耗</h2><p>我们看一下监控数据，在单任务并发的情况下，我们可以看到，远远没有达到NVMe的极限速度。</p><p><img src="/images/pasted-228.png" alt="upload successful"></p><p>CPU利用率方面基本没有超过25%，而网络利用率我们看到，在挖矿过程中并没有太多的网络消耗。</p><p><img src="/images/pasted-231.png" alt="upload successful"></p><p><img src="/images/pasted-230.png" alt="upload successful"></p><h2 id="资源成本"><a href="#资源成本" class="headerlink" title="资源成本"></a>资源成本</h2><p>测试过程中使用的是按量计费，Plots过程中主要涉及的云资源包括主机和云盘，费用分别为：</p><ul><li>云主机 0.44 元/小时（账单内是将存储和计算资源分别计算，购买时时在一起）</li><li>云硬盘 2.92 元/小时</li></ul><p>所以本次挖矿过程中产生的成本约为31元。对象存储1TB保存1个月数据的时间约为111元。</p><h1 id="Chia-Serverless架构挖矿"><a href="#Chia-Serverless架构挖矿" class="headerlink" title="Chia Serverless架构挖矿"></a>Chia Serverless架构挖矿</h1><h2 id="部署架构-1"><a href="#部署架构-1" class="headerlink" title="部署架构"></a>部署架构</h2><p>公有云目前都提供基于容器的实例，这种实例是按照CPU和内存的使用时间来计费，也就是如果你的CPU没有使用，则无须付费。但是目前公有云中无法将NVMe类型的磁盘直接给容器使用，我们只能将性能最佳的云盘挂载给容器的方式。另外在测试过程中，如果直接使用对象存储作为持久化存储，最终拷贝过程会出现input/output error的异常，所以在测试过程中仍然借用NAS存储作为临时性最终存储。以下为部署架构：</p><p><img src="/images/pasted-233.png" alt="upload successful"></p><p>我们将挖矿的所有节点运行在Kubernetes（Serverless）中，而Full Node放在一台低配置云主机（云主机和OSS通过内部网络通讯不收费）甚至本地环境，通过文件方式挂载使用。</p><p>本次选择的临时存储为最高性能的云硬盘，IOPS最高可达14300，缓存存储选择了普通的云盘（也可以使用NAS，成本接近），最终的数据仍然存放在对象存储。</p><h2 id="时间分析-1"><a href="#时间分析-1" class="headerlink" title="时间分析"></a>时间分析</h2><p>容器最大可使用的规格诶4C8G，云盘最大IOPS为14300。我们仍然使用k=32，其他为默认参数进行验证。总体生成耗时10.6小时，拷贝至最终存储14.5分钟，转存至对象存储大约耗时14分钟，总体耗时为11小时6分钟左右。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Approximate working space used (without final file): 269.379 GiB</span><br><span class="line">Final File size: 101.374 GiB</span><br><span class="line">Total time &#x3D; 38470.562 seconds. CPU (110.440%) Thu May 13 14:06:05 2021</span><br><span class="line">Copied final file from &quot;&#x2F;plots-tmp&#x2F;plot-k32-2021-05-13-03-24-598167f5cc365884a79d55b3c0a68d5339f223f7708a5fec1108caf2e42d3f55.plot.2.tmp&quot; to &quot;&#x2F;plots-final&#x2F;plot-k32-2021-05-13-03-24-598167f5cc365884a79d55b3c0a68d5339f223f7708a5fec1108caf2e42d3f55.plot.2.tmp&quot;</span><br><span class="line">Copy time &#x3D; 870.129 seconds. CPU (18.280%) Thu May 13 14:20:36 2021</span><br></pre></td></tr></table></figure><h2 id="资源消耗-1"><a href="#资源消耗-1" class="headerlink" title="资源消耗"></a>资源消耗</h2><p>从磁盘性能损耗来看，也仍然没有达到云盘的极限性能。</p><p><img src="/images/pasted-235.png" alt="upload successful"></p><p>内存利用率上，由于最高上限的限制，使用率应该不会超过4G，CPU利用率相对来说比较稳定，并没有超过200%。</p><p>11点监控<br><img src="/images/pasted-236.png" alt="upload successful"></p><p>15点监控<br><img src="/images/pasted-237.png" alt="upload successful"></p><p>21点监控<br><img src="/images/pasted-238.png" alt="upload successful"></p><h2 id="资源成本-1"><a href="#资源成本-1" class="headerlink" title="资源成本"></a>资源成本</h2><ul><li>容器实例：0.52 元/小时</li><li>云硬盘：0.6元/小时</li></ul><p>所以本次挖矿过程中的成本约为12.3元左右。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>从监控数据可以看到，Chia币在挖矿中虽然非常依赖于硬盘，但是单任务运行时并没有完全把硬盘性能榨干（曾经调试过Thread参数但是结果差不多，如果有其他参数请告知），只能通过提高并发性来压榨硬盘。对于Serverless，根据监控可以适当降低磁盘规格来达到进一步降低成本的目的。同时，对于CPU利用率和内存的利用也不会占用太高，2核4G基本可以满足需求（有内存不足的风险，内存默认上限为3389，可以限制）。</p><p>通过以上的实验数据可以看到，在公有云上挖矿有不同的组合方案，<br>每一种组合的成本是完全不同的。如果以单一Plots比较，Serverless方式确实有比较明显的优势。但是，由于NVMe卓越性能可以通过提高并发方式实现成本最优。根据下表中临时空间占用，在刚刚规格配置的云主机上可以实现并发3个同时挖矿的效果。</p><p><img src="/images/pasted-234.png" alt="upload successful"></p><p>同时Serverless在扩展的灵活性上要优于云主机的方案，通过适当的自动化手段，可以做到成本最优的效果。以上单纯的是从技术上对云主机挖矿的可行性进行分析，有兴趣的朋友可以入群讨论。</p><p><img src="/images/pasted-239.png" alt="upload successful"></p><p>如果加群失败，请添加个人微信号入群</p><p><img src="/images/pasted-240.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;奇亚币Chia是最近非常火的新币种，火爆到什么程度呢？火爆到大容量的硬盘都被卖光了。另外一点Chia的创始人就是BT的创始人，依靠的是硬盘容量挖矿，号称绿色挖矿。虽然一直对区块链行业不是很了解，但是仍然想凑个热闹，想尝试一下Serverless是不是能挖矿。&lt;/p&gt;
&lt;p&gt;目前挖矿这件事情在国内还是有所禁忌的，毕竟是有违低碳环保的宗旨，同时，也有人质疑虚拟货币是不是一场资本骗局。笔者对于这些问题并没有太多研究，本文主要从技术维度对Serverless挖矿的技术实现和成本进行分析。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>阿里云盘与网盘终于合并</title>
    <link href="http://sunqi.site/2021/03/13/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E4%B8%8E%E7%BD%91%E7%9B%98%E7%BB%88%E4%BA%8E%E5%90%88%E5%B9%B6/"/>
    <id>http://sunqi.site/2021/03/13/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E4%B8%8E%E7%BD%91%E7%9B%98%E7%BB%88%E4%BA%8E%E5%90%88%E5%B9%B6/</id>
    <published>2021-03-13T11:41:48.000Z</published>
    <updated>2021-11-19T02:46:24.343Z</updated>
    
    <content type="html"><![CDATA[<p>之前曾经写过一篇《我需要什么样的网盘？》来介绍内测版本的阿里云盘和Teambition网盘，其中重点讲述了阿里云内测的网盘和云盘项目，今天得到了一个确切的消息，阿里云盘和Teambition网盘终将合并。</p><a id="more"></a><p>目前阿里云盘开始公测，到3月17日之前都可以申请。</p><p><img src="/images/pasted-214.png" alt="upload successful"></p><p>目前登陆Teambiton后，会收到网盘合并的通知。登陆后，会弹出合并通知。同时，如果你同时是云盘和Teambition网盘测试用户，你将获得双倍容量即6TB。</p><p><img src="/images/pasted-215.png" alt="upload successful"></p><p>如果你在Teambition上存放数据，有几件事情需要关注一下：</p><ul><li>文件数量少：自行手动迁移</li><li>文件数量多：如果目前已存储较多数据，也可申请使用我们提供的技术迁移服务。点击填写报名表，我们将在 10 个工作日内完成技术迁移，届时将以短信通知你。</li></ul><p>另外一个值得关注就是Teambition和阿里云盘未来之间的关系，从官方给出的解释来看，一些Teambition的特色功能例如圈点评论并不会同步到阿里云盘，而阿里云盘的相册备份等特色功能也不会同步到Teambition端，但是两个应用之间功能对齐已经在计划中。</p><p>我早在上一篇软文实际上已经分析过这个问题，两个“同一公司的竞品”终于殊途同归，也算是大势所趋了。另外我还注意到阿里新的云盘图标并非阿里的传统颜色，而是近似蓝色的背景，白色的线条。</p><p><img src="/images/pasted-216.png" alt="upload successful"></p><p>另外，阿里云盘目前仍然不支持PC客户端，入口只有APP和网页部分，不过目前已经预留了客户端下载位置，应该很快就会发布了。</p><p><img src="/images/pasted-217.png" alt="upload successful"></p><p>APP方面，目前界面比较干净清爽，但是功能也偏少，目前并不支持百度云盘的分享功能。</p><p><img src="/images/pasted-218.png" alt="upload successful"></p><p>已经提供了基本的相册和视频备份功能（百度视频备份功能，如果是高清要收费，普通免费）和人脸识别分类功能。</p><p><img src="/images/pasted-219.png" alt="upload successful"></p><p><img src="/images/pasted-220.png" alt="upload successful"></p><p>虽然功能尚不完善，相信随着用户使用量激增，作为企业存储最常用的功能，这款产品的快速迭代是很快的事情，同时未来也期待与钉钉之间的深度整合，让企业办公变得更完整。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前曾经写过一篇《我需要什么样的网盘？》来介绍内测版本的阿里云盘和Teambition网盘，其中重点讲述了阿里云内测的网盘和云盘项目，今天得到了一个确切的消息，阿里云盘和Teambition网盘终将合并。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>关闭Mac系统开机启动音</title>
    <link href="http://sunqi.site/2021/03/04/%E5%85%B3%E9%97%ADMac%E7%B3%BB%E7%BB%9F%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E9%9F%B3/"/>
    <id>http://sunqi.site/2021/03/04/%E5%85%B3%E9%97%ADMac%E7%B3%BB%E7%BB%9F%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E9%9F%B3/</id>
    <published>2021-03-04T23:31:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>不知道你是否和我有一样的困惑，宁静的早晨打开iMac，一声浑然天成的开机声响彻屋内。虽然以Mac系统稳定性来说不必关机，但是对于iMac这种没有电池的主机，我还是有定期关机的习惯，只不过开机声这个问题让我很困扰。</p><a id="more"></a><h1 id="Big-Sur关闭开机音"><a href="#Big-Sur关闭开机音" class="headerlink" title="Big Sur关闭开机音"></a>Big Sur关闭开机音</h1><p>在macOS Big Sur 11或者以上版本中，可以直接通过系统菜单就将开机启动声音进行关闭，具体的设置路径如下：</p><p>系统左上角 &gt;【系统偏好设置】&gt;【声音】&gt;【声音效果】，取消【启动时播放声音】即可。</p><p><img src="/images/pasted-206.png" alt="upload successful"></p><h1 id="低版本关闭开机音"><a href="#低版本关闭开机音" class="headerlink" title="低版本关闭开机音"></a>低版本关闭开机音</h1><p>那么对于低版本的Mac系统如何关闭声音呢，答案只能通过命令行的方式了。在【终端】中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvram StartupMute&#x3D;%01</span><br></pre></td></tr></table></figure><p>恢复开机音：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvram StartupMute&#x3D;%00</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知道你是否和我有一样的困惑，宁静的早晨打开iMac，一声浑然天成的开机声响彻屋内。虽然以Mac系统稳定性来说不必关机，但是对于iMac这种没有电池的主机，我还是有定期关机的习惯，只不过开机声这个问题让我很困扰。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="MacOS" scheme="http://sunqi.site/tags/MacOS/"/>
    
  </entry>
  
  <entry>
    <title>如何在Mac上控制独立应用的音量</title>
    <link href="http://sunqi.site/2021/03/04/%E5%A6%82%E4%BD%95%E5%9C%A8Mac%E4%B8%8A%E6%8E%A7%E5%88%B6%E7%8B%AC%E7%AB%8B%E5%BA%94%E7%94%A8%E7%9A%84%E9%9F%B3%E9%87%8F/"/>
    <id>http://sunqi.site/2021/03/04/%E5%A6%82%E4%BD%95%E5%9C%A8Mac%E4%B8%8A%E6%8E%A7%E5%88%B6%E7%8B%AC%E7%AB%8B%E5%BA%94%E7%94%A8%E7%9A%84%E9%9F%B3%E9%87%8F/</id>
    <published>2021-03-04T01:12:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>我平时用Mac开会时，需要将音量调大的情况，但是有时候忘记打开了勿扰模式，导致其他应用在通知的时候声音也巨大，比如钉钉。那么如何在Mac是否有方法独立的控制每一个应用的音量呢？答案就是Background Music。</p><p><img src="/images/pasted-202.png" alt="upload successful"></p><a id="more"></a><h1 id="关于Background-Music"><a href="#关于Background-Music" class="headerlink" title="关于Background Music"></a>关于Background Music</h1><p>Background Music是一款纯开源软件，代码托管在Github上(<a href="https://github.com/kyleneideck/BackgroundMusic)。" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic)。</a></p><p>如下图所示，你可以针对每一个服务进行独立选择音量提示的范围，比如我就把钉钉静音了。</p><p><img src="/images/pasted-203.png" alt="upload successful"></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>你可以尝试使用代码编译，当然最简单的就是下载打好包的pkg文件，直接安装即可，现在安装时候需要注意，如果你是Big Sur版本，需要下载的是预览版本。</p><ul><li>Bug Sur版本：<a href="https://github.com/kyleneideck/BackgroundMusic/releases/tag/0.4.0-SNAPSHOT-c0ab98b" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic/releases/tag/0.4.0-SNAPSHOT-c0ab98b</a></li><li>早期版本：<a href="https://github.com/kyleneideck/BackgroundMusic/releases/download/v0.3.2/BackgroundMusic-0.3.2.pkg" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic/releases/download/v0.3.2/BackgroundMusic-0.3.2.pkg</a></li></ul><h1 id="开机启动"><a href="#开机启动" class="headerlink" title="开机启动"></a>开机启动</h1><p>【系统偏好配置】-&gt;【用于与群组】-&gt;【登陆项】-&gt;【添加】，从应用程序中选择Backgroud Music即可。</p><p><img src="/images/pasted-204.png" alt="upload successful"></p><p><img src="/images/pasted-205.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我平时用Mac开会时，需要将音量调大的情况，但是有时候忘记打开了勿扰模式，导致其他应用在通知的时候声音也巨大，比如钉钉。那么如何在Mac是否有方法独立的控制每一个应用的音量呢？答案就是Background Music。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-202.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="MacOS" scheme="http://sunqi.site/tags/MacOS/"/>
    
  </entry>
  
  <entry>
    <title>腾讯云Serverless现状与发展趋势</title>
    <link href="http://sunqi.site/2021/02/21/%E8%85%BE%E8%AE%AF%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
    <id>http://sunqi.site/2021/02/21/%E8%85%BE%E8%AE%AF%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-02-21T07:47:00.000Z</published>
    <updated>2021-11-19T02:46:24.343Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇主要和大家分析了Serverless整体的格局，以及重点就AWS在Serverless的现状和发展趋势进行了简单分析，今天来和大家一起来看一下腾讯云。</p><p>其实我对腾讯云Serverless的了解是通过云开发开始的，当时我的个人博客托管在Github Pages上，由于众所周知的原因，Github访问越来越慢，所以无奈之下将个人博客托管回国内。当时恰好看到了云开发的广告，9.9元网站托管赞助计划。在将网站部署到腾讯云开发过程中，逐步开始了解了腾讯的Serverless体系。</p><p><img src="/images/pasted-184.png" alt="upload successful"></p><a id="more"></a><p>第二点开始对腾讯Serverless有所了解的是通过一个开源项目Serverless，目前这个项目的中文版本和社区(serverlesscloud.cn)都是腾讯维护的。</p><p><img src="/images/pasted-185.png" alt="upload successful"></p><p>从公开的新闻看，腾讯与serverless.com在2019年达成战略合作协议（是否存在投资关系不确定，从公开资料看，目前serverless.com三家投资机构分别是：Trinity/Heavybit/Lightspeed）。</p><blockquote><p>2019年11月6日，在由腾讯云主办的首届Techo开发者大会上，腾讯云宣布与全球最流行的Serverless开发平台Serverless.com达成战略合作，成为Serverless.com的全球战略合作伙伴以及大中华区独家合作伙伴。</p></blockquote><p>第三点了解是在去年（2020年）11月腾讯小程序开发峰会上，发现腾讯小程序的开发已经与Serverless进行了深度整合，我们来看一下微信开发者工具，在顶部直接提供了云开发入口。这样小程序的开发变得更为完整，对于基于小程序生态进行开发变得更加容易，同时让前端工程师手伸的更长。</p><p><img src="/images/pasted-187.png" alt="upload successful"></p><h1 id="产品体系与生态"><a href="#产品体系与生态" class="headerlink" title="产品体系与生态"></a>产品体系与生态</h1><p>我们先从Serverless相关的产品体系来看，腾讯云对于自身的产品家族定位分为云服务、开发者平台和应用方案，另外还包括Serverless生态体系的支持。</p><p><img src="/images/pasted-183.png" alt="upload successful"></p><p>函数服务和API网关属于底层的云原生服务，在中间层上提供了聚合的Serverless Framework，无论Serverless HTTP还是Serverless SSR都是基于Serverless Framework封装的应用场景。Serverless HTTP倾向于API的提供，而SSR像是Google App Engine的PaaS服务。</p><p>基于产品体系，又推出了Serverless生态支持。包含了存储服务、应用服务、应用性能管理、开发者工具以及开发平台。</p><p><img src="/images/pasted-194.png" alt="upload successful"></p><p>基于Serverless架构，腾讯进一步封装出云开发CloudBase，上面我们也提到，云开发与微信小程序生态有着非常紧密的结合。</p><p>之前曾经参加过一次关于云开发的在线培训课程，除了底层基础服务外，腾讯云在组装Serverless向上的趋势非常明显。从开发者角度来看，目前腾讯提供的Serverless生态注重轻应用的构建。我首先从Serverless Framework和云开发角度进一步说明，当然我们首先来看一下函数计算。</p><h1 id="云函数SCF"><a href="#云函数SCF" class="headerlink" title="云函数SCF"></a>云函数SCF</h1><h2 id="用户体验"><a href="#用户体验" class="headerlink" title="用户体验"></a>用户体验</h2><p>云函数设计的界面很清爽，左侧导航栏并不非常多，只有概览、函数服务和层三个功能菜单。</p><p><img src="/images/pasted-199.png" alt="upload successful"></p><p>区别于AWS的UE设计，云函数还是保留了传统的技术风格，开发者可以通过模板创建或者自定义创建方式。在模板库里内置了很多场景化的组件供开发者选择，可以帮助开发者很快速的构建出应用场景。</p><p><img src="/images/pasted-200.png" alt="upload successful"></p><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><p>从国内的云平台提供的函数服务来看，二者从发展思路上有很大的差别，这一点从触发器角度看非常明显。腾讯的触发器种类不是非常多，但是基本都是非常实用的触发器类型。</p><p><img src="/images/pasted-195.png" alt="upload successful"></p><p>定时触发：在AWS中，需要使用CloudWatch Events服务间接的实现定时触发，而腾讯函数计算服务直接提供了定时触发的方式，可以按照既定的规则，或者干脆自己写crontab表达式。</p><p><img src="/images/pasted-196.png" alt="upload successful"></p><p>另外几种实用的触发器包括：对象存储COS触发，消息服务CMQ主题触发，消息队列Kafka触发。一种比较特殊的服务是视频处理MPS，还可以通过日志触发CLS和负载均衡触发CLB。</p><p><img src="/images/pasted-197.png" alt="upload successful"></p><p><img src="/images/pasted-198.png" alt="upload successful"></p><p>虽然触发器种类不多，但是对于用户来说不必受到云平台的深度绑定，还是有很大的灵活和自主性。</p><h2 id="开发模式"><a href="#开发模式" class="headerlink" title="开发模式"></a>开发模式</h2><p>与AWS相同，云函数中同样提供了在线开发和CLI方式进行开发。CLI方面原有腾讯的开发工具叫做sls，不过从2020年2月不再维护，转而建议用户使用兼容性更好的serverless，这个就是我们上面提到的serverless.com开源的产品。我个人对serverless.com的理解就是无服务领域的Terrafrom，不仅仅单纯的编排函数计算一种资源，serverless还可以包括对数据库、消息队列、对象存储等一系列serverless服务进行统一编排，同时提供了良好的扩展性，未来可以满足更多服务的编排。用户在构建serverless framework时更方便的对资源进行统一管理与发布。后面我会单独就serverless.com使用方法进行说明。</p><p><img src="/images/pasted-201.png" alt="upload successful"></p><h1 id="云开发"><a href="#云开发" class="headerlink" title="云开发"></a>云开发</h1><p>在之前一篇《基于Serverless架构进行应用开发》中，曾经给大家贴出这张云开发未来发展的架构图，今天再来回顾一下。(<a href="http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/">http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</a>)</p><p><img src="/images/pasted-135.png" alt="upload successful"></p><p>云开发对云原生资源进行了进一步整合，从应用开发到应用运维的全生命周期提供支持。进而向上一层提供开发者工具IDE、低代码平台等。同时提供各种SDK产品，为多端接入提供良好的支持。在之前那篇Blog中，我们也看到通过微信小程序与云开发生态整合，更快的进行轻应用开发，同时最大程度的节省成本。从云开发的发展规划不难看出，云开发未来还将更深度支持各种轻量级应用开发。</p><h2 id="微信开发者工具"><a href="#微信开发者工具" class="headerlink" title="微信开发者工具"></a>微信开发者工具</h2><p>我们在开篇提到微信开发者工具与云开发进行了深度整合，进入微信开发者工具后，其中提供了常用的云开发支持。包括数据库、存储、云函数等。</p><p><img src="/images/pasted-188.png" alt="upload successful"></p><p>虽然云函数已经支持了很多种语言，但是目前在云开发内，应用开发者还是只能使用运行环境为NodeJS 10.15的环境。不知道这样的考虑是不是因为微信很多开发者都是Node.js生态的。</p><p><img src="/images/pasted-189.png" alt="upload successful"></p><p>我们再来看看费用，之前曾经讲到过，Serverless的一个目标就是真正的让应用开发者按需使用资源，所以目前云开发的全部资源计费模式基本都是按照使用量计费的。云开发提供了套餐方式和单独资源付费的模式，如果你的应用访问不是很大，基础版1的免费版本完全可以满足你的需求。从这个角度来看，如果开发者能够合理优化自己的代码实现，很大程度上能节省掉很多成本。</p><p><img src="/images/pasted-190.png" alt="upload successful"></p><h1 id="总体评价"><a href="#总体评价" class="headerlink" title="总体评价"></a>总体评价</h1><p>腾讯的Serverless提供轻应用开发支持的感觉更强，特别是将零散的云原生服务进行二次封装，让开发者更简单的使用Serverless架构进行开发。同时通过Serverless Framework解决了无服务在编排上的问题，更容易组织复杂一点的无服务化应用程序。同时，由于微信这个金牛，一下子为云开发提供了巨大的流量入口，也让基于微信生态的小程序应用开发更容易、加快应用层创新速度。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇主要和大家分析了Serverless整体的格局，以及重点就AWS在Serverless的现状和发展趋势进行了简单分析，今天来和大家一起来看一下腾讯云。&lt;/p&gt;
&lt;p&gt;其实我对腾讯云Serverless的了解是通过云开发开始的，当时我的个人博客托管在Github Pages上，由于众所周知的原因，Github访问越来越慢，所以无奈之下将个人博客托管回国内。当时恰好看到了云开发的广告，9.9元网站托管赞助计划。在将网站部署到腾讯云开发过程中，逐步开始了解了腾讯的Serverless体系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-184.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>AWS Serverless现状与发展趋势</title>
    <link href="http://sunqi.site/2021/02/20/AWS-Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
    <id>http://sunqi.site/2021/02/20/AWS-Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-02-20T23:30:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>Serverless架构是最近一直非常关注的技术方向，基础架构在应用构建中的地位被被进一步弱化的趋势不可逆转。Serveless让开发者更加关注业务本身逻辑的特性决定了技术演进的趋势。</p><p>目前，很多人可能很难认可这样的观点，大部分人还是认为Kubernetes能够带来更多的灵活性。但是Kubernetes对于应用开发者来说，仍然要顾及底层架构。Serverless的终极目标就是彻底打消这层的关系。但不可否认的一点，Kubernetes、OpenStack等基础平台作为Serverless的底层支撑一定会长期存在，所以二者之间并非竞争关系，而是发展的阶段的不同。从另外一个角度看，在公有云最佳实践中，函数计算已经成为构建应用必不可少的一环。</p><a id="more"></a><p>我大概在2018年左右接触了AWS Lambda服务，后续一直在关注着Serverless趋势，所以本文就结合我的一点粗浅理解来分析一下AWS、阿里云和腾讯云在Serverless架构发展的趋势（分为三篇）。本文中的观点是我自身使用公有云相关服务的经验，难免存在片面性，如有不妥之处，请各位给予批评和指正。</p><p>这里先借用一张InfoQ在《Serverless国内发展纵向观察》的一张图，前面的文章中我也讲到这个问题，对于云来说，Serverless架构很重要的两个部分就是函数即服务（Function-as-a-Service）和后端即服务（Backend-as-a-Service）两部分，这两种服务类型有都属于云原生的范畴。</p><p><img src="/images/pasted-162.png" alt="upload successful"></p><p>由上图可知，FaaS和BaaS是成就Serverless的关键服务能力。函数计算的执行是通过各个云原生服务触发的（触发器执行），所以作为Serverless架构中的业务逻辑实现层，函数计算及其相关服务的发展策略基本代表了一家云商对于Serverless架构的态度。每个云其实都会有自己对Serverless的独特理解，有共性也有差别，同时又都有自身对于Serverless未来场景的理解。</p><h1 id="AWS-Serverless现状"><a href="#AWS-Serverless现状" class="headerlink" title="AWS Serverless现状"></a>AWS Serverless现状</h1><p>我在上一篇关于《Serverless发展历史》的中提到，2014年AWS发布函数计算服务Lambda，开启了新Serverless的篇章，自此以后各大公有云纷纷推出自己的函数计算服务。截止目前为止，AWS仍然是公有云领域的引领者，也是为数不多盈利的公有云公司，其发展方向一直是其他友商追逐的目标。</p><p>从局部角度看，函数计算服务在整个云计算架构中像一个粘合剂，巧妙的串联了各个云原生服务，让“不可变”的云原生服务具备了“可变性”，巧妙的解决了云原生服务之间最后一公里的问题。目前，这种使用方式几乎涵盖了AWS所有的最佳实践。</p><h1 id="AWS-Serverless架构"><a href="#AWS-Serverless架构" class="headerlink" title="AWS Serverless架构"></a>AWS Serverless架构</h1><p>根据AWS的定义，将Serverless架构定义为三层服务类别：计算、应用集成和数据存储。</p><h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><p>计算层主要包括Lambda和Fargate服务。Lambda是函数计算服务，Fargate是AWS的容器编排引擎，Fargate服务包含两种不同不同的方式：一种是自有的引擎(ECS服务)，另外一种是基于Kubernetes底座的。相较于AWS EC2服务，容器编排层好像并不是AWS关注的重点，这一点从容器服务与其他服务联动性能够隐约感觉出来。但是，AWS Lambda服务绝对足够强大。</p><p><img src="/images/pasted-173.png" alt="upload successful"></p><h2 id="应用集成"><a href="#应用集成" class="headerlink" title="应用集成"></a>应用集成</h2><p>应用集成类主要包含了用于串联函数计算的相关服务。SQS/SNS/API都是非常常用的触发器；AppSync提供了GraphQL的接口，能够从函数计算获取数据；EventBridge提供了事件驱动的架构，扩展了函数计算的事件触发类别，同时也可以进行自定义。</p><p><img src="/images/pasted-177.png" alt="upload successful"></p><p>Step Functions通过状态机的定义，很好的让多个函数计算有序运行，降低Serverless架构控制难度。</p><p><img src="/images/pasted-178.png" alt="upload successful"></p><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>在任何应用场景下，数据都是用户最宝贵的资源，特别是在当今社会下，数据被供奉在一个前所未有的高度。在与Lambda配合使用的持久化存储方面，除了常规的对象存储和非关系型数据库，还支持了RDS Proxy和Aurora Serverless。</p><p><img src="/images/pasted-179.png" alt="upload successful"></p><p>RDS Proxy主要解决并发访问RDS数据库连接数量的限制，由于函数计算随时启停的特点，无法像我们在开发传统应用时使用统一的数据库连接资源池来控制数据库的访问连接数。当并发量非常大时，会超过最大连接数导致失败的情况，所以RDS Proxy就是专门用于解决这一问题的服务。</p><p><img src="/images/pasted-182.png" alt="upload successful"></p><h1 id="函数服务Lambda"><a href="#函数服务Lambda" class="headerlink" title="函数服务Lambda"></a>函数服务Lambda</h1><h2 id="开发语言支持"><a href="#开发语言支持" class="headerlink" title="开发语言支持"></a>开发语言支持</h2><p>目前函数计算服务几乎覆盖了主流的高级开发语言，如果你的语言比较特殊，还可以基于容器自定义，提供了最大灵活度，这也是大部分厂商通用的做法。</p><p><img src="/images/pasted-181.png" alt="upload successful"></p><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><p>我们重点来看看Lmabda服务，函数计算是由事件触发的，以目前的认知，AWS Lambda与国内的公有云相比，是触发器最多的云平台(Google和AZure我没有对比过)。能够触发Lambda的，除了传统的数据库、消息队列、对象存储等，还包括了物联网设备，包括loT和Alexa音箱。</p><p><img src="/images/pasted-174.png" alt="upload successful"></p><p>除了云原生服务外，还通过EventBridge支持第三方服务直接触发Lambda，为应用开发提供了极大的便利性。</p><p><img src="/images/pasted-175.png" alt="upload successful"></p><h2 id="目标配置"><a href="#目标配置" class="headerlink" title="目标配置"></a>目标配置</h2><p>另外值得称道的是Lambda除了提供了丰富的触发器资源，在函数执行结束后也提供了异常处理能力以及后续触发调用能力，让基于Lambda开发的应用更加健壮，也更加简单。</p><p><img src="/images/pasted-176.png" alt="upload successful"></p><p>AWS还支持流式调用的映射，方便更实时的利用Lambda处理数据。</p><p><img src="/images/pasted-180.png" alt="upload successful"></p><h2 id="开发与调试"><a href="#开发与调试" class="headerlink" title="开发与调试"></a>开发与调试</h2><p>我在使用函数过程中，最大的感触就是函数计算的开发和调试是比较麻烦的，因为牵扯到各种云服务，所以在本地调试的时候会有很多限制，在线上调试又担心出现问题。AWS除了提供在线的编辑器外，CLI工具包括了AWS CLI和AWS SAM(AWS Serverless Application Model)。如果是开发函数计算，还是推荐SAM，毕竟是面向函数计算开发设计的。</p><h2 id="日志、监控与权限控制"><a href="#日志、监控与权限控制" class="headerlink" title="日志、监控与权限控制"></a>日志、监控与权限控制</h2><p>在实际使用过程中，函数计算追踪往往是初学者遇到的最大的挑战。其实用了这么久的云，在云原生服务关联性方面你是能真真切切感受到AWS的设计感的。函数计算也不例外，与IAM、日志以及CloudWatch监控服务都有比较良好的互动性，包括上面提到的CLI工具，底层也是调用了CloudFormation编排的能力实现的。所以Lambda的整个开发者生态还是非常完善和友好的。</p><h1 id="发展趋势"><a href="#发展趋势" class="headerlink" title="发展趋势"></a>发展趋势</h1><p>AWS Lambda是函数计算的里程碑，也是目前为止生态最为完整的函数计算服务。由于Lambda与其他AWS服务的良好的互动性，所以往往在整个Serverless架构中，Lambda作为连接云原生服务之间的能力体现的更加淋漓尽致一些。特别是在一些最佳实践中，通过Lambda的合理利用，往往可以降低在云架构设计和开发的成本。从另外一个层面上讲，对Lambda的特性使用的越多，对AWS依赖就会越强，对用户形成一定的锁定性。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Serverless架构是最近一直非常关注的技术方向，基础架构在应用构建中的地位被被进一步弱化的趋势不可逆转。Serveless让开发者更加关注业务本身逻辑的特性决定了技术演进的趋势。&lt;/p&gt;
&lt;p&gt;目前，很多人可能很难认可这样的观点，大部分人还是认为Kubernetes能够带来更多的灵活性。但是Kubernetes对于应用开发者来说，仍然要顾及底层架构。Serverless的终极目标就是彻底打消这层的关系。但不可否认的一点，Kubernetes、OpenStack等基础平台作为Serverless的底层支撑一定会长期存在，所以二者之间并非竞争关系，而是发展的阶段的不同。从另外一个角度看，在公有云最佳实践中，函数计算已经成为构建应用必不可少的一环。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>Serverless发展历史</title>
    <link href="http://sunqi.site/2021/02/20/Serverless%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/"/>
    <id>http://sunqi.site/2021/02/20/Serverless%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/</id>
    <published>2021-02-20T23:30:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了很多Serverless的文章，关于发展历史看了很多版本，其实对于2010年后的时间点各种国内外说法基本一致，但是在2010年之前就有多种不同的描述方式了，本文结合各种资料对Serverless发展的历史进行一下整理。</p><a id="more"></a><p>从应用开发的历史角度看，我们的应用从运行在传统的物理服务器上，经历了到虚拟化、容器到目前的Serverless，至于Serverless之后会是什么，目前还没有看到。从应用开发角度看，这个过程实际一直在进行的事情就是“解耦”，解除应用与底层之间的关联关系，最终使得应用的开发走向轻量化，用户对于底层无感。</p><p><img src="/images/pasted-166.png" alt="upload successful"></p><p>再从我们看的见的商业维度说，中关村海龙、鼎好的兴衰的过程也在印证了这一切的发展，时间回退到20年前，当初做硬件发家致富的中关村老板大有人在，包括今天的京东也是从中关村卖光盘起家的。但是如今的中关村是什么样的景象呢？这些老牌的商场纷纷面临转型，如今的繁华再也一去不复返了。</p><p>与之相呼应的是，传统的硬件集成商的日子越来越不好过了，靠卖铁度日的利润越来越薄，竞争也越来越激烈，市场也越来越透明。为什么出现这样的局面呢？原因其实就在于应用离底层越来越远，单纯的采购硬件无法解决用户的需求。虽然在传统硬件的销售也一样需要解决方案，但是在新的云计算的态势下，解决方案的复杂程度、技术含量越来越高，并非传统的“攒机”式销售就能搞定的。当然在云计算领域下还是存在这样的简单粗暴的销售产品，就是网络，这个话题并不在我们本文的范畴内。</p><h1 id="Zimki——最早使用Serverless模式的公司"><a href="#Zimki——最早使用Serverless模式的公司" class="headerlink" title="Zimki——最早使用Serverless模式的公司"></a>Zimki——最早使用Serverless模式的公司</h1><p>目前公开资料认为最早使用Serverless模式的公司叫做Zimki，即Pay as you go。他们提供服务端的Javascript程序，理念在2006年被提出。这个团队来自被欧洲佳能收购的Fotango。在slidershare上还能找到他们最早的PPT资料，不过这家公司已经倒闭。</p><p><img src="/images/pasted-163.png" alt="upload successful"></p><p>虽然Zimki是Serverless模式最早的缔造者，但是并不是最早使用Serverless词的公司。</p><p>有兴趣的朋友可以看一下他们早期的一些理念的介绍：</p><ul><li><a href="http://radar.oreilly.com/2006/09/zimki-hosted-javascript-enviro.html" target="_blank" rel="noopener">http://radar.oreilly.com/2006/09/zimki-hosted-javascript-enviro.html</a></li><li><a href="https://www.slideshare.net/swardley/zimki-2006" target="_blank" rel="noopener">https://www.slideshare.net/swardley/zimki-2006</a></li></ul><h1 id="Platform-as-a-Service"><a href="#Platform-as-a-Service" class="headerlink" title="Platform-as-a-Service"></a>Platform-as-a-Service</h1><p>在出现函数计算服务形态之前，还有一种PaaS形态，也是属于Serverless的一种形态，只不过设计的出发点不同。PaaS更注重的是完整的代码托管，开发者只需要上传自己的代码，剩下全部的交给平台。这种形态最早出现于2007年。在最近3年内，特别在容器和K8S出现之后，PaaS平台迎来了新一波的关注热度。</p><p>Heroku这家公司想必早期写博客的朋友都不会感到陌生，在那个计算资源还比较昂贵的时代，Heroku的免费资源还是非常受广大开发人员欢迎的。2007年6月Heroku开始开发，最早只支持Ruby语言(这就是为什么早期的博客工具octopress是基于Ruby开发的)，2011年的时候Ruby的首席设计师日本人松本行弘加盟了这家公司，后续又扩大了对Node.js和Clojure的支持。到目前为止，Heroku几乎覆盖了主流开发语言的。2010年Salesforce斥资两亿多美金收购了Heroku公司。</p><p><img src="/images/pasted-165.png" alt="upload successful"></p><p>2008年，Google推出了Google App Engine的PaaS服务，想必如果你当时对科学上网有所研究的话，对这个平台并不陌生。当时，最著名的开源项目非GoAgent莫属，当然实现这个项目已经无法使用了。但是当时GAE平台有非常大的局限性，无论是开发语言还是开发模式，对于框架支持等都有比较严格的限制；另外由于缺少云原生服务的支持，所以应用场景有限，同时具有非常明显的厂商锁定的特性。</p><p>其实包括AWS(AWS Beanstak)、阿里云(Web应用托管服务)在内的主流公有云厂商，目前均提供了类似GAE便于用户快速构建自己的应用，在很多最佳实践中也都有提到。</p><p>国内最早提供SAE服务的，是新浪云，是的你没有听错新浪也是有云的。新浪早在2009年11月3日推出了Alpha版本的新浪SAE，当时用于支付平台费用的叫做云豆，笔者记得当时注册新浪SAE平台，会赠送相当可观的云豆用于开发和测试。虽然新浪涉及云计算领域较早，但是后劲不足。另外还有一个值得一提的一点，新浪SAE也是国内比较早期使用OpenStack的技术团队。后来，OpenStack在中国得到前所未有的发展，与新浪SAE技术与运维团队的推广有着非常直接的关系。</p><h1 id="开源PaaS平台"><a href="#开源PaaS平台" class="headerlink" title="开源PaaS平台"></a>开源PaaS平台</h1><p>2008年一个基于AWS EC2的PaaS项目开始开发，项目使用Java语言并且基于AWS EC2，名称叫做Cloud Foundry。2009年该项目被SpringSource公司收购，同年SpringSource又被VMWare收购。但是这个Cloud Foundry与我们现在熟知的Cloud Foundry项目完全无关，只是保留了名称。最早的Cloud Foundry项目实际是由VMware内部的一个小团队开发的B29项目。</p><p>2011年4月，Cloud Foundry正式宣布开源。2012年4月，又开源了BOSH项目用于Cloud Foundry基础资源及自身的全生命周期管理。笔者在2011年有机会从事了一部分Cloud Foundry产品开发工作，记得当时BOSH对VMware支持非常完美，但是OpenStack平台基本惨不忍睹，当然这也怪当时的OpenStack自己不够争气。<br>2013年，VMware和EMC正式成立了Pivotal公司，自此包括Cloud Foundry, RabbitMQ和Spring都归属于Pivotal。</p><p>同一时期，与Cloud Foundry同一类型的开源项目就是Redhat OpenShift，目前OpenShift也是国内基于Kubernetes之上的PaaS项目(CloudFoundry也开始这么定义自己了)。当然OpenShift也不是Redhat原生项目，而是在2010年收购的Makara的项目，该公司主要基于Linux Container技术实现PaaS平台。2012年5月的时候，OpenShift正式宣布开源。OpenShift v3版本开始支持Kubernetes作为容器编排引擎，Docker作为底层容器。OpenShift v4版本为了防止Docker锁定，使用CRI-O作为容器Runtime。</p><h1 id="”Serverless“概念的来历"><a href="#”Serverless“概念的来历" class="headerlink" title="”Serverless“概念的来历"></a>”Serverless“概念的来历</h1><p>如果你使用中文搜索引擎搜索Serverless的历史，往往会提到一家公司叫做Iron.io，但是如果你搜索英文资料的时候却发现很少有提及此公司。经过一系列的搜索，终于梳理清楚了Serverless概念和定义的由来。</p><p>2012年10月，时任Iron.io BD副总裁的Ken Fromm在ReadWrite网站(互联网科技博客)上发表了一篇名为《Why The Future Of Software And Apps Is Serverless》的文章，完整的阐述了对Serverless架构的构想，其中开篇的第一句话就是：</p><blockquote><p>Even with the rise of cloud computing, the world still revolves around servers. That won’t last, though. Cloud apps are moving into a serverless world, and that will bring big implications for the creation and distribution of software and applications.</p></blockquote><p>ThoughWorks提出了对Serverless架构的定义：</p><blockquote><p>A serverless architecture approach replaces long-running virtual machines with ephemeral compute power that comes into existence on request and disappears immediately after use.</p></blockquote><blockquote><p>Serverless架构使用临时计算资源替代原有常态化运行的虚拟机，当有请求时资源存在，请求结束后资源自动销毁。</p></blockquote><p>也许你觉得太复杂了，我们来看看Techopedia网站上对Serverless的定义：</p><blockquote><p>Serverless computing is a type of cloud computing where the customer does not have to provision servers for the back-end code to run on, but accesses services as they are needed. Instead, the cloud provider starts and stops a container platform as a service as requests come in and the provider bills accordingly.</p></blockquote><blockquote><p>Serverless是云计算服务的一种，用户只需要将提供服务的代码运行在云上，而无须实现其他后端服务。云商根据访问情况，启动或者停止容器来提供服务，用户只需要根据实际消费付费。</p></blockquote><p>如果你还认为复杂，可以简单的将Serverless理解为“基于事件驱动的计算服务”。</p><h1 id="Function-as-a-Service"><a href="#Function-as-a-Service" class="headerlink" title="Function-as-a-Service"></a>Function-as-a-Service</h1><p>2014年对于Serverless是具备里程碑的一年，AWS发布了Lambda服务——基于事件驱动的函数计算服务。最早发布的Lambda仅支持JavaScript和Node，但是目前几乎涵盖了所有主流编程语言，同时支持自定义方式。</p><p><img src="/images/pasted-167.png" alt="upload successful"></p><p>在接下来的时间里，各大公有云厂商纷纷发布了自己的函数计算服务。从2014年到2018年的四年里，各大主要公有云厂商纷纷发布自己的函数计算服务并不断的迭代、演进。一方面扩大对触发器的支持范围，加强与各个云原生服务的联动性；另外一方面基于函数计算增加编排服务，方便构建更复杂的应用场景。</p><p><img src="/images/pasted-168.png" alt="upload successful"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>目前，Serverless被各方认为是未来云计算服务发展的重要趋势，也是各大厂商的必争之地。我认为Serverless对于行业的影响是深远的，除了技术层面外，还包括从业者的格局。根据Gartner 2020年6月的成熟度曲线看，Serverless还有一段发展的时间，但是作为云计算行业的从业者，应该着手应对Serverless对未来产业格局的影响。后面的文章，我将继续和大家分享我对目前公有云厂商Serverless发展的看法。</p><p><img src="/images/pasted-170.png" alt="upload successful"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://mp.weixin.qq.com/s/1jhLRNaUag-Gp-kbYvzzGA" target="_blank" rel="noopener">Serverless国内发展的纵向观察</a></li><li><a href="https://readwrite.com/2012/10/15/why-the-future-of-software-and-apps-is-serverless/?__cf_chl_jschl_tk__=9d9134331acb78cc239f3e7db934345af67bbdc7-1613485823-0-ARJ7RlgI0rpCz7GIY2DCiOUmXfWwk0bP-j7LmFE25MHdY6rqorQ069DcGqkzOpoxRuF_6QQav0-GxS00_nMmF7lpD2gCs33ZMSva-klU-Dlc9Vg2bMzg9TiW4s4mjpmwpjG4SvaWqwsr0rTe48hjYksKmMwUn9GWWeYRjERPJUvgQ20EVTLysumFK6sOjvEt7-AlesfFVqDeCRFjjpN6-_cbDwyGHGZ-PgAxaWrgy4_dbgDFXiz98GSEb0BBhtdqcWMFpI1qkocucVqWrOwsQdKfwX6_zh_QV1joZDfefFJqKafULTlgJ8bpx7AczZOkheoMZFwMaCXRrCd2jX5SFiv2fkgf5fBq3h71pWKaQsFF_oKHxqzx-NBGidZH22_qSYf5LkbpJdGLJRUNGWURU02GZmSK_HqqPlLhRxNS_pQTHMe2qM-7pSzvMadnDRZafQ" target="_blank" rel="noopener">Why The Future Of Software And Apps Is Serverless</a></li><li><a href="https://www.thoughtworks.com/radar/techniques/serverless-architecture" target="_blank" rel="noopener">ThoughtWorks Serverless architecture</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看了很多Serverless的文章，关于发展历史看了很多版本，其实对于2010年后的时间点各种国内外说法基本一致，但是在2010年之前就有多种不同的描述方式了，本文结合各种资料对Serverless发展的历史进行一下整理。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>防止你的钱包掉进Serverless使用的坑</title>
    <link href="http://sunqi.site/2021/02/18/%E9%98%B2%E6%AD%A2%E4%BD%A0%E7%9A%84%E9%92%B1%E5%8C%85%E6%8E%89%E8%BF%9BServerless%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9D%91/"/>
    <id>http://sunqi.site/2021/02/18/%E9%98%B2%E6%AD%A2%E4%BD%A0%E7%9A%84%E9%92%B1%E5%8C%85%E6%8E%89%E8%BF%9BServerless%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9D%91/</id>
    <published>2021-02-18T13:51:00.000Z</published>
    <updated>2021-11-19T02:46:24.343Z</updated>
    
    <content type="html"><![CDATA[<p>今天读到InfoQ一篇《应用上云2小时烧掉近50万，创始人：差点破产，简直噩梦》讲述了在使用Serverless方式开发时由于程序Bug导致快速的资源消耗，差点破产的经历。特意查询了英文原文，题目叫做《We Burnt $72K testing Firebase - Cloud Run and almost went Bankrupt》。我之前在使用函数计算时也有一次类似经历，所以写出来供大家参考，防止你的钱包掉进Serverless使用的坑。</p><a id="more"></a><h1 id="钱是如何被烧掉的？"><a href="#钱是如何被烧掉的？" class="headerlink" title="钱是如何被烧掉的？"></a>钱是如何被烧掉的？</h1><p>如果要理解原文中为什么出现问题，先要了解一下Google Serverless的产品体系：</p><ul><li>Cloud Functions: 基于事件驱动的函数计算服务</li><li>App Engine: 上一篇讲述Serverless发展过程的时候恰好提到过这个服务，是Google的PaaS平台，开发人员可以直接将代码托管在平台上运行，具有良好的扩展性</li><li>Cloud Run: 无状态的Serverless HTTP容器，口号是 Bringing Serverless to Containers，可以执行任何语言</li><li>Cloud Firestore: 是一种灵活且可扩缩的数据库，适用于在Firebase和Google Cloud Platform上进行移动、Web 和服务器开发。</li></ul><p>从账单里可以看到，用户最消耗资源的费用是来自App Engine对Cloud Firestore读取次数达到惊人的千亿次，按照原文里的说法，这里仅仅是两个个小时的成绩。在惊叹费用的同时，我们不得不感叹云原生服务性能之优异。</p><p><img src="/images/pasted-171.png" alt="upload successful"></p><p>作者针对这一事件前后共发布了三篇博客，第一篇主要还原事情的脉络，以及在使用Google服务时候的坑；第二篇在剖析自身的错误；最后一篇在作者感叹了一下自己的经历被翻译成各种语言，另外写了另外一篇《How to user Cloud without losing Sleep》防止大家踩坑。</p><p>通篇看下来，作者将问题归咎于几个地方：</p><ul><li>核心问题：代码中包含Bug(Deploying flawed algorithm on Cloud)，不恰当的使用递归而形成死循环(Exponential Recursion without Break: The instances wouldn’t know when to break, as there was no break statement.)</li><li>测试环境中，Cloud Run默认并发实例时1000，测试环境中也使用了默认值，如果在测试环境选择并发数是2，那么费用将从72,000美金降到144美金</li><li>在没有完全掌握Firebase时探索性的使用，没想到Firebase性能这么强大（广告嫌疑）</li><li>基于云开发仍然要抱有对技术的敬畏心，云原生服务降低了运维和开发的难度，但是在使用方式、价格、配置等诸多因素的复杂度必然会与传统有很大的区别，正所谓软件工程领域没有银弹</li></ul><h1 id="我在函数计算上踩过的坑"><a href="#我在函数计算上踩过的坑" class="headerlink" title="我在函数计算上踩过的坑"></a>我在函数计算上踩过的坑</h1><p>之前在测试阿里云函数计算过程时，曾经也有过一次入坑经历。当时我写了一个简单的函数，当有.png文件上传至OSS后，就自动进行Resize操作，保存成三种规格16x16, 32x32, 64x64，之后重新传回到OSS。但是我忽略了一点，我将处理好的文件重新传输回了同一个OSS Bucket内，结果造成了一个死循环。</p><p><img src="/images/pasted-172.png" alt="upload successful"></p><p>其实我所犯的错误和上面公司遇到的问题是一样的，不过好在我的这次错误没有导致很严重的后果。由于时间久远，我无法找到当时的截图。我只记得我的函数计算在短时间内调用了70万次，OSS上传了几百万个小文件。还好阿里云100万次内的访问是免费的，OSS价格比较便宜，但是还是惊出了一身冷汗。赶紧把我的函数服务下线，同时写了一个脚本删除小文件，因为没有直接的命令可以删除非空的Bucket，整个善后清理工作持续了几个小时。</p><h1 id="如何防止踩坑"><a href="#如何防止踩坑" class="headerlink" title="如何防止踩坑"></a>如何防止踩坑</h1><p>作为新的技术趋势，在前进的过程中难免遇到各种各样的问题。目前确实还没有一套指导规范帮助研发人员有效的避免踩坑。所以也需要大家在实践中不断总结。</p><ul><li>做技术的人还是要有一颗敬畏的心，任何新技术的引进都会带来风险，所以在你没有十足的把握的时候，还是小心的比较好</li><li>云的并发性能真的太强大了，所以一定要做好发生异常时的应对方案，让并发性在你的可控范围内进行，控制”爆炸半径“</li><li>Serverless的开发模式对研发流程是一个全新的挑战，在上述案例中问题出现在了测试阶段，不同于传统的测试，Serverless与开发更为紧密，对于白盒测试的要求更高，一方面需要做好单元测试，另外一方面对开发者综合考虑问题的素质要求更高，或许DevTest会成为Serverless在落地实践中需要解决的问题之一</li><li>动手与阅读文档并行，云服务的文档就和普通商品的说明书一样，没人会去主动阅读的，只有实在搞不出来的时候才会想着看一看，但是云服务不同于普通的产品，一些细枝末节的选项太多，还是应当在使用一段时间后回过头来通读文档的内容，加深理解</li></ul><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://blog.tomilkieway.com/72k-1/" target="_blank" rel="noopener">https://blog.tomilkieway.com/72k-1/</a></li><li><a href="https://blog.tomilkieway.com/72k-2/" target="_blank" rel="noopener">https://blog.tomilkieway.com/72k-2/</a></li><li><a href="https://sudcha.com/guide-to-cloud/" target="_blank" rel="noopener">https://sudcha.com/guide-to-cloud/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天读到InfoQ一篇《应用上云2小时烧掉近50万，创始人：差点破产，简直噩梦》讲述了在使用Serverless方式开发时由于程序Bug导致快速的资源消耗，差点破产的经历。特意查询了英文原文，题目叫做《We Burnt $72K testing Firebase - Cloud Run and almost went Bankrupt》。我之前在使用函数计算时也有一次类似经历，所以写出来供大家参考，防止你的钱包掉进Serverless使用的坑。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSQL无法启动“global/pg_control”：Permission denied</title>
    <link href="http://sunqi.site/2021/02/11/PostgreSQL%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E2%80%9Cglobal-pg-control%E2%80%9D%EF%BC%9APermission-denied/"/>
    <id>http://sunqi.site/2021/02/11/PostgreSQL%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E2%80%9Cglobal-pg-control%E2%80%9D%EF%BC%9APermission-denied/</id>
    <published>2021-02-11T00:44:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>昨天在为用户进行迁移后，用户Windows 2012系统上PostgreSQL服务无法启动，日志中提示“global/pg_control”：Permission denied，于是上网一顿搜索终于解决了这个问题。</p><a id="more"></a><h1 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h1><p>如果端口没有被占用，那么你可以用PostgreSQL原生的命令启动它。进入postgresql安装路径下的 bin 文件夹，在这里打开命令行，执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\pg_ctl start -D ..\data</span><br></pre></td></tr></table></figure><p>如果程序报出如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR: could not open control file “global&#x2F;pg_control”: Permission denied</span><br></pre></td></tr></table></figure><p><img src="/images/pasted-159.png" alt="upload successful"></p><p>则说明当前操作系统用户丢失了data文件夹及其内容的权限。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><ol><li>首先，进入postgresql 的安装路径，右键data文件夹，依次点击属性——安全——编辑，你能看到所有用户或用户组的权限。</li></ol><p><img src="/images/pasted-160.png" alt="upload successful"></p><ol start="2"><li>确保System 和 Administrator 拥有“完全控制”权限。Users 用户组默认只拥有“读取和执行”，“列出文件夹内容”和“读取”3种权限。当启动数据库提示“权限不足”时，应再添加“修改”和 “写入”。我这次出现问题就在这里，User没有修改和写入权限，添加后即可启动成功。</li></ol><p><img src="/images/pasted-161.png" alt="upload successful"></p><ol start="3"><li>保存并尝试再次在bin 文件夹下执行：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\pg_ctl start -D ..\data</span><br></pre></td></tr></table></figure><p>观察PostgreSQL数据库能否启动。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://blog.csdn.net/international24/article/details/89710703" target="_blank" rel="noopener">https://blog.csdn.net/international24/article/details/89710703</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;昨天在为用户进行迁移后，用户Windows 2012系统上PostgreSQL服务无法启动，日志中提示“global/pg_control”：Permission denied，于是上网一顿搜索终于解决了这个问题。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据库" scheme="http://sunqi.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>传统应用架构与Serverless架构总体拥有成本(TCO)分析与比较</title>
    <link href="http://sunqi.site/2021/02/10/%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B8%8EServerless%E6%9E%B6%E6%9E%84%E6%80%BB%E4%BD%93%E6%8B%A5%E6%9C%89%E6%88%90%E6%9C%AC-TCO-%E5%88%86%E6%9E%90%E4%B8%8E%E6%AF%94%E8%BE%83/"/>
    <id>http://sunqi.site/2021/02/10/%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B8%8EServerless%E6%9E%B6%E6%9E%84%E6%80%BB%E4%BD%93%E6%8B%A5%E6%9C%89%E6%88%90%E6%9C%AC-TCO-%E5%88%86%E6%9E%90%E4%B8%8E%E6%AF%94%E8%BE%83/</id>
    <published>2021-02-10T13:55:00.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>这篇报告是2019年9月德勤基于AWS Serverless发布的一篇白皮书，原文叫《Determining the Total<br>Cost of Ownership of Serverless Technologies when compared to Traditional Cloud》。本文就基于这篇文章提供的方法论，来分析一下Serverless模式的开发总成本。顺便比较一下国内各个云在Serverless架构下的成本。我们重点比较国内排名前三的云平台：阿里云、腾讯云和华为云。</p><p>在原文中包含两个案例，我们重点结合第一个案例云主机与Serverless的比较进行详细分析。</p><a id="more"></a><h1 id="如何对Serverless模式成本进行估算"><a href="#如何对Serverless模式成本进行估算" class="headerlink" title="如何对Serverless模式成本进行估算"></a>如何对Serverless模式成本进行估算</h1><p>Serverless模式是一种真正的将云平台的计算、存储和网络按需付费的云计算理想模式。之前的文章中我也提到过，Serverless最大的优势就是降低了基础架构层的可见性，即“零运维”。开发人员可以更关注业务逻辑的开发，而将繁重的运维工作交由云商负责。Serverless为应用带来了良好的可扩展性、敏捷性和弹性，缩短应用上线时间，提高发布频率，加速公司收入增长。</p><p>但是由于使用情况的不确定性，往往很难精准的估算Serverless的成本。在本文中对于Serverless TCO评估框架包含三个关键成本：基础设施、开发和维护。</p><h1 id="案例简述"><a href="#案例简述" class="headerlink" title="案例简述"></a>案例简述</h1><p>这是一家交通运输公司的需求，用户平均在途中的时间要花费两个多小时。交通公司提供了一个应用（可能是手机APP）包含以下功能：在线订票、连接WIFI、还可以实时监控自己行程。每年有数百万乘客、数百个目的地以及数千条线路，这些相乘之后需要一个并发量巨大的系统进行支撑。运输公司应对这种情况需要花费非常昂贵的成本，而且很难预测。这样也影响了与决策相关的数据得不到及时更新，造成机会成本的丧失。所以为了解决这个问题，这家公司在评估将订票系统运行在函数计算服务上还是EC2实例上。根据测算，这套系统需要满足每天150万笔交易。</p><h1 id="基础设施成本"><a href="#基础设施成本" class="headerlink" title="基础设施成本"></a>基础设施成本</h1><p>资源部分应该是最透明也是最容易比较的部分，只要根据应用运行的情况评估价格即可。</p><h2 id="传统方式"><a href="#传统方式" class="headerlink" title="传统方式"></a>传统方式</h2><p>这是原文中给出的系统资源消耗情况，因为没有更细节化的信息，所以只能根据价格进行反推。</p><table><thead><tr><th align="left">云资源名称</th><th>规格</th><th align="center">数量</th></tr></thead><tbody><tr><td align="left">云主机</td><td>m5.large(2vCPU/8G/200G)</td><td align="center">3个</td></tr><tr><td align="left">数据库</td><td>r5.large(2vCPU/16G/500G)</td><td align="center">3个</td></tr><tr><td align="left">云硬盘</td><td>500 IOPS SSD</td><td align="center">1GB</td></tr><tr><td align="left">负载均衡</td><td></td><td align="center">30 GB/小时</td></tr></tbody></table><p>原文案例中并没有改变给出具体的应用架构和构建细节，所以我们无法从技术层面深究架构合理性，所以只能更关注成本因素。</p><h2 id="Serverless模式"><a href="#Serverless模式" class="headerlink" title="Serverless模式"></a>Serverless模式</h2><p>Serverless是按照资源使用时间计费的，所以这里要根据使用时间计算价格。</p><table><thead><tr><th align="left">功能模块</th><th>规格</th><th align="center">执行时间</th><th>每月平均请求次数</th></tr></thead><tbody><tr><td align="left">售票响应函数</td><td>512 MB内存</td><td align="center">3000 ms</td><td>32,400,000</td></tr><tr><td align="left">数据处理</td><td>512 MB内存</td><td align="center">3000 ms</td><td>10,800,000</td></tr></tbody></table><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>这是原文给出的资源消耗情况比对，但是有一些非常明显的错误，总计部分很明显的对不上。从原文中的描述可以得知这些信息：Webservers三台节点对应了下面处理票务的函数；而数据库加上存储对应了数据处理函数。这里我非常疑惑的一点：就算你把逻辑写在了函数计算里，你最终处理完的数据还是需要用持久化存储呀？所以我认为这个案例在描述上存在很大的纰漏，对于Serverless至少还应该包含一个数据库服务用于存储最终处理的数据。不过这里我们不纠结与这个问题，只从案例的成本分析进行对比。</p><p><img src="/images/pasted-155.png" alt="upload successful"></p><p>出乎意料的是，在这个请求量级上，使用函数计算服务在这个场景下反而要高于应用系统建立在云主机上。函数计算两个非常重要的计量指标：运行时间和请求次数，这两个指标决定了你的账单。</p><p>相同的情况也发生在Kubernetes服务中，我们之前在构建SaaS时，重点评估了阿里云Kubernetes托管版本(用两台云主机作为Worker, Master托管)和Serverless版本(Master和Worker节点均不见，底层直接使用阿里云ECI容器服务)，原本以为Serverless版本要比托管版本便宜，但是由于我们的程序多以Daemon方式运行，轮询任务很多，导致资源使用时间较长，最终的结果是Serverless版本的价格远远高于托管版本的价格。所以在应用Serverless架构时，要从这种架构的特点进行设计，降低上线后的成本。</p><h1 id="开发成本"><a href="#开发成本" class="headerlink" title="开发成本"></a>开发成本</h1><p>开发成本是评估Serverless架构总体成本第二个重要因素，如果使用传统方式开发，当客户量激增后，基础架构瓶颈的问题。当出现问题再去调整架构进行开发，会无形中错失很多机会成本，引起客户不满。如果在前期过度进行开发设计或者投入大量基础架构设施，又会导致前期成本的浪费。所以对于这种场景，Serverless灵活的扩展性就更加适合业务发展的需要，更好的满足客户的需求，同时又避免了资源的浪费。</p><p><img src="/images/pasted-156.png" alt="upload successful"></p><p>虽然云主机在一定程度上降低了传统运维成本，但是相较于Serverless架构，仍然需要去维护网络、安全、负载均衡、自动伸缩策略等。而使用Serverless架构时，由于采用的事件驱动，所以研发人员无须在前期设计阶段将过多精力研究系统健壮性，可以马上进入研发阶段。</p><p><img src="/images/pasted-157.png" alt="upload successful"></p><p>另外一部分成本来自于持久化集成，在传统方式下，DevOps流程往往需要经历多个阶段，从编译到制品库，从打包到上线中间过程相对较长。由于函数计算的特点，可以更快速的发布上线。测试人员也可以根据函数计算针对性的设计测试方法，合理的控制产品出现Bug的“爆炸半径”。</p><h1 id="运维成本"><a href="#运维成本" class="headerlink" title="运维成本"></a>运维成本</h1><p>运维上主要关注以下几个方面：扩展性、安全、补丁、监控验证测试等内容。每一个应用受到应用的范围和组织的影响，在运维成本上不同。但是，根据平均情况，使用传统云主机，运维人员每个月需要花费8-10小时在于加强安全性，额外每月需要40个小时用于监控、日志分析、验证和测试工作。而使用Serverless架构，运维的工作量进一步下降，真正可以做到开发运维一体化的效果，让Developer做Operation成为可能。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>在达到一定请求数量级时，Serverless架构在基础架构上要高于传统自建方式，但是在开发和维护成本上，Serverless要大幅度优于传统架构。在本案例中，整体成本预估节约40%的TCO。要从架构设计上对函数计算的特点有充分的认知，根据函数计算特点进行设计，才能最大化利用函数计算实现降本增效的结果。</p><p><img src="/images/pasted-158.png" alt="upload successful"></p><p>Serverless非常适合建设业务需求变化较快的业务场景，并且由于拥有一定数量免费额度，当请求量在每月百万级别时，使用Serverless的成本会更低甚至免费。</p><h1 id="参考：国内云平台资源比较"><a href="#参考：国内云平台资源比较" class="headerlink" title="参考：国内云平台资源比较"></a>参考：国内云平台资源比较</h1><p>这里所列的费用，均未包含流量费用。我们可以看到国内三大主流公有云的定价是出奇的一致，但从目录价格角度来说，三朵云基本是一样的。</p><table><thead><tr><th align="left">功能模块</th><th>阿里云</th><th>腾讯云</th><th>华为云</th></tr></thead><tbody><tr><td align="left">售票响应函数</td><td>5372.2964元</td><td>5395.818元</td><td>5396元</td></tr><tr><td align="left">数据处理</td><td>1760.3876元</td><td>1768.098元</td><td>1768元</td></tr></tbody></table><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul><li>阿里云函数价格计算器：<a href="http://tools.functioncompute.com/?spm=5176.8663048.0.0.42f33edcdlsZnq#/price" target="_blank" rel="noopener">http://tools.functioncompute.com/?spm=5176.8663048.0.0.42f33edcdlsZnq#/price</a></li><li>腾讯云函数价格计算器：<a href="https://buy.cloud.tencent.com/price/scf/calculator?rid=8&amp;invokeCountUnit=1&amp;invokeDurationUnit=1&amp;publicNetOutTrafficUnit=1&amp;timestamp=0" target="_blank" rel="noopener">https://buy.cloud.tencent.com/price/scf/calculator?rid=8&amp;invokeCountUnit=1&amp;invokeDurationUnit=1&amp;publicNetOutTrafficUnit=1&amp;timestamp=0</a></li><li>华为云函数工作流（无计算功能）：<a href="https://www.huaweicloud.com/pricing.html?tab=detail#/function" target="_blank" rel="noopener">https://www.huaweicloud.com/pricing.html?tab=detail#/function</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇报告是2019年9月德勤基于AWS Serverless发布的一篇白皮书，原文叫《Determining the Total&lt;br&gt;Cost of Ownership of Serverless Technologies when compared to Traditional Cloud》。本文就基于这篇文章提供的方法论，来分析一下Serverless模式的开发总成本。顺便比较一下国内各个云在Serverless架构下的成本。我们重点比较国内排名前三的云平台：阿里云、腾讯云和华为云。&lt;/p&gt;
&lt;p&gt;在原文中包含两个案例，我们重点结合第一个案例云主机与Serverless的比较进行详细分析。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>利用阿里云VPN服务实现HyperMotion SaaS私有云迁移</title>
    <link href="http://sunqi.site/2021/02/10/%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91VPN%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0HyperMotion-SaaS%E7%A7%81%E6%9C%89%E4%BA%91%E8%BF%81%E7%A7%BB/"/>
    <id>http://sunqi.site/2021/02/10/%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91VPN%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0HyperMotion-SaaS%E7%A7%81%E6%9C%89%E4%BA%91%E8%BF%81%E7%A7%BB/</id>
    <published>2021-02-10T02:35:16.000Z</published>
    <updated>2021-11-19T02:46:24.339Z</updated>
    
    <content type="html"><![CDATA[<p>目前云原生迁移平台HyperMotion SaaS主要应用场景在公有云上，但是在我们平时的测试场景中，由于上行带宽的限制，每次向公有云同步比较消耗时间，特别是在验证启动流程时，需要等待半天到一天的时间进行数据同步，非常不划算。在我们内部环境中，我们经常测试的一种场景是从VMWare迁移到私有化部署的OpenStack上。但是由于网络的限制不可能将OpenStack及Floating IP资源在公网上一一映射（如果是客户场景，通常是私有化部署的HyperMotion解决）。那么，是否可以将线上VPC与本地的机房网络环境利用VPN隧道打通，实现利用HyperMotion SaaS进行私有云环境的迁移呢？本文就为你分享利用阿里云VPN服务实现上述场景的需求。</p><a id="more"></a><h1 id="需求与场景分析"><a href="#需求与场景分析" class="headerlink" title="需求与场景分析"></a>需求与场景分析</h1><p>HyperMotion SaaS是部署在阿里云Kubernetes托管版集群中，即Kubernetes Master节点由阿里云负责，阿里云为我们在指定VPC内启动了两台ECS实例作为Worker节点。在我们自身需求中，需要解决两个流量问题：</p><ul><li>控制流：HyperMotion SaaS每个租户可以添加指定的目标云平台，HyperMotion SaaS后台模块通过VPC关联的NAT网关访问云平台API接口及资源，但是如果添加的是我们内部的OpenStack，则需要SaaS侧与OpenStack控制网络想通；另外HyperMotion会自动利用云平台的云主机资源安装云存储网关，所以也需要访问OpenStack Floating IP的地址（具体看云平台规划，也许是Fixed IP）。</li><li>数据流：在数据层面上，我们仍然希望数据层面通过内网传输，没有必要将数据流入公网，好在HyperMotion SaaS的设计满足了这样的需求</li></ul><p><img src="/images/pasted-133.png" alt="upload successful"></p><p>所以在这个解决方案中，重点是利用阿里云VPN网关和本地打通后（前提是公司出口路由有固定的公网IP），通过合理的设置路由规则实现我们上述的需求。</p><p>注意：文章中使用的截图并非全部都是真实截图，所以在实际配置过程中要根据实际情况进行。</p><h1 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h1><p>配置过程中主要涉及阿里云VPN服务和H3C路由器，基本流程如下：</p><ul><li>1、阿里云建立VPN网关，这个最低购买力度是包月</li><li>2、拿到阿里云VPN网关后，在路由器上进行相关配置</li><li>3、回到阿里云配置用户网关及IPsec连接，查看连接是否成功</li><li>4、阿里云侧路由设置</li></ul><h1 id="1、阿里云VPN网关配置"><a href="#1、阿里云VPN网关配置" class="headerlink" title="1、阿里云VPN网关配置"></a>1、阿里云VPN网关配置</h1><p>VPN需要关联到VPC和交换机上，根据带宽的不同，价格也不同，最低是按照包1个月5 Mbps。</p><p><img src="/images/pasted-147.png" alt="upload successful"></p><p>配置好后，会得到一个公网IP，这个公网IP需要在后续配置到路由器上。</p><p><img src="/images/pasted-134.png" alt="upload successful"></p><h1 id="2、H3C路由器设置"><a href="#2、H3C路由器设置" class="headerlink" title="2、H3C路由器设置"></a>2、H3C路由器设置</h1><p>目前我们机房使用的路由器属于非常入门级的企业级路由器（H3C ER3200G2），但是基本能满足我们的需求了，并且支持IPsec VPN方式。之前一直很惧怕配置IPsec VPN，相较于L2TP等简单方案，配置起来太复杂了。但是经过几次折腾，也基本摸清楚是怎么回事了，真是应了那句话：人类的恐惧来自于无知。</p><p>我并不是网络方面的专家，也对IPsec原理没什么研究，我只想记录一下我是怎么配置的。我认为IPsec在配置的时候，最重要的一点是两头配置一样，无法连接往往是由于配置信息不一致导致的。这是一张原理图，加深我们对配置过程的理解。</p><p><img src="/images/pasted-143.png" alt="upload successful"></p><p>H3C配置的基本流程为：虚接口-&gt;IKE安全提议-&gt;IKE对等体-&gt;IPsec安全提议-&gt;IPsec安全策略。</p><h2 id="2-1、虚接口配置"><a href="#2-1、虚接口配置" class="headerlink" title="2.1、虚接口配置"></a>2.1、虚接口配置</h2><p>虚接口应该是定义与外界互连的通道，配置很简单，只要指明对外服务的接口（比如：WAN1）就可以了。</p><p><img src="/images/pasted-134.png" alt="upload successful"></p><h2 id="2-2、IKE安全提议"><a href="#2-2、IKE安全提议" class="headerlink" title="2.2、IKE安全提议"></a>2.2、IKE安全提议</h2><p>IKE是因特网密钥交换的缩写(Internet Key Exchange)，从名字上可以猜出这与互联网进行交换数据时加密有关。验证算法和加密算法一定要与对端配置一致，关于DH组，每一个平台选项不一样，比如截图中叫DH2 modp1024，到了阿里云就叫做group2了，所以也必须要配置一致。</p><p><img src="/images/pasted-139.png" alt="upload successful"></p><p>阿里云侧DH组选项</p><p><img src="/images/pasted-140.png" alt="upload successful"></p><h2 id="2-3、IKE对等体"><a href="#2-3、IKE对等体" class="headerlink" title="2.3、IKE对等体"></a>2.3、IKE对等体</h2><p>和对端的VPN网关进行连接，对端IP是需要首先在对端建立VPN网关后，会得到相应的地址，填入即可。</p><p><img src="/images/pasted-141.png" alt="upload successful"></p><p>协商模式上，阿里云的配置是英文的，主模式叫做main，而野蛮模式被称为aggresive。</p><p><img src="/images/pasted-142.png" alt="upload successful"></p><p>共享密钥是自定义的，两端必须一致，DPD阿里云默认是开启的，而H3C上是关闭的，保持统一即可。</p><h2 id="2-4、IPsec安全提议"><a href="#2-4、IPsec安全提议" class="headerlink" title="2.4、IPsec安全提议"></a>2.4、IPsec安全提议</h2><p>按照我粗浅的认知，IKE主要负责两端连接，同时简化了IPsec交互，而真正的数据交互还是要在IPsec上进行控制。所以要对IPsec也要进行相应的安全配置。安全协议类型，我们选择了默认的ESP，阿里云侧默认也应该采用的是此协议。在配置对端时，仍然是保持一致即可。</p><p><img src="/images/pasted-144.png" alt="upload successful"></p><h2 id="2-5、IPsec安全策略"><a href="#2-5、IPsec安全策略" class="headerlink" title="2.5、IPsec安全策略"></a>2.5、IPsec安全策略</h2><p>这一步最关键的是本地子网IP和对端子网IP及掩码的设置，双方是相反的，如果本地是192.168.0.0/24，源端是172.16.0.0/24。则在阿里云侧的配置就是本地是172.16.0.0/24，远端是192.168.0.0/24。</p><p><img src="/images/pasted-145.png" alt="upload successful"></p><p>还有一个就是PFS的设置，和IKE的DH组是一样的，在阿里云侧也被称为IPsec的DH组。也必须设置一致。</p><p><img src="/images/pasted-146.png" alt="upload successful"></p><h1 id="3、阿里云IPsec连接配置"><a href="#3、阿里云IPsec连接配置" class="headerlink" title="3、阿里云IPsec连接配置"></a>3、阿里云IPsec连接配置</h1><h2 id="3-1、用户网关设置"><a href="#3-1、用户网关设置" class="headerlink" title="3.1、用户网关设置"></a>3.1、用户网关设置</h2><p>用户网关设置比较简单，只要在阿里云测配置你路由的公网IP即可。</p><p><img src="/images/pasted-149.png" alt="upload successful"></p><h2 id="3-2、IPsec连接"><a href="#3-2、IPsec连接" class="headerlink" title="3.2、IPsec连接"></a>3.2、IPsec连接</h2><p>这是最关键的一步，经常在这一步配置失败，提示在第一阶段或者第二阶段失败，目前在我遇到的情况中，基本都是上述配置不一致导致的。配置过程基本分为三个阶段，基本配置、高级配置中的IKE配置和IPsec配置。</p><h3 id="3-2-1-基本配置"><a href="#3-2-1-基本配置" class="headerlink" title="3.2.1 基本配置"></a>3.2.1 基本配置</h3><p>注意图中标出的本端网络、对端网络和预共享密钥的配置，一定要填对。</p><p><img src="/images/pasted-150.png" alt="upload successful"></p><h3 id="3-2-2-IKE配置"><a href="#3-2-2-IKE配置" class="headerlink" title="3.2.2 IKE配置"></a>3.2.2 IKE配置</h3><p>点开下方的高级设置，能够看到IKE和IPsec设置。</p><p>配置只要按照我们在H3C的配置选择相应的内容即可，LocalId和RemoteId都是自动根据VPN填写的，并不需要输入。</p><p><img src="/images/pasted-151.png" alt="upload successful"></p><h3 id="3-2-3-IPsec配置"><a href="#3-2-3-IPsec配置" class="headerlink" title="3.2.3 IPsec配置"></a>3.2.3 IPsec配置</h3><p>图中标注的选项一定要保持一致，提交配置后，等待连接。</p><p><img src="/images/pasted-152.png" alt="upload successful"></p><h2 id="3-3、查看连接状态"><a href="#3-3、查看连接状态" class="headerlink" title="3.3、查看连接状态"></a>3.3、查看连接状态</h2><p>如果连接状态为第二阶段协商成功，就证明VPN已经建立成功，否则请检查配置，多半是由于配置不一致导致的。</p><p><img src="/images/pasted-153.png" alt="upload successful"></p><h1 id="4、设置路由"><a href="#4、设置路由" class="headerlink" title="4、设置路由"></a>4、设置路由</h1><p>我们次此设置路由的目的是为了阿里云侧能够访问我们内网，所以接下来需要在阿里云VPC内设置路由表，当访问我们的内网时，需要使用VPN网关。进入VPC服务的路由表配置中，找到VPC。将目标IP段吓一跳设置为VPN网关。因为阿里云的ACL还处于内测阶段，所以暂时无须考虑ACL的设定。</p><p><img src="/images/pasted-154.png" alt="upload successful"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>网络对于未来混合云的场景有至关重要的作用，本文重点描述的是以VPN方式来打通云上和云下环境，但是VPN最大的带宽规格只有200 Mbps，如果真实的需求更大，则需要考虑云联网，通过运营商底层基础设施，实现不同云之间的互联互通。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前云原生迁移平台HyperMotion SaaS主要应用场景在公有云上，但是在我们平时的测试场景中，由于上行带宽的限制，每次向公有云同步比较消耗时间，特别是在验证启动流程时，需要等待半天到一天的时间进行数据同步，非常不划算。在我们内部环境中，我们经常测试的一种场景是从VMWare迁移到私有化部署的OpenStack上。但是由于网络的限制不可能将OpenStack及Floating IP资源在公网上一一映射（如果是客户场景，通常是私有化部署的HyperMotion解决）。那么，是否可以将线上VPC与本地的机房网络环境利用VPN隧道打通，实现利用HyperMotion SaaS进行私有云环境的迁移呢？本文就为你分享利用阿里云VPN服务实现上述场景的需求。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
