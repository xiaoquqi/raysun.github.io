<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>老孙正经胡说</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://sunqi.site/"/>
  <updated>2021-04-20T02:14:09.996Z</updated>
  <id>http://sunqi.site/</id>
  
  <author>
    <name>孙琦(Ray)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>阿里云盘与网盘终于合并</title>
    <link href="http://sunqi.site/2021/03/13/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E4%B8%8E%E7%BD%91%E7%9B%98%E7%BB%88%E4%BA%8E%E5%90%88%E5%B9%B6/"/>
    <id>http://sunqi.site/2021/03/13/%E9%98%BF%E9%87%8C%E4%BA%91%E7%9B%98%E4%B8%8E%E7%BD%91%E7%9B%98%E7%BB%88%E4%BA%8E%E5%90%88%E5%B9%B6/</id>
    <published>2021-03-13T11:41:48.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>之前曾经写过一篇《我需要什么样的网盘？》来介绍内测版本的阿里云盘和Teambition网盘，其中重点讲述了阿里云内测的网盘和云盘项目，今天得到了一个确切的消息，阿里云盘和Teambition网盘终将合并。</p><a id="more"></a><p>目前阿里云盘开始公测，到3月17日之前都可以申请。</p><p><img src="/images/pasted-214.png" alt="upload successful"></p><p>目前登陆Teambiton后，会收到网盘合并的通知。登陆后，会弹出合并通知。同时，如果你同时是云盘和Teambition网盘测试用户，你将获得双倍容量即6TB。</p><p><img src="/images/pasted-215.png" alt="upload successful"></p><p>如果你在Teambition上存放数据，有几件事情需要关注一下：</p><ul><li>文件数量少：自行手动迁移</li><li>文件数量多：如果目前已存储较多数据，也可申请使用我们提供的技术迁移服务。点击填写报名表，我们将在 10 个工作日内完成技术迁移，届时将以短信通知你。</li></ul><p>另外一个值得关注就是Teambition和阿里云盘未来之间的关系，从官方给出的解释来看，一些Teambition的特色功能例如圈点评论并不会同步到阿里云盘，而阿里云盘的相册备份等特色功能也不会同步到Teambition端，但是两个应用之间功能对齐已经在计划中。</p><p>我早在上一篇软文实际上已经分析过这个问题，两个“同一公司的竞品”终于殊途同归，也算是大势所趋了。另外我还注意到阿里新的云盘图标并非阿里的传统颜色，而是近似蓝色的背景，白色的线条。</p><p><img src="/images/pasted-216.png" alt="upload successful"></p><p>另外，阿里云盘目前仍然不支持PC客户端，入口只有APP和网页部分，不过目前已经预留了客户端下载位置，应该很快就会发布了。</p><p><img src="/images/pasted-217.png" alt="upload successful"></p><p>APP方面，目前界面比较干净清爽，但是功能也偏少，目前并不支持百度云盘的分享功能。</p><p><img src="/images/pasted-218.png" alt="upload successful"></p><p>已经提供了基本的相册和视频备份功能（百度视频备份功能，如果是高清要收费，普通免费）和人脸识别分类功能。</p><p><img src="/images/pasted-219.png" alt="upload successful"></p><p><img src="/images/pasted-220.png" alt="upload successful"></p><p>虽然功能尚不完善，相信随着用户使用量激增，作为企业存储最常用的功能，这款产品的快速迭代是很快的事情，同时未来也期待与钉钉之间的深度整合，让企业办公变得更完整。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前曾经写过一篇《我需要什么样的网盘？》来介绍内测版本的阿里云盘和Teambition网盘，其中重点讲述了阿里云内测的网盘和云盘项目，今天得到了一个确切的消息，阿里云盘和Teambition网盘终将合并。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>关闭Mac系统开机启动音</title>
    <link href="http://sunqi.site/2021/03/04/%E5%85%B3%E9%97%ADMac%E7%B3%BB%E7%BB%9F%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E9%9F%B3/"/>
    <id>http://sunqi.site/2021/03/04/%E5%85%B3%E9%97%ADMac%E7%B3%BB%E7%BB%9F%E5%BC%80%E6%9C%BA%E5%90%AF%E5%8A%A8%E9%9F%B3/</id>
    <published>2021-03-04T23:31:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>不知道你是否和我有一样的困惑，宁静的早晨打开iMac，一声浑然天成的开机声响彻屋内。虽然以Mac系统稳定性来说不必关机，但是对于iMac这种没有电池的主机，我还是有定期关机的习惯，只不过开机声这个问题让我很困扰。</p><a id="more"></a><h1 id="Big-Sur关闭开机音"><a href="#Big-Sur关闭开机音" class="headerlink" title="Big Sur关闭开机音"></a>Big Sur关闭开机音</h1><p>在macOS Big Sur 11或者以上版本中，可以直接通过系统菜单就将开机启动声音进行关闭，具体的设置路径如下：</p><p>系统左上角 &gt;【系统偏好设置】&gt;【声音】&gt;【声音效果】，取消【启动时播放声音】即可。</p><p><img src="/images/pasted-206.png" alt="upload successful"></p><h1 id="低版本关闭开机音"><a href="#低版本关闭开机音" class="headerlink" title="低版本关闭开机音"></a>低版本关闭开机音</h1><p>那么对于低版本的Mac系统如何关闭声音呢，答案只能通过命令行的方式了。在【终端】中输入：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvram StartupMute&#x3D;%01</span><br></pre></td></tr></table></figure><p>恢复开机音：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvram StartupMute&#x3D;%00</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;不知道你是否和我有一样的困惑，宁静的早晨打开iMac，一声浑然天成的开机声响彻屋内。虽然以Mac系统稳定性来说不必关机，但是对于iMac这种没有电池的主机，我还是有定期关机的习惯，只不过开机声这个问题让我很困扰。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="MacOS" scheme="http://sunqi.site/tags/MacOS/"/>
    
  </entry>
  
  <entry>
    <title>如何在Mac上控制独立应用的音量</title>
    <link href="http://sunqi.site/2021/03/04/%E5%A6%82%E4%BD%95%E5%9C%A8Mac%E4%B8%8A%E6%8E%A7%E5%88%B6%E7%8B%AC%E7%AB%8B%E5%BA%94%E7%94%A8%E7%9A%84%E9%9F%B3%E9%87%8F/"/>
    <id>http://sunqi.site/2021/03/04/%E5%A6%82%E4%BD%95%E5%9C%A8Mac%E4%B8%8A%E6%8E%A7%E5%88%B6%E7%8B%AC%E7%AB%8B%E5%BA%94%E7%94%A8%E7%9A%84%E9%9F%B3%E9%87%8F/</id>
    <published>2021-03-04T01:12:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>我平时用Mac开会时，需要将音量调大的情况，但是有时候忘记打开了勿扰模式，导致其他应用在通知的时候声音也巨大，比如钉钉。那么如何在Mac是否有方法独立的控制每一个应用的音量呢？答案就是Background Music。</p><p><img src="/images/pasted-202.png" alt="upload successful"></p><a id="more"></a><h1 id="关于Background-Music"><a href="#关于Background-Music" class="headerlink" title="关于Background Music"></a>关于Background Music</h1><p>Background Music是一款纯开源软件，代码托管在Github上(<a href="https://github.com/kyleneideck/BackgroundMusic)。" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic)。</a></p><p>如下图所示，你可以针对每一个服务进行独立选择音量提示的范围，比如我就把钉钉静音了。</p><p><img src="/images/pasted-203.png" alt="upload successful"></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>你可以尝试使用代码编译，当然最简单的就是下载打好包的pkg文件，直接安装即可，现在安装时候需要注意，如果你是Big Sur版本，需要下载的是预览版本。</p><ul><li>Bug Sur版本：<a href="https://github.com/kyleneideck/BackgroundMusic/releases/tag/0.4.0-SNAPSHOT-c0ab98b" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic/releases/tag/0.4.0-SNAPSHOT-c0ab98b</a></li><li>早期版本：<a href="https://github.com/kyleneideck/BackgroundMusic/releases/download/v0.3.2/BackgroundMusic-0.3.2.pkg" target="_blank" rel="noopener">https://github.com/kyleneideck/BackgroundMusic/releases/download/v0.3.2/BackgroundMusic-0.3.2.pkg</a></li></ul><h1 id="开机启动"><a href="#开机启动" class="headerlink" title="开机启动"></a>开机启动</h1><p>【系统偏好配置】-&gt;【用于与群组】-&gt;【登陆项】-&gt;【添加】，从应用程序中选择Backgroud Music即可。</p><p><img src="/images/pasted-204.png" alt="upload successful"></p><p><img src="/images/pasted-205.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我平时用Mac开会时，需要将音量调大的情况，但是有时候忘记打开了勿扰模式，导致其他应用在通知的时候声音也巨大，比如钉钉。那么如何在Mac是否有方法独立的控制每一个应用的音量呢？答案就是Background Music。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-202.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="MacOS" scheme="http://sunqi.site/tags/MacOS/"/>
    
  </entry>
  
  <entry>
    <title>腾讯云Serverless现状与发展趋势</title>
    <link href="http://sunqi.site/2021/02/21/%E8%85%BE%E8%AE%AF%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
    <id>http://sunqi.site/2021/02/21/%E8%85%BE%E8%AE%AF%E4%BA%91Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-02-21T07:47:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇主要和大家分析了Serverless整体的格局，以及重点就AWS在Serverless的现状和发展趋势进行了简单分析，今天来和大家一起来看一下腾讯云。</p><p>其实我对腾讯云Serverless的了解是通过云开发开始的，当时我的个人博客托管在Github Pages上，由于众所周知的原因，Github访问越来越慢，所以无奈之下将个人博客托管回国内。当时恰好看到了云开发的广告，9.9元网站托管赞助计划。在将网站部署到腾讯云开发过程中，逐步开始了解了腾讯的Serverless体系。</p><p><img src="/images/pasted-184.png" alt="upload successful"></p><a id="more"></a><p>第二点开始对腾讯Serverless有所了解的是通过一个开源项目Serverless，目前这个项目的中文版本和社区(serverlesscloud.cn)都是腾讯维护的。</p><p><img src="/images/pasted-185.png" alt="upload successful"></p><p>从公开的新闻看，腾讯与serverless.com在2019年达成战略合作协议（是否存在投资关系不确定，从公开资料看，目前serverless.com三家投资机构分别是：Trinity/Heavybit/Lightspeed）。</p><blockquote><p>2019年11月6日，在由腾讯云主办的首届Techo开发者大会上，腾讯云宣布与全球最流行的Serverless开发平台Serverless.com达成战略合作，成为Serverless.com的全球战略合作伙伴以及大中华区独家合作伙伴。</p></blockquote><p>第三点了解是在去年（2020年）11月腾讯小程序开发峰会上，发现腾讯小程序的开发已经与Serverless进行了深度整合，我们来看一下微信开发者工具，在顶部直接提供了云开发入口。这样小程序的开发变得更为完整，对于基于小程序生态进行开发变得更加容易，同时让前端工程师手伸的更长。</p><p><img src="/images/pasted-187.png" alt="upload successful"></p><h1 id="产品体系与生态"><a href="#产品体系与生态" class="headerlink" title="产品体系与生态"></a>产品体系与生态</h1><p>我们先从Serverless相关的产品体系来看，腾讯云对于自身的产品家族定位分为云服务、开发者平台和应用方案，另外还包括Serverless生态体系的支持。</p><p><img src="/images/pasted-183.png" alt="upload successful"></p><p>函数服务和API网关属于底层的云原生服务，在中间层上提供了聚合的Serverless Framework，无论Serverless HTTP还是Serverless SSR都是基于Serverless Framework封装的应用场景。Serverless HTTP倾向于API的提供，而SSR像是Google App Engine的PaaS服务。</p><p>基于产品体系，又推出了Serverless生态支持。包含了存储服务、应用服务、应用性能管理、开发者工具以及开发平台。</p><p><img src="/images/pasted-194.png" alt="upload successful"></p><p>基于Serverless架构，腾讯进一步封装出云开发CloudBase，上面我们也提到，云开发与微信小程序生态有着非常紧密的结合。</p><p>之前曾经参加过一次关于云开发的在线培训课程，除了底层基础服务外，腾讯云在组装Serverless向上的趋势非常明显。从开发者角度来看，目前腾讯提供的Serverless生态注重轻应用的构建。我首先从Serverless Framework和云开发角度进一步说明，当然我们首先来看一下函数计算。</p><h1 id="云函数SCF"><a href="#云函数SCF" class="headerlink" title="云函数SCF"></a>云函数SCF</h1><h2 id="用户体验"><a href="#用户体验" class="headerlink" title="用户体验"></a>用户体验</h2><p>云函数设计的界面很清爽，左侧导航栏并不非常多，只有概览、函数服务和层三个功能菜单。</p><p><img src="/images/pasted-199.png" alt="upload successful"></p><p>区别于AWS的UE设计，云函数还是保留了传统的技术风格，开发者可以通过模板创建或者自定义创建方式。在模板库里内置了很多场景化的组件供开发者选择，可以帮助开发者很快速的构建出应用场景。</p><p><img src="/images/pasted-200.png" alt="upload successful"></p><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><p>从国内的云平台提供的函数服务来看，二者从发展思路上有很大的差别，这一点从触发器角度看非常明显。腾讯的触发器种类不是非常多，但是基本都是非常实用的触发器类型。</p><p><img src="/images/pasted-195.png" alt="upload successful"></p><p>定时触发：在AWS中，需要使用CloudWatch Events服务间接的实现定时触发，而腾讯函数计算服务直接提供了定时触发的方式，可以按照既定的规则，或者干脆自己写crontab表达式。</p><p><img src="/images/pasted-196.png" alt="upload successful"></p><p>另外几种实用的触发器包括：对象存储COS触发，消息服务CMQ主题触发，消息队列Kafka触发。一种比较特殊的服务是视频处理MPS，还可以通过日志触发CLS和负载均衡触发CLB。</p><p><img src="/images/pasted-197.png" alt="upload successful"></p><p><img src="/images/pasted-198.png" alt="upload successful"></p><p>虽然触发器种类不多，但是对于用户来说不必受到云平台的深度绑定，还是有很大的灵活和自主性。</p><h2 id="开发模式"><a href="#开发模式" class="headerlink" title="开发模式"></a>开发模式</h2><p>与AWS相同，云函数中同样提供了在线开发和CLI方式进行开发。CLI方面原有腾讯的开发工具叫做sls，不过从2020年2月不再维护，转而建议用户使用兼容性更好的serverless，这个就是我们上面提到的serverless.com开源的产品。我个人对serverless.com的理解就是无服务领域的Terrafrom，不仅仅单纯的编排函数计算一种资源，serverless还可以包括对数据库、消息队列、对象存储等一系列serverless服务进行统一编排，同时提供了良好的扩展性，未来可以满足更多服务的编排。用户在构建serverless framework时更方便的对资源进行统一管理与发布。后面我会单独就serverless.com使用方法进行说明。</p><p><img src="/images/pasted-201.png" alt="upload successful"></p><h1 id="云开发"><a href="#云开发" class="headerlink" title="云开发"></a>云开发</h1><p>在之前一篇《基于Serverless架构进行应用开发》中，曾经给大家贴出这张云开发未来发展的架构图，今天再来回顾一下。(<a href="http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/">http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</a>)</p><p><img src="/images/pasted-135.png" alt="upload successful"></p><p>云开发对云原生资源进行了进一步整合，从应用开发到应用运维的全生命周期提供支持。进而向上一层提供开发者工具IDE、低代码平台等。同时提供各种SDK产品，为多端接入提供良好的支持。在之前那篇Blog中，我们也看到通过微信小程序与云开发生态整合，更快的进行轻应用开发，同时最大程度的节省成本。从云开发的发展规划不难看出，云开发未来还将更深度支持各种轻量级应用开发。</p><h2 id="微信开发者工具"><a href="#微信开发者工具" class="headerlink" title="微信开发者工具"></a>微信开发者工具</h2><p>我们在开篇提到微信开发者工具与云开发进行了深度整合，进入微信开发者工具后，其中提供了常用的云开发支持。包括数据库、存储、云函数等。</p><p><img src="/images/pasted-188.png" alt="upload successful"></p><p>虽然云函数已经支持了很多种语言，但是目前在云开发内，应用开发者还是只能使用运行环境为NodeJS 10.15的环境。不知道这样的考虑是不是因为微信很多开发者都是Node.js生态的。</p><p><img src="/images/pasted-189.png" alt="upload successful"></p><p>我们再来看看费用，之前曾经讲到过，Serverless的一个目标就是真正的让应用开发者按需使用资源，所以目前云开发的全部资源计费模式基本都是按照使用量计费的。云开发提供了套餐方式和单独资源付费的模式，如果你的应用访问不是很大，基础版1的免费版本完全可以满足你的需求。从这个角度来看，如果开发者能够合理优化自己的代码实现，很大程度上能节省掉很多成本。</p><p><img src="/images/pasted-190.png" alt="upload successful"></p><h1 id="总体评价"><a href="#总体评价" class="headerlink" title="总体评价"></a>总体评价</h1><p>腾讯的Serverless提供轻应用开发支持的感觉更强，特别是将零散的云原生服务进行二次封装，让开发者更简单的使用Serverless架构进行开发。同时通过Serverless Framework解决了无服务在编排上的问题，更容易组织复杂一点的无服务化应用程序。同时，由于微信这个金牛，一下子为云开发提供了巨大的流量入口，也让基于微信生态的小程序应用开发更容易、加快应用层创新速度。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇主要和大家分析了Serverless整体的格局，以及重点就AWS在Serverless的现状和发展趋势进行了简单分析，今天来和大家一起来看一下腾讯云。&lt;/p&gt;
&lt;p&gt;其实我对腾讯云Serverless的了解是通过云开发开始的，当时我的个人博客托管在Github Pages上，由于众所周知的原因，Github访问越来越慢，所以无奈之下将个人博客托管回国内。当时恰好看到了云开发的广告，9.9元网站托管赞助计划。在将网站部署到腾讯云开发过程中，逐步开始了解了腾讯的Serverless体系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-184.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>Serverless发展历史</title>
    <link href="http://sunqi.site/2021/02/20/Serverless%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/"/>
    <id>http://sunqi.site/2021/02/20/Serverless%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2/</id>
    <published>2021-02-20T23:30:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>最近看了很多Serverless的文章，关于发展历史看了很多版本，其实对于2010年后的时间点各种国内外说法基本一致，但是在2010年之前就有多种不同的描述方式了，本文结合各种资料对Serverless发展的历史进行一下整理。</p><a id="more"></a><p>从应用开发的历史角度看，我们的应用从运行在传统的物理服务器上，经历了到虚拟化、容器到目前的Serverless，至于Serverless之后会是什么，目前还没有看到。从应用开发角度看，这个过程实际一直在进行的事情就是“解耦”，解除应用与底层之间的关联关系，最终使得应用的开发走向轻量化，用户对于底层无感。</p><p><img src="/images/pasted-166.png" alt="upload successful"></p><p>再从我们看的见的商业维度说，中关村海龙、鼎好的兴衰的过程也在印证了这一切的发展，时间回退到20年前，当初做硬件发家致富的中关村老板大有人在，包括今天的京东也是从中关村卖光盘起家的。但是如今的中关村是什么样的景象呢？这些老牌的商场纷纷面临转型，如今的繁华再也一去不复返了。</p><p>与之相呼应的是，传统的硬件集成商的日子越来越不好过了，靠卖铁度日的利润越来越薄，竞争也越来越激烈，市场也越来越透明。为什么出现这样的局面呢？原因其实就在于应用离底层越来越远，单纯的采购硬件无法解决用户的需求。虽然在传统硬件的销售也一样需要解决方案，但是在新的云计算的态势下，解决方案的复杂程度、技术含量越来越高，并非传统的“攒机”式销售就能搞定的。当然在云计算领域下还是存在这样的简单粗暴的销售产品，就是网络，这个话题并不在我们本文的范畴内。</p><h1 id="Zimki——最早使用Serverless模式的公司"><a href="#Zimki——最早使用Serverless模式的公司" class="headerlink" title="Zimki——最早使用Serverless模式的公司"></a>Zimki——最早使用Serverless模式的公司</h1><p>目前公开资料认为最早使用Serverless模式的公司叫做Zimki，即Pay as you go。他们提供服务端的Javascript程序，理念在2006年被提出。这个团队来自被欧洲佳能收购的Fotango。在slidershare上还能找到他们最早的PPT资料，不过这家公司已经倒闭。</p><p><img src="/images/pasted-163.png" alt="upload successful"></p><p>虽然Zimki是Serverless模式最早的缔造者，但是并不是最早使用Serverless词的公司。</p><p>有兴趣的朋友可以看一下他们早期的一些理念的介绍：</p><ul><li><a href="http://radar.oreilly.com/2006/09/zimki-hosted-javascript-enviro.html" target="_blank" rel="noopener">http://radar.oreilly.com/2006/09/zimki-hosted-javascript-enviro.html</a></li><li><a href="https://www.slideshare.net/swardley/zimki-2006" target="_blank" rel="noopener">https://www.slideshare.net/swardley/zimki-2006</a></li></ul><h1 id="Platform-as-a-Service"><a href="#Platform-as-a-Service" class="headerlink" title="Platform-as-a-Service"></a>Platform-as-a-Service</h1><p>在出现函数计算服务形态之前，还有一种PaaS形态，也是属于Serverless的一种形态，只不过设计的出发点不同。PaaS更注重的是完整的代码托管，开发者只需要上传自己的代码，剩下全部的交给平台。这种形态最早出现于2007年。在最近3年内，特别在容器和K8S出现之后，PaaS平台迎来了新一波的关注热度。</p><p>Heroku这家公司想必早期写博客的朋友都不会感到陌生，在那个计算资源还比较昂贵的时代，Heroku的免费资源还是非常受广大开发人员欢迎的。2007年6月Heroku开始开发，最早只支持Ruby语言(这就是为什么早期的博客工具octopress是基于Ruby开发的)，2011年的时候Ruby的首席设计师日本人松本行弘加盟了这家公司，后续又扩大了对Node.js和Clojure的支持。到目前为止，Heroku几乎覆盖了主流开发语言的。2010年Salesforce斥资两亿多美金收购了Heroku公司。</p><p><img src="/images/pasted-165.png" alt="upload successful"></p><p>2008年，Google推出了Google App Engine的PaaS服务，想必如果你当时对科学上网有所研究的话，对这个平台并不陌生。当时，最著名的开源项目非GoAgent莫属，当然实现这个项目已经无法使用了。但是当时GAE平台有非常大的局限性，无论是开发语言还是开发模式，对于框架支持等都有比较严格的限制；另外由于缺少云原生服务的支持，所以应用场景有限，同时具有非常明显的厂商锁定的特性。</p><p>其实包括AWS(AWS Beanstak)、阿里云(Web应用托管服务)在内的主流公有云厂商，目前均提供了类似GAE便于用户快速构建自己的应用，在很多最佳实践中也都有提到。</p><p>国内最早提供SAE服务的，是新浪云，是的你没有听错新浪也是有云的。新浪早在2009年11月3日推出了Alpha版本的新浪SAE，当时用于支付平台费用的叫做云豆，笔者记得当时注册新浪SAE平台，会赠送相当可观的云豆用于开发和测试。虽然新浪涉及云计算领域较早，但是后劲不足。另外还有一个值得一提的一点，新浪SAE也是国内比较早期使用OpenStack的技术团队。后来，OpenStack在中国得到前所未有的发展，与新浪SAE技术与运维团队的推广有着非常直接的关系。</p><h1 id="开源PaaS平台"><a href="#开源PaaS平台" class="headerlink" title="开源PaaS平台"></a>开源PaaS平台</h1><p>2008年一个基于AWS EC2的PaaS项目开始开发，项目使用Java语言并且基于AWS EC2，名称叫做Cloud Foundry。2009年该项目被SpringSource公司收购，同年SpringSource又被VMWare收购。但是这个Cloud Foundry与我们现在熟知的Cloud Foundry项目完全无关，只是保留了名称。最早的Cloud Foundry项目实际是由VMware内部的一个小团队开发的B29项目。</p><p>2011年4月，Cloud Foundry正式宣布开源。2012年4月，又开源了BOSH项目用于Cloud Foundry基础资源及自身的全生命周期管理。笔者在2011年有机会从事了一部分Cloud Foundry产品开发工作，记得当时BOSH对VMware支持非常完美，但是OpenStack平台基本惨不忍睹，当然这也怪当时的OpenStack自己不够争气。<br>2013年，VMware和EMC正式成立了Pivotal公司，自此包括Cloud Foundry, RabbitMQ和Spring都归属于Pivotal。</p><p>同一时期，与Cloud Foundry同一类型的开源项目就是Redhat OpenShift，目前OpenShift也是国内基于Kubernetes之上的PaaS项目(CloudFoundry也开始这么定义自己了)。当然OpenShift也不是Redhat原生项目，而是在2010年收购的Makara的项目，该公司主要基于Linux Container技术实现PaaS平台。2012年5月的时候，OpenShift正式宣布开源。OpenShift v3版本开始支持Kubernetes作为容器编排引擎，Docker作为底层容器。OpenShift v4版本为了防止Docker锁定，使用CRI-O作为容器Runtime。</p><h1 id="”Serverless“概念的来历"><a href="#”Serverless“概念的来历" class="headerlink" title="”Serverless“概念的来历"></a>”Serverless“概念的来历</h1><p>如果你使用中文搜索引擎搜索Serverless的历史，往往会提到一家公司叫做Iron.io，但是如果你搜索英文资料的时候却发现很少有提及此公司。经过一系列的搜索，终于梳理清楚了Serverless概念和定义的由来。</p><p>2012年10月，时任Iron.io BD副总裁的Ken Fromm在ReadWrite网站(互联网科技博客)上发表了一篇名为《Why The Future Of Software And Apps Is Serverless》的文章，完整的阐述了对Serverless架构的构想，其中开篇的第一句话就是：</p><blockquote><p>Even with the rise of cloud computing, the world still revolves around servers. That won’t last, though. Cloud apps are moving into a serverless world, and that will bring big implications for the creation and distribution of software and applications.</p></blockquote><p>ThoughWorks提出了对Serverless架构的定义：</p><blockquote><p>A serverless architecture approach replaces long-running virtual machines with ephemeral compute power that comes into existence on request and disappears immediately after use.</p></blockquote><blockquote><p>Serverless架构使用临时计算资源替代原有常态化运行的虚拟机，当有请求时资源存在，请求结束后资源自动销毁。</p></blockquote><p>也许你觉得太复杂了，我们来看看Techopedia网站上对Serverless的定义：</p><blockquote><p>Serverless computing is a type of cloud computing where the customer does not have to provision servers for the back-end code to run on, but accesses services as they are needed. Instead, the cloud provider starts and stops a container platform as a service as requests come in and the provider bills accordingly.</p></blockquote><blockquote><p>Serverless是云计算服务的一种，用户只需要将提供服务的代码运行在云上，而无须实现其他后端服务。云商根据访问情况，启动或者停止容器来提供服务，用户只需要根据实际消费付费。</p></blockquote><p>如果你还认为复杂，可以简单的将Serverless理解为“基于事件驱动的计算服务”。</p><h1 id="Function-as-a-Service"><a href="#Function-as-a-Service" class="headerlink" title="Function-as-a-Service"></a>Function-as-a-Service</h1><p>2014年对于Serverless是具备里程碑的一年，AWS发布了Lambda服务——基于事件驱动的函数计算服务。最早发布的Lambda仅支持JavaScript和Node，但是目前几乎涵盖了所有主流编程语言，同时支持自定义方式。</p><p><img src="/images/pasted-167.png" alt="upload successful"></p><p>在接下来的时间里，各大公有云厂商纷纷发布了自己的函数计算服务。从2014年到2018年的四年里，各大主要公有云厂商纷纷发布自己的函数计算服务并不断的迭代、演进。一方面扩大对触发器的支持范围，加强与各个云原生服务的联动性；另外一方面基于函数计算增加编排服务，方便构建更复杂的应用场景。</p><p><img src="/images/pasted-168.png" alt="upload successful"></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>目前，Serverless被各方认为是未来云计算服务发展的重要趋势，也是各大厂商的必争之地。我认为Serverless对于行业的影响是深远的，除了技术层面外，还包括从业者的格局。根据Gartner 2020年6月的成熟度曲线看，Serverless还有一段发展的时间，但是作为云计算行业的从业者，应该着手应对Serverless对未来产业格局的影响。后面的文章，我将继续和大家分享我对目前公有云厂商Serverless发展的看法。</p><p><img src="/images/pasted-170.png" alt="upload successful"></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ul><li><a href="https://mp.weixin.qq.com/s/1jhLRNaUag-Gp-kbYvzzGA" target="_blank" rel="noopener">Serverless国内发展的纵向观察</a></li><li><a href="https://readwrite.com/2012/10/15/why-the-future-of-software-and-apps-is-serverless/?__cf_chl_jschl_tk__=9d9134331acb78cc239f3e7db934345af67bbdc7-1613485823-0-ARJ7RlgI0rpCz7GIY2DCiOUmXfWwk0bP-j7LmFE25MHdY6rqorQ069DcGqkzOpoxRuF_6QQav0-GxS00_nMmF7lpD2gCs33ZMSva-klU-Dlc9Vg2bMzg9TiW4s4mjpmwpjG4SvaWqwsr0rTe48hjYksKmMwUn9GWWeYRjERPJUvgQ20EVTLysumFK6sOjvEt7-AlesfFVqDeCRFjjpN6-_cbDwyGHGZ-PgAxaWrgy4_dbgDFXiz98GSEb0BBhtdqcWMFpI1qkocucVqWrOwsQdKfwX6_zh_QV1joZDfefFJqKafULTlgJ8bpx7AczZOkheoMZFwMaCXRrCd2jX5SFiv2fkgf5fBq3h71pWKaQsFF_oKHxqzx-NBGidZH22_qSYf5LkbpJdGLJRUNGWURU02GZmSK_HqqPlLhRxNS_pQTHMe2qM-7pSzvMadnDRZafQ" target="_blank" rel="noopener">Why The Future Of Software And Apps Is Serverless</a></li><li><a href="https://www.thoughtworks.com/radar/techniques/serverless-architecture" target="_blank" rel="noopener">ThoughtWorks Serverless architecture</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近看了很多Serverless的文章，关于发展历史看了很多版本，其实对于2010年后的时间点各种国内外说法基本一致，但是在2010年之前就有多种不同的描述方式了，本文结合各种资料对Serverless发展的历史进行一下整理。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>AWS Serverless现状与发展趋势</title>
    <link href="http://sunqi.site/2021/02/20/AWS-Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/"/>
    <id>http://sunqi.site/2021/02/20/AWS-Serverless%E7%8E%B0%E7%8A%B6%E4%B8%8E%E5%8F%91%E5%B1%95%E8%B6%8B%E5%8A%BF/</id>
    <published>2021-02-20T23:30:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>Serverless架构是最近一直非常关注的技术方向，基础架构在应用构建中的地位被被进一步弱化的趋势不可逆转。Serveless让开发者更加关注业务本身逻辑的特性决定了技术演进的趋势。</p><p>目前，很多人可能很难认可这样的观点，大部分人还是认为Kubernetes能够带来更多的灵活性。但是Kubernetes对于应用开发者来说，仍然要顾及底层架构。Serverless的终极目标就是彻底打消这层的关系。但不可否认的一点，Kubernetes、OpenStack等基础平台作为Serverless的底层支撑一定会长期存在，所以二者之间并非竞争关系，而是发展的阶段的不同。从另外一个角度看，在公有云最佳实践中，函数计算已经成为构建应用必不可少的一环。</p><a id="more"></a><p>我大概在2018年左右接触了AWS Lambda服务，后续一直在关注着Serverless趋势，所以本文就结合我的一点粗浅理解来分析一下AWS、阿里云和腾讯云在Serverless架构发展的趋势（分为三篇）。本文中的观点是我自身使用公有云相关服务的经验，难免存在片面性，如有不妥之处，请各位给予批评和指正。</p><p>这里先借用一张InfoQ在《Serverless国内发展纵向观察》的一张图，前面的文章中我也讲到这个问题，对于云来说，Serverless架构很重要的两个部分就是函数即服务（Function-as-a-Service）和后端即服务（Backend-as-a-Service）两部分，这两种服务类型有都属于云原生的范畴。</p><p><img src="/images/pasted-162.png" alt="upload successful"></p><p>由上图可知，FaaS和BaaS是成就Serverless的关键服务能力。函数计算的执行是通过各个云原生服务触发的（触发器执行），所以作为Serverless架构中的业务逻辑实现层，函数计算及其相关服务的发展策略基本代表了一家云商对于Serverless架构的态度。每个云其实都会有自己对Serverless的独特理解，有共性也有差别，同时又都有自身对于Serverless未来场景的理解。</p><h1 id="AWS-Serverless现状"><a href="#AWS-Serverless现状" class="headerlink" title="AWS Serverless现状"></a>AWS Serverless现状</h1><p>我在上一篇关于《Serverless发展历史》的中提到，2014年AWS发布函数计算服务Lambda，开启了新Serverless的篇章，自此以后各大公有云纷纷推出自己的函数计算服务。截止目前为止，AWS仍然是公有云领域的引领者，也是为数不多盈利的公有云公司，其发展方向一直是其他友商追逐的目标。</p><p>从局部角度看，函数计算服务在整个云计算架构中像一个粘合剂，巧妙的串联了各个云原生服务，让“不可变”的云原生服务具备了“可变性”，巧妙的解决了云原生服务之间最后一公里的问题。目前，这种使用方式几乎涵盖了AWS所有的最佳实践。</p><h1 id="AWS-Serverless架构"><a href="#AWS-Serverless架构" class="headerlink" title="AWS Serverless架构"></a>AWS Serverless架构</h1><p>根据AWS的定义，将Serverless架构定义为三层服务类别：计算、应用集成和数据存储。</p><h2 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h2><p>计算层主要包括Lambda和Fargate服务。Lambda是函数计算服务，Fargate是AWS的容器编排引擎，Fargate服务包含两种不同不同的方式：一种是自有的引擎(ECS服务)，另外一种是基于Kubernetes底座的。相较于AWS EC2服务，容器编排层好像并不是AWS关注的重点，这一点从容器服务与其他服务联动性能够隐约感觉出来。但是，AWS Lambda服务绝对足够强大。</p><p><img src="/images/pasted-173.png" alt="upload successful"></p><h2 id="应用集成"><a href="#应用集成" class="headerlink" title="应用集成"></a>应用集成</h2><p>应用集成类主要包含了用于串联函数计算的相关服务。SQS/SNS/API都是非常常用的触发器；AppSync提供了GraphQL的接口，能够从函数计算获取数据；EventBridge提供了事件驱动的架构，扩展了函数计算的事件触发类别，同时也可以进行自定义。</p><p><img src="/images/pasted-177.png" alt="upload successful"></p><p>Step Functions通过状态机的定义，很好的让多个函数计算有序运行，降低Serverless架构控制难度。</p><p><img src="/images/pasted-178.png" alt="upload successful"></p><h2 id="数据存储"><a href="#数据存储" class="headerlink" title="数据存储"></a>数据存储</h2><p>在任何应用场景下，数据都是用户最宝贵的资源，特别是在当今社会下，数据被供奉在一个前所未有的高度。在与Lambda配合使用的持久化存储方面，除了常规的对象存储和非关系型数据库，还支持了RDS Proxy和Aurora Serverless。</p><p><img src="/images/pasted-179.png" alt="upload successful"></p><p>RDS Proxy主要解决并发访问RDS数据库连接数量的限制，由于函数计算随时启停的特点，无法像我们在开发传统应用时使用统一的数据库连接资源池来控制数据库的访问连接数。当并发量非常大时，会超过最大连接数导致失败的情况，所以RDS Proxy就是专门用于解决这一问题的服务。</p><p><img src="/images/pasted-182.png" alt="upload successful"></p><h1 id="函数服务Lambda"><a href="#函数服务Lambda" class="headerlink" title="函数服务Lambda"></a>函数服务Lambda</h1><h2 id="开发语言支持"><a href="#开发语言支持" class="headerlink" title="开发语言支持"></a>开发语言支持</h2><p>目前函数计算服务几乎覆盖了主流的高级开发语言，如果你的语言比较特殊，还可以基于容器自定义，提供了最大灵活度，这也是大部分厂商通用的做法。</p><p><img src="/images/pasted-181.png" alt="upload successful"></p><h2 id="触发器"><a href="#触发器" class="headerlink" title="触发器"></a>触发器</h2><p>我们重点来看看Lmabda服务，函数计算是由事件触发的，以目前的认知，AWS Lambda与国内的公有云相比，是触发器最多的云平台(Google和AZure我没有对比过)。能够触发Lambda的，除了传统的数据库、消息队列、对象存储等，还包括了物联网设备，包括loT和Alexa音箱。</p><p><img src="/images/pasted-174.png" alt="upload successful"></p><p>除了云原生服务外，还通过EventBridge支持第三方服务直接触发Lambda，为应用开发提供了极大的便利性。</p><p><img src="/images/pasted-175.png" alt="upload successful"></p><h2 id="目标配置"><a href="#目标配置" class="headerlink" title="目标配置"></a>目标配置</h2><p>另外值得称道的是Lambda除了提供了丰富的触发器资源，在函数执行结束后也提供了异常处理能力以及后续触发调用能力，让基于Lambda开发的应用更加健壮，也更加简单。</p><p><img src="/images/pasted-176.png" alt="upload successful"></p><p>AWS还支持流式调用的映射，方便更实时的利用Lambda处理数据。</p><p><img src="/images/pasted-180.png" alt="upload successful"></p><h2 id="开发与调试"><a href="#开发与调试" class="headerlink" title="开发与调试"></a>开发与调试</h2><p>我在使用函数过程中，最大的感触就是函数计算的开发和调试是比较麻烦的，因为牵扯到各种云服务，所以在本地调试的时候会有很多限制，在线上调试又担心出现问题。AWS除了提供在线的编辑器外，CLI工具包括了AWS CLI和AWS SAM(AWS Serverless Application Model)。如果是开发函数计算，还是推荐SAM，毕竟是面向函数计算开发设计的。</p><h2 id="日志、监控与权限控制"><a href="#日志、监控与权限控制" class="headerlink" title="日志、监控与权限控制"></a>日志、监控与权限控制</h2><p>在实际使用过程中，函数计算追踪往往是初学者遇到的最大的挑战。其实用了这么久的云，在云原生服务关联性方面你是能真真切切感受到AWS的设计感的。函数计算也不例外，与IAM、日志以及CloudWatch监控服务都有比较良好的互动性，包括上面提到的CLI工具，底层也是调用了CloudFormation编排的能力实现的。所以Lambda的整个开发者生态还是非常完善和友好的。</p><h1 id="发展趋势"><a href="#发展趋势" class="headerlink" title="发展趋势"></a>发展趋势</h1><p>AWS Lambda是函数计算的里程碑，也是目前为止生态最为完整的函数计算服务。由于Lambda与其他AWS服务的良好的互动性，所以往往在整个Serverless架构中，Lambda作为连接云原生服务之间的能力体现的更加淋漓尽致一些。特别是在一些最佳实践中，通过Lambda的合理利用，往往可以降低在云架构设计和开发的成本。从另外一个层面上讲，对Lambda的特性使用的越多，对AWS依赖就会越强，对用户形成一定的锁定性。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Serverless架构是最近一直非常关注的技术方向，基础架构在应用构建中的地位被被进一步弱化的趋势不可逆转。Serveless让开发者更加关注业务本身逻辑的特性决定了技术演进的趋势。&lt;/p&gt;
&lt;p&gt;目前，很多人可能很难认可这样的观点，大部分人还是认为Kubernetes能够带来更多的灵活性。但是Kubernetes对于应用开发者来说，仍然要顾及底层架构。Serverless的终极目标就是彻底打消这层的关系。但不可否认的一点，Kubernetes、OpenStack等基础平台作为Serverless的底层支撑一定会长期存在，所以二者之间并非竞争关系，而是发展的阶段的不同。从另外一个角度看，在公有云最佳实践中，函数计算已经成为构建应用必不可少的一环。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>防止你的钱包掉进Serverless使用的坑</title>
    <link href="http://sunqi.site/2021/02/18/%E9%98%B2%E6%AD%A2%E4%BD%A0%E7%9A%84%E9%92%B1%E5%8C%85%E6%8E%89%E8%BF%9BServerless%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9D%91/"/>
    <id>http://sunqi.site/2021/02/18/%E9%98%B2%E6%AD%A2%E4%BD%A0%E7%9A%84%E9%92%B1%E5%8C%85%E6%8E%89%E8%BF%9BServerless%E4%BD%BF%E7%94%A8%E7%9A%84%E5%9D%91/</id>
    <published>2021-02-18T13:51:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>今天读到InfoQ一篇《应用上云2小时烧掉近50万，创始人：差点破产，简直噩梦》讲述了在使用Serverless方式开发时由于程序Bug导致快速的资源消耗，差点破产的经历。特意查询了英文原文，题目叫做《We Burnt $72K testing Firebase - Cloud Run and almost went Bankrupt》。我之前在使用函数计算时也有一次类似经历，所以写出来供大家参考，防止你的钱包掉进Serverless使用的坑。</p><a id="more"></a><h1 id="钱是如何被烧掉的？"><a href="#钱是如何被烧掉的？" class="headerlink" title="钱是如何被烧掉的？"></a>钱是如何被烧掉的？</h1><p>如果要理解原文中为什么出现问题，先要了解一下Google Serverless的产品体系：</p><ul><li>Cloud Functions: 基于事件驱动的函数计算服务</li><li>App Engine: 上一篇讲述Serverless发展过程的时候恰好提到过这个服务，是Google的PaaS平台，开发人员可以直接将代码托管在平台上运行，具有良好的扩展性</li><li>Cloud Run: 无状态的Serverless HTTP容器，口号是 Bringing Serverless to Containers，可以执行任何语言</li><li>Cloud Firestore: 是一种灵活且可扩缩的数据库，适用于在Firebase和Google Cloud Platform上进行移动、Web 和服务器开发。</li></ul><p>从账单里可以看到，用户最消耗资源的费用是来自App Engine对Cloud Firestore读取次数达到惊人的千亿次，按照原文里的说法，这里仅仅是两个个小时的成绩。在惊叹费用的同时，我们不得不感叹云原生服务性能之优异。</p><p><img src="/images/pasted-171.png" alt="upload successful"></p><p>作者针对这一事件前后共发布了三篇博客，第一篇主要还原事情的脉络，以及在使用Google服务时候的坑；第二篇在剖析自身的错误；最后一篇在作者感叹了一下自己的经历被翻译成各种语言，另外写了另外一篇《How to user Cloud without losing Sleep》防止大家踩坑。</p><p>通篇看下来，作者将问题归咎于几个地方：</p><ul><li>核心问题：代码中包含Bug(Deploying flawed algorithm on Cloud)，不恰当的使用递归而形成死循环(Exponential Recursion without Break: The instances wouldn’t know when to break, as there was no break statement.)</li><li>测试环境中，Cloud Run默认并发实例时1000，测试环境中也使用了默认值，如果在测试环境选择并发数是2，那么费用将从72,000美金降到144美金</li><li>在没有完全掌握Firebase时探索性的使用，没想到Firebase性能这么强大（广告嫌疑）</li><li>基于云开发仍然要抱有对技术的敬畏心，云原生服务降低了运维和开发的难度，但是在使用方式、价格、配置等诸多因素的复杂度必然会与传统有很大的区别，正所谓软件工程领域没有银弹</li></ul><h1 id="我在函数计算上踩过的坑"><a href="#我在函数计算上踩过的坑" class="headerlink" title="我在函数计算上踩过的坑"></a>我在函数计算上踩过的坑</h1><p>之前在测试阿里云函数计算过程时，曾经也有过一次入坑经历。当时我写了一个简单的函数，当有.png文件上传至OSS后，就自动进行Resize操作，保存成三种规格16x16, 32x32, 64x64，之后重新传回到OSS。但是我忽略了一点，我将处理好的文件重新传输回了同一个OSS Bucket内，结果造成了一个死循环。</p><p><img src="/images/pasted-172.png" alt="upload successful"></p><p>其实我所犯的错误和上面公司遇到的问题是一样的，不过好在我的这次错误没有导致很严重的后果。由于时间久远，我无法找到当时的截图。我只记得我的函数计算在短时间内调用了70万次，OSS上传了几百万个小文件。还好阿里云100万次内的访问是免费的，OSS价格比较便宜，但是还是惊出了一身冷汗。赶紧把我的函数服务下线，同时写了一个脚本删除小文件，因为没有直接的命令可以删除非空的Bucket，整个善后清理工作持续了几个小时。</p><h1 id="如何防止踩坑"><a href="#如何防止踩坑" class="headerlink" title="如何防止踩坑"></a>如何防止踩坑</h1><p>作为新的技术趋势，在前进的过程中难免遇到各种各样的问题。目前确实还没有一套指导规范帮助研发人员有效的避免踩坑。所以也需要大家在实践中不断总结。</p><ul><li>做技术的人还是要有一颗敬畏的心，任何新技术的引进都会带来风险，所以在你没有十足的把握的时候，还是小心的比较好</li><li>云的并发性能真的太强大了，所以一定要做好发生异常时的应对方案，让并发性在你的可控范围内进行，控制”爆炸半径“</li><li>Serverless的开发模式对研发流程是一个全新的挑战，在上述案例中问题出现在了测试阶段，不同于传统的测试，Serverless与开发更为紧密，对于白盒测试的要求更高，一方面需要做好单元测试，另外一方面对开发者综合考虑问题的素质要求更高，或许DevTest会成为Serverless在落地实践中需要解决的问题之一</li><li>动手与阅读文档并行，云服务的文档就和普通商品的说明书一样，没人会去主动阅读的，只有实在搞不出来的时候才会想着看一看，但是云服务不同于普通的产品，一些细枝末节的选项太多，还是应当在使用一段时间后回过头来通读文档的内容，加深理解</li></ul><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://blog.tomilkieway.com/72k-1/" target="_blank" rel="noopener">https://blog.tomilkieway.com/72k-1/</a></li><li><a href="https://blog.tomilkieway.com/72k-2/" target="_blank" rel="noopener">https://blog.tomilkieway.com/72k-2/</a></li><li><a href="https://sudcha.com/guide-to-cloud/" target="_blank" rel="noopener">https://sudcha.com/guide-to-cloud/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天读到InfoQ一篇《应用上云2小时烧掉近50万，创始人：差点破产，简直噩梦》讲述了在使用Serverless方式开发时由于程序Bug导致快速的资源消耗，差点破产的经历。特意查询了英文原文，题目叫做《We Burnt $72K testing Firebase - Cloud Run and almost went Bankrupt》。我之前在使用函数计算时也有一次类似经历，所以写出来供大家参考，防止你的钱包掉进Serverless使用的坑。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSQL无法启动“global/pg_control”：Permission denied</title>
    <link href="http://sunqi.site/2021/02/11/PostgreSQL%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E2%80%9Cglobal-pg-control%E2%80%9D%EF%BC%9APermission-denied/"/>
    <id>http://sunqi.site/2021/02/11/PostgreSQL%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E2%80%9Cglobal-pg-control%E2%80%9D%EF%BC%9APermission-denied/</id>
    <published>2021-02-11T00:44:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>昨天在为用户进行迁移后，用户Windows 2012系统上PostgreSQL服务无法启动，日志中提示“global/pg_control”：Permission denied，于是上网一顿搜索终于解决了这个问题。</p><a id="more"></a><h1 id="检查"><a href="#检查" class="headerlink" title="检查"></a>检查</h1><p>如果端口没有被占用，那么你可以用PostgreSQL原生的命令启动它。进入postgresql安装路径下的 bin 文件夹，在这里打开命令行，执行下面的命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\pg_ctl start -D ..\data</span><br></pre></td></tr></table></figure><p>如果程序报出如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR: could not open control file “global&#x2F;pg_control”: Permission denied</span><br></pre></td></tr></table></figure><p><img src="/images/pasted-159.png" alt="upload successful"></p><p>则说明当前操作系统用户丢失了data文件夹及其内容的权限。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><ol><li>首先，进入postgresql 的安装路径，右键data文件夹，依次点击属性——安全——编辑，你能看到所有用户或用户组的权限。</li></ol><p><img src="/images/pasted-160.png" alt="upload successful"></p><ol start="2"><li>确保System 和 Administrator 拥有“完全控制”权限。Users 用户组默认只拥有“读取和执行”，“列出文件夹内容”和“读取”3种权限。当启动数据库提示“权限不足”时，应再添加“修改”和 “写入”。我这次出现问题就在这里，User没有修改和写入权限，添加后即可启动成功。</li></ol><p><img src="/images/pasted-161.png" alt="upload successful"></p><ol start="3"><li>保存并尝试再次在bin 文件夹下执行：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.\pg_ctl start -D ..\data</span><br></pre></td></tr></table></figure><p>观察PostgreSQL数据库能否启动。</p><h1 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h1><ul><li><a href="https://blog.csdn.net/international24/article/details/89710703" target="_blank" rel="noopener">https://blog.csdn.net/international24/article/details/89710703</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;昨天在为用户进行迁移后，用户Windows 2012系统上PostgreSQL服务无法启动，日志中提示“global/pg_control”：Permission denied，于是上网一顿搜索终于解决了这个问题。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="数据库" scheme="http://sunqi.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>传统应用架构与Serverless架构总体拥有成本(TCO)分析与比较</title>
    <link href="http://sunqi.site/2021/02/10/%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B8%8EServerless%E6%9E%B6%E6%9E%84%E6%80%BB%E4%BD%93%E6%8B%A5%E6%9C%89%E6%88%90%E6%9C%AC-TCO-%E5%88%86%E6%9E%90%E4%B8%8E%E6%AF%94%E8%BE%83/"/>
    <id>http://sunqi.site/2021/02/10/%E4%BC%A0%E7%BB%9F%E5%BA%94%E7%94%A8%E6%9E%B6%E6%9E%84%E4%B8%8EServerless%E6%9E%B6%E6%9E%84%E6%80%BB%E4%BD%93%E6%8B%A5%E6%9C%89%E6%88%90%E6%9C%AC-TCO-%E5%88%86%E6%9E%90%E4%B8%8E%E6%AF%94%E8%BE%83/</id>
    <published>2021-02-10T13:55:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>这篇报告是2019年9月德勤基于AWS Serverless发布的一篇白皮书，原文叫《Determining the Total<br>Cost of Ownership of Serverless Technologies when compared to Traditional Cloud》。本文就基于这篇文章提供的方法论，来分析一下Serverless模式的开发总成本。顺便比较一下国内各个云在Serverless架构下的成本。我们重点比较国内排名前三的云平台：阿里云、腾讯云和华为云。</p><p>在原文中包含两个案例，我们重点结合第一个案例云主机与Serverless的比较进行详细分析。</p><a id="more"></a><h1 id="如何对Serverless模式成本进行估算"><a href="#如何对Serverless模式成本进行估算" class="headerlink" title="如何对Serverless模式成本进行估算"></a>如何对Serverless模式成本进行估算</h1><p>Serverless模式是一种真正的将云平台的计算、存储和网络按需付费的云计算理想模式。之前的文章中我也提到过，Serverless最大的优势就是降低了基础架构层的可见性，即“零运维”。开发人员可以更关注业务逻辑的开发，而将繁重的运维工作交由云商负责。Serverless为应用带来了良好的可扩展性、敏捷性和弹性，缩短应用上线时间，提高发布频率，加速公司收入增长。</p><p>但是由于使用情况的不确定性，往往很难精准的估算Serverless的成本。在本文中对于Serverless TCO评估框架包含三个关键成本：基础设施、开发和维护。</p><h1 id="案例简述"><a href="#案例简述" class="headerlink" title="案例简述"></a>案例简述</h1><p>这是一家交通运输公司的需求，用户平均在途中的时间要花费两个多小时。交通公司提供了一个应用（可能是手机APP）包含以下功能：在线订票、连接WIFI、还可以实时监控自己行程。每年有数百万乘客、数百个目的地以及数千条线路，这些相乘之后需要一个并发量巨大的系统进行支撑。运输公司应对这种情况需要花费非常昂贵的成本，而且很难预测。这样也影响了与决策相关的数据得不到及时更新，造成机会成本的丧失。所以为了解决这个问题，这家公司在评估将订票系统运行在函数计算服务上还是EC2实例上。根据测算，这套系统需要满足每天150万笔交易。</p><h1 id="基础设施成本"><a href="#基础设施成本" class="headerlink" title="基础设施成本"></a>基础设施成本</h1><p>资源部分应该是最透明也是最容易比较的部分，只要根据应用运行的情况评估价格即可。</p><h2 id="传统方式"><a href="#传统方式" class="headerlink" title="传统方式"></a>传统方式</h2><p>这是原文中给出的系统资源消耗情况，因为没有更细节化的信息，所以只能根据价格进行反推。</p><table><thead><tr><th align="left">云资源名称</th><th>规格</th><th align="center">数量</th></tr></thead><tbody><tr><td align="left">云主机</td><td>m5.large(2vCPU/8G/200G)</td><td align="center">3个</td></tr><tr><td align="left">数据库</td><td>r5.large(2vCPU/16G/500G)</td><td align="center">3个</td></tr><tr><td align="left">云硬盘</td><td>500 IOPS SSD</td><td align="center">1GB</td></tr><tr><td align="left">负载均衡</td><td></td><td align="center">30 GB/小时</td></tr></tbody></table><p>原文案例中并没有改变给出具体的应用架构和构建细节，所以我们无法从技术层面深究架构合理性，所以只能更关注成本因素。</p><h2 id="Serverless模式"><a href="#Serverless模式" class="headerlink" title="Serverless模式"></a>Serverless模式</h2><p>Serverless是按照资源使用时间计费的，所以这里要根据使用时间计算价格。</p><table><thead><tr><th align="left">功能模块</th><th>规格</th><th align="center">执行时间</th><th>每月平均请求次数</th></tr></thead><tbody><tr><td align="left">售票响应函数</td><td>512 MB内存</td><td align="center">3000 ms</td><td>32,400,000</td></tr><tr><td align="left">数据处理</td><td>512 MB内存</td><td align="center">3000 ms</td><td>10,800,000</td></tr></tbody></table><h2 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h2><p>这是原文给出的资源消耗情况比对，但是有一些非常明显的错误，总计部分很明显的对不上。从原文中的描述可以得知这些信息：Webservers三台节点对应了下面处理票务的函数；而数据库加上存储对应了数据处理函数。这里我非常疑惑的一点：就算你把逻辑写在了函数计算里，你最终处理完的数据还是需要用持久化存储呀？所以我认为这个案例在描述上存在很大的纰漏，对于Serverless至少还应该包含一个数据库服务用于存储最终处理的数据。不过这里我们不纠结与这个问题，只从案例的成本分析进行对比。</p><p><img src="/images/pasted-155.png" alt="upload successful"></p><p>出乎意料的是，在这个请求量级上，使用函数计算服务在这个场景下反而要高于应用系统建立在云主机上。函数计算两个非常重要的计量指标：运行时间和请求次数，这两个指标决定了你的账单。</p><p>相同的情况也发生在Kubernetes服务中，我们之前在构建SaaS时，重点评估了阿里云Kubernetes托管版本(用两台云主机作为Worker, Master托管)和Serverless版本(Master和Worker节点均不见，底层直接使用阿里云ECI容器服务)，原本以为Serverless版本要比托管版本便宜，但是由于我们的程序多以Daemon方式运行，轮询任务很多，导致资源使用时间较长，最终的结果是Serverless版本的价格远远高于托管版本的价格。所以在应用Serverless架构时，要从这种架构的特点进行设计，降低上线后的成本。</p><h1 id="开发成本"><a href="#开发成本" class="headerlink" title="开发成本"></a>开发成本</h1><p>开发成本是评估Serverless架构总体成本第二个重要因素，如果使用传统方式开发，当客户量激增后，基础架构瓶颈的问题。当出现问题再去调整架构进行开发，会无形中错失很多机会成本，引起客户不满。如果在前期过度进行开发设计或者投入大量基础架构设施，又会导致前期成本的浪费。所以对于这种场景，Serverless灵活的扩展性就更加适合业务发展的需要，更好的满足客户的需求，同时又避免了资源的浪费。</p><p><img src="/images/pasted-156.png" alt="upload successful"></p><p>虽然云主机在一定程度上降低了传统运维成本，但是相较于Serverless架构，仍然需要去维护网络、安全、负载均衡、自动伸缩策略等。而使用Serverless架构时，由于采用的事件驱动，所以研发人员无须在前期设计阶段将过多精力研究系统健壮性，可以马上进入研发阶段。</p><p><img src="/images/pasted-157.png" alt="upload successful"></p><p>另外一部分成本来自于持久化集成，在传统方式下，DevOps流程往往需要经历多个阶段，从编译到制品库，从打包到上线中间过程相对较长。由于函数计算的特点，可以更快速的发布上线。测试人员也可以根据函数计算针对性的设计测试方法，合理的控制产品出现Bug的“爆炸半径”。</p><h1 id="运维成本"><a href="#运维成本" class="headerlink" title="运维成本"></a>运维成本</h1><p>运维上主要关注以下几个方面：扩展性、安全、补丁、监控验证测试等内容。每一个应用受到应用的范围和组织的影响，在运维成本上不同。但是，根据平均情况，使用传统云主机，运维人员每个月需要花费8-10小时在于加强安全性，额外每月需要40个小时用于监控、日志分析、验证和测试工作。而使用Serverless架构，运维的工作量进一步下降，真正可以做到开发运维一体化的效果，让Developer做Operation成为可能。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>在达到一定请求数量级时，Serverless架构在基础架构上要高于传统自建方式，但是在开发和维护成本上，Serverless要大幅度优于传统架构。在本案例中，整体成本预估节约40%的TCO。要从架构设计上对函数计算的特点有充分的认知，根据函数计算特点进行设计，才能最大化利用函数计算实现降本增效的结果。</p><p><img src="/images/pasted-158.png" alt="upload successful"></p><p>Serverless非常适合建设业务需求变化较快的业务场景，并且由于拥有一定数量免费额度，当请求量在每月百万级别时，使用Serverless的成本会更低甚至免费。</p><h1 id="参考：国内云平台资源比较"><a href="#参考：国内云平台资源比较" class="headerlink" title="参考：国内云平台资源比较"></a>参考：国内云平台资源比较</h1><p>这里所列的费用，均未包含流量费用。我们可以看到国内三大主流公有云的定价是出奇的一致，但从目录价格角度来说，三朵云基本是一样的。</p><table><thead><tr><th align="left">功能模块</th><th>阿里云</th><th>腾讯云</th><th>华为云</th></tr></thead><tbody><tr><td align="left">售票响应函数</td><td>5372.2964元</td><td>5395.818元</td><td>5396元</td></tr><tr><td align="left">数据处理</td><td>1760.3876元</td><td>1768.098元</td><td>1768元</td></tr></tbody></table><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul><li>阿里云函数价格计算器：<a href="http://tools.functioncompute.com/?spm=5176.8663048.0.0.42f33edcdlsZnq#/price" target="_blank" rel="noopener">http://tools.functioncompute.com/?spm=5176.8663048.0.0.42f33edcdlsZnq#/price</a></li><li>腾讯云函数价格计算器：<a href="https://buy.cloud.tencent.com/price/scf/calculator?rid=8&amp;invokeCountUnit=1&amp;invokeDurationUnit=1&amp;publicNetOutTrafficUnit=1&amp;timestamp=0" target="_blank" rel="noopener">https://buy.cloud.tencent.com/price/scf/calculator?rid=8&amp;invokeCountUnit=1&amp;invokeDurationUnit=1&amp;publicNetOutTrafficUnit=1&amp;timestamp=0</a></li><li>华为云函数工作流（无计算功能）：<a href="https://www.huaweicloud.com/pricing.html?tab=detail#/function" target="_blank" rel="noopener">https://www.huaweicloud.com/pricing.html?tab=detail#/function</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这篇报告是2019年9月德勤基于AWS Serverless发布的一篇白皮书，原文叫《Determining the Total&lt;br&gt;Cost of Ownership of Serverless Technologies when compared to Traditional Cloud》。本文就基于这篇文章提供的方法论，来分析一下Serverless模式的开发总成本。顺便比较一下国内各个云在Serverless架构下的成本。我们重点比较国内排名前三的云平台：阿里云、腾讯云和华为云。&lt;/p&gt;
&lt;p&gt;在原文中包含两个案例，我们重点结合第一个案例云主机与Serverless的比较进行详细分析。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>利用阿里云VPN服务实现HyperMotion SaaS私有云迁移</title>
    <link href="http://sunqi.site/2021/02/10/%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91VPN%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0HyperMotion-SaaS%E7%A7%81%E6%9C%89%E4%BA%91%E8%BF%81%E7%A7%BB/"/>
    <id>http://sunqi.site/2021/02/10/%E5%88%A9%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91VPN%E6%9C%8D%E5%8A%A1%E5%AE%9E%E7%8E%B0HyperMotion-SaaS%E7%A7%81%E6%9C%89%E4%BA%91%E8%BF%81%E7%A7%BB/</id>
    <published>2021-02-10T02:35:16.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>目前云原生迁移平台HyperMotion SaaS主要应用场景在公有云上，但是在我们平时的测试场景中，由于上行带宽的限制，每次向公有云同步比较消耗时间，特别是在验证启动流程时，需要等待半天到一天的时间进行数据同步，非常不划算。在我们内部环境中，我们经常测试的一种场景是从VMWare迁移到私有化部署的OpenStack上。但是由于网络的限制不可能将OpenStack及Floating IP资源在公网上一一映射（如果是客户场景，通常是私有化部署的HyperMotion解决）。那么，是否可以将线上VPC与本地的机房网络环境利用VPN隧道打通，实现利用HyperMotion SaaS进行私有云环境的迁移呢？本文就为你分享利用阿里云VPN服务实现上述场景的需求。</p><a id="more"></a><h1 id="需求与场景分析"><a href="#需求与场景分析" class="headerlink" title="需求与场景分析"></a>需求与场景分析</h1><p>HyperMotion SaaS是部署在阿里云Kubernetes托管版集群中，即Kubernetes Master节点由阿里云负责，阿里云为我们在指定VPC内启动了两台ECS实例作为Worker节点。在我们自身需求中，需要解决两个流量问题：</p><ul><li>控制流：HyperMotion SaaS每个租户可以添加指定的目标云平台，HyperMotion SaaS后台模块通过VPC关联的NAT网关访问云平台API接口及资源，但是如果添加的是我们内部的OpenStack，则需要SaaS侧与OpenStack控制网络想通；另外HyperMotion会自动利用云平台的云主机资源安装云存储网关，所以也需要访问OpenStack Floating IP的地址（具体看云平台规划，也许是Fixed IP）。</li><li>数据流：在数据层面上，我们仍然希望数据层面通过内网传输，没有必要将数据流入公网，好在HyperMotion SaaS的设计满足了这样的需求</li></ul><p><img src="/images/pasted-133.png" alt="upload successful"></p><p>所以在这个解决方案中，重点是利用阿里云VPN网关和本地打通后（前提是公司出口路由有固定的公网IP），通过合理的设置路由规则实现我们上述的需求。</p><p>注意：文章中使用的截图并非全部都是真实截图，所以在实际配置过程中要根据实际情况进行。</p><h1 id="配置流程"><a href="#配置流程" class="headerlink" title="配置流程"></a>配置流程</h1><p>配置过程中主要涉及阿里云VPN服务和H3C路由器，基本流程如下：</p><ul><li>1、阿里云建立VPN网关，这个最低购买力度是包月</li><li>2、拿到阿里云VPN网关后，在路由器上进行相关配置</li><li>3、回到阿里云配置用户网关及IPsec连接，查看连接是否成功</li><li>4、阿里云侧路由设置</li></ul><h1 id="1、阿里云VPN网关配置"><a href="#1、阿里云VPN网关配置" class="headerlink" title="1、阿里云VPN网关配置"></a>1、阿里云VPN网关配置</h1><p>VPN需要关联到VPC和交换机上，根据带宽的不同，价格也不同，最低是按照包1个月5 Mbps。</p><p><img src="/images/pasted-147.png" alt="upload successful"></p><p>配置好后，会得到一个公网IP，这个公网IP需要在后续配置到路由器上。</p><p><img src="/images/pasted-134.png" alt="upload successful"></p><h1 id="2、H3C路由器设置"><a href="#2、H3C路由器设置" class="headerlink" title="2、H3C路由器设置"></a>2、H3C路由器设置</h1><p>目前我们机房使用的路由器属于非常入门级的企业级路由器（H3C ER3200G2），但是基本能满足我们的需求了，并且支持IPsec VPN方式。之前一直很惧怕配置IPsec VPN，相较于L2TP等简单方案，配置起来太复杂了。但是经过几次折腾，也基本摸清楚是怎么回事了，真是应了那句话：人类的恐惧来自于无知。</p><p>我并不是网络方面的专家，也对IPsec原理没什么研究，我只想记录一下我是怎么配置的。我认为IPsec在配置的时候，最重要的一点是两头配置一样，无法连接往往是由于配置信息不一致导致的。这是一张原理图，加深我们对配置过程的理解。</p><p><img src="/images/pasted-143.png" alt="upload successful"></p><p>H3C配置的基本流程为：虚接口-&gt;IKE安全提议-&gt;IKE对等体-&gt;IPsec安全提议-&gt;IPsec安全策略。</p><h2 id="2-1、虚接口配置"><a href="#2-1、虚接口配置" class="headerlink" title="2.1、虚接口配置"></a>2.1、虚接口配置</h2><p>虚接口应该是定义与外界互连的通道，配置很简单，只要指明对外服务的接口（比如：WAN1）就可以了。</p><p><img src="/images/pasted-134.png" alt="upload successful"></p><h2 id="2-2、IKE安全提议"><a href="#2-2、IKE安全提议" class="headerlink" title="2.2、IKE安全提议"></a>2.2、IKE安全提议</h2><p>IKE是因特网密钥交换的缩写(Internet Key Exchange)，从名字上可以猜出这与互联网进行交换数据时加密有关。验证算法和加密算法一定要与对端配置一致，关于DH组，每一个平台选项不一样，比如截图中叫DH2 modp1024，到了阿里云就叫做group2了，所以也必须要配置一致。</p><p><img src="/images/pasted-139.png" alt="upload successful"></p><p>阿里云侧DH组选项</p><p><img src="/images/pasted-140.png" alt="upload successful"></p><h2 id="2-3、IKE对等体"><a href="#2-3、IKE对等体" class="headerlink" title="2.3、IKE对等体"></a>2.3、IKE对等体</h2><p>和对端的VPN网关进行连接，对端IP是需要首先在对端建立VPN网关后，会得到相应的地址，填入即可。</p><p><img src="/images/pasted-141.png" alt="upload successful"></p><p>协商模式上，阿里云的配置是英文的，主模式叫做main，而野蛮模式被称为aggresive。</p><p><img src="/images/pasted-142.png" alt="upload successful"></p><p>共享密钥是自定义的，两端必须一致，DPD阿里云默认是开启的，而H3C上是关闭的，保持统一即可。</p><h2 id="2-4、IPsec安全提议"><a href="#2-4、IPsec安全提议" class="headerlink" title="2.4、IPsec安全提议"></a>2.4、IPsec安全提议</h2><p>按照我粗浅的认知，IKE主要负责两端连接，同时简化了IPsec交互，而真正的数据交互还是要在IPsec上进行控制。所以要对IPsec也要进行相应的安全配置。安全协议类型，我们选择了默认的ESP，阿里云侧默认也应该采用的是此协议。在配置对端时，仍然是保持一致即可。</p><p><img src="/images/pasted-144.png" alt="upload successful"></p><h2 id="2-5、IPsec安全策略"><a href="#2-5、IPsec安全策略" class="headerlink" title="2.5、IPsec安全策略"></a>2.5、IPsec安全策略</h2><p>这一步最关键的是本地子网IP和对端子网IP及掩码的设置，双方是相反的，如果本地是192.168.0.0/24，源端是172.16.0.0/24。则在阿里云侧的配置就是本地是172.16.0.0/24，远端是192.168.0.0/24。</p><p><img src="/images/pasted-145.png" alt="upload successful"></p><p>还有一个就是PFS的设置，和IKE的DH组是一样的，在阿里云侧也被称为IPsec的DH组。也必须设置一致。</p><p><img src="/images/pasted-146.png" alt="upload successful"></p><h1 id="3、阿里云IPsec连接配置"><a href="#3、阿里云IPsec连接配置" class="headerlink" title="3、阿里云IPsec连接配置"></a>3、阿里云IPsec连接配置</h1><h2 id="3-1、用户网关设置"><a href="#3-1、用户网关设置" class="headerlink" title="3.1、用户网关设置"></a>3.1、用户网关设置</h2><p>用户网关设置比较简单，只要在阿里云测配置你路由的公网IP即可。</p><p><img src="/images/pasted-149.png" alt="upload successful"></p><h2 id="3-2、IPsec连接"><a href="#3-2、IPsec连接" class="headerlink" title="3.2、IPsec连接"></a>3.2、IPsec连接</h2><p>这是最关键的一步，经常在这一步配置失败，提示在第一阶段或者第二阶段失败，目前在我遇到的情况中，基本都是上述配置不一致导致的。配置过程基本分为三个阶段，基本配置、高级配置中的IKE配置和IPsec配置。</p><h3 id="3-2-1-基本配置"><a href="#3-2-1-基本配置" class="headerlink" title="3.2.1 基本配置"></a>3.2.1 基本配置</h3><p>注意图中标出的本端网络、对端网络和预共享密钥的配置，一定要填对。</p><p><img src="/images/pasted-150.png" alt="upload successful"></p><h3 id="3-2-2-IKE配置"><a href="#3-2-2-IKE配置" class="headerlink" title="3.2.2 IKE配置"></a>3.2.2 IKE配置</h3><p>点开下方的高级设置，能够看到IKE和IPsec设置。</p><p>配置只要按照我们在H3C的配置选择相应的内容即可，LocalId和RemoteId都是自动根据VPN填写的，并不需要输入。</p><p><img src="/images/pasted-151.png" alt="upload successful"></p><h3 id="3-2-3-IPsec配置"><a href="#3-2-3-IPsec配置" class="headerlink" title="3.2.3 IPsec配置"></a>3.2.3 IPsec配置</h3><p>图中标注的选项一定要保持一致，提交配置后，等待连接。</p><p><img src="/images/pasted-152.png" alt="upload successful"></p><h2 id="3-3、查看连接状态"><a href="#3-3、查看连接状态" class="headerlink" title="3.3、查看连接状态"></a>3.3、查看连接状态</h2><p>如果连接状态为第二阶段协商成功，就证明VPN已经建立成功，否则请检查配置，多半是由于配置不一致导致的。</p><p><img src="/images/pasted-153.png" alt="upload successful"></p><h1 id="4、设置路由"><a href="#4、设置路由" class="headerlink" title="4、设置路由"></a>4、设置路由</h1><p>我们次此设置路由的目的是为了阿里云侧能够访问我们内网，所以接下来需要在阿里云VPC内设置路由表，当访问我们的内网时，需要使用VPN网关。进入VPC服务的路由表配置中，找到VPC。将目标IP段吓一跳设置为VPN网关。因为阿里云的ACL还处于内测阶段，所以暂时无须考虑ACL的设定。</p><p><img src="/images/pasted-154.png" alt="upload successful"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>网络对于未来混合云的场景有至关重要的作用，本文重点描述的是以VPN方式来打通云上和云下环境，但是VPN最大的带宽规格只有200 Mbps，如果真实的需求更大，则需要考虑云联网，通过运营商底层基础设施，实现不同云之间的互联互通。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;目前云原生迁移平台HyperMotion SaaS主要应用场景在公有云上，但是在我们平时的测试场景中，由于上行带宽的限制，每次向公有云同步比较消耗时间，特别是在验证启动流程时，需要等待半天到一天的时间进行数据同步，非常不划算。在我们内部环境中，我们经常测试的一种场景是从VMWare迁移到私有化部署的OpenStack上。但是由于网络的限制不可能将OpenStack及Floating IP资源在公网上一一映射（如果是客户场景，通常是私有化部署的HyperMotion解决）。那么，是否可以将线上VPC与本地的机房网络环境利用VPN隧道打通，实现利用HyperMotion SaaS进行私有云环境的迁移呢？本文就为你分享利用阿里云VPN服务实现上述场景的需求。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>基于Serverless架构进行应用开发</title>
    <link href="http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/"/>
    <id>http://sunqi.site/2021/02/06/%E5%9F%BA%E4%BA%8EServerless-Framework%E8%BF%9B%E8%A1%8C%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/</id>
    <published>2021-02-06T01:01:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是Serverless"><a href="#什么是Serverless" class="headerlink" title="什么是Serverless"></a>什么是Serverless</h1><p>从过去20年IT基础架构层的发展过程来看，计算、存储和网络三种基础资源得到了不断的发展和抽象。从物理机到虚拟化，从虚拟化到云计算，再从云计算到云原生，孕育出诸多新生概念，无论如何变化，一定是向着有利于业务创新方向发展，开发人员越来越不需要关注底层的基础架构。</p><p>云原生本身是一个非常广义的概念，主要包含：微服务架构，应用容器化、Serverless化以及敏捷的软件交付流程。所以很多人在谈论云原生时与Kubernetes划等号，是非常片面的。</p><a id="more"></a><p>今天我们重点来说说Serverless，这种技术的本质并不是真的“无服务器”，真正的目的是要帮助应用开发者摆脱应用程序后端所需的服务器资源的管理和运维工作。我们在设计一款产品或应用时，往往要从不同的唯独考虑产品。<br>从开发与测试角度更多的考虑的是开发语言、框架的选择、数据库、如何进行压力测试等；而从实施和运维角度考虑则要考虑环境怎么构建、高可靠如何实现，如何升级、如何扩容等诸多基础架构的问题。从Serverless架构看，更希望你专注于你的开发和测试，而将实施和运维彻底交给云来解决，前提是你需要遵循Serverless架构。</p><p>在构建Serverless架构中，通常包含两种常用的服务类型：</p><p>1、后端即服务（Backend-as-a-Servce，BaaS），例如：数据库、消息队列、身份验证由云商直接以服务方式提供的服务<br>2、函数计算（Function-as-a-Service），主要将业务逻辑代码运行在其中，函数计算通常运行在容器环境内，按照CPU和内存的运行时间来计费。函数计算触发往往与时间相关，例如：定时器、HTTP请求。目前各家云商云商都提供了函数计算服务，而这方面的佼佼者无疑是2014年11月就推出的AWS Lambda服务，在很多AWS的最佳实践中都能看到巧妙利用函数计算服务来解决业务架构问题。</p><p>我们在开发一个业务系统时，通常采用传统的架构思想来规划系统建设。但是随着云原生技术的发展，除了逐步打破传统的运维与开发之间的关系，我们的开发架构也随之发生了改变。未来的应用开发架构，让开发、测试与运维的边界越来越模糊，应用开发的迭代速度进一步提升。</p><p>当然Serverless并不是万能的，很多劣势无法满足所有的场景需求，但是随着新技术的不断迭代，一定会有新的技术出现来填补这些空白。</p><h1 id="从业务视角看Serverless"><a href="#从业务视角看Serverless" class="headerlink" title="从业务视角看Serverless"></a>从业务视角看Serverless</h1><p>记得是在2020年12月的微信小程序峰会上一个分享中看到这一组数据，给我的震撼很大。这是一家专门依托于微信小程序从事线上娱乐化社交电商社区。我们从图中数据可以看到1-10月份销售数据为23,909,022.69元，销售在14万笔。</p><p><img src="/images/pasted-136.png" alt="upload successful"></p><p>那么如果是一个传统电商平台，承载这样的销量需要付出多少资源的代价呢？我们来看看这家公司的运营数据。是的，你没看错仅仅是3000元，而研发人力投入仅仅不到10个人。</p><p><img src="/images/pasted-137.png" alt="upload successful"></p><p>2020年双十一销量数据为2,194,203元，而基础架构层为此付出的额外费用仅为10元钱。</p><p><img src="/images/pasted-138.png" alt="upload successful"></p><p>从交易数据看，虽然从并发性上远不及天猫这样每秒几十万的交易量。但是如果从性价比(销量/基础架构投入)看，这样的数据绝对是可以各位同行参考的。为什么可以得到这样惊人的数据，这离不开以Serverless为理念的云开发。</p><h1 id="从开发者视角看Serverless"><a href="#从开发者视角看Serverless" class="headerlink" title="从开发者视角看Serverless"></a>从开发者视角看Serverless</h1><p>这是一张云开发自身发展的版图，这张图还是与厂商利益之间进行了深度绑定，不过我们重点从技术角度去分析一下。Serverless架构的发展主要集中在平台能力和基础能力两个方面，当然扩展能力也很重要，我们也可以将这些归属为平台能力层，并且可以是多云。这些插件能够给我们应用提供更多的想象空间，例如最近大火的Clubhouse，就是利用了中国声网提供的服务。</p><p><img src="/images/pasted-135.png" alt="upload successful"></p><p>去年的时候我曾经专门录制过阿里云的函数计算课程( <a href="https://edu.51cto.com/course/22144.html" target="_blank" rel="noopener">https://edu.51cto.com/course/22144.html</a> )，在这个课程里，我更多的是将函数计算作为串联云原生服务的纽带进行讲解。但是随着Servless开发框架越来越成熟，函数计算在构建应用的地位发生了变化，上述提到的云开发就是一个典型。通过微信这个入口，快速支撑了业务发展的需要，在2020年初紧急的开发的健康码就是利用了这样的特性实现。</p><p>我们设计一款全新的应用架构时，要从云开发能够提供的整体能力角度出发进行思考。简单说，Serverless框架的核心在于围绕着函数计算来设计业务逻辑，通过使用各个云原生服务的能力，满足业务上的需求。Serverless架构的设计更多的是在改变原有的开发框架和开发模式，将原有以架构为核心的代码组织形式打散在各个函数中。将原有架构层需要考虑的并发、高可用等完全交由底层来支撑，开发可以更专注于业务本身。</p><p>那么构建以函数计算为核心的Serverless框架应用时，应当注意哪些问题呢？</p><p>1、函数计算需要事件驱动，例如一个HTTP请求，或者一个上传对象存储的行为都会产生事件，而这些事件产生都是云原生的，也是最及时的。以最常见的WEB类应用为例，基本就是前端及后端对数据库各种CURD的组合实现。前端的静态文件可以考虑使用对象存储，再使用CDN进行加速，通过API网关来驱动后端的函数计算，如果有需要持久化存储的数据可以选择NAS或对象存储服务。通过这套架构可以很轻松的实现一个高并发的业务系统。<br>2、虽然Serverless架构看上去很美好，但是仍然会面临很多挑战。性能问题就是其中之一，因为函数计算是触发式启动，在初始阶段和并发激增的情况下响应请求时会很慢。所以在实际开发过程中，除了要合理优化自己的初始化代码逻辑外，还要结合性能监控指标，合理利用预留实例的功能，达到性能与价格的最优。</p><p><img src="/images/pasted-132.png" alt="upload successful"></p><p>3、那么用户现有的业务是否有必要改造为Serverless架构呢？我觉得应该取决于需求，因为Serverless的开发模式决定了这个改造一定会产生时间和人力投入的成本。首先研发人员要学习Serverless的理念，熟悉开发模式，梳理出当前系统改造的方式，甚至要重构部分代码。这个过程往往要高于容器改造的成本，但是小于微服务改造的成本。</p><p>4、研发管理问题也是在应用Serverless应用中需要考虑的问题，从代码结构如何组织，到如何进行上线前的测试，再到如何优化原有持久化集成的流程，都对研发管理提出了挑战。</p><h1 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h1><p>Serverless架构为应用开发带来了新的活力，让研发人员能够更加的专注于业务逻辑的开发工作。同时，让企业的总体拥有成本（TCO）降低，但是提供服务的能力和灵活度大幅度提升。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是Serverless&quot;&gt;&lt;a href=&quot;#什么是Serverless&quot; class=&quot;headerlink&quot; title=&quot;什么是Serverless&quot;&gt;&lt;/a&gt;什么是Serverless&lt;/h1&gt;&lt;p&gt;从过去20年IT基础架构层的发展过程来看，计算、存储和网络三种基础资源得到了不断的发展和抽象。从物理机到虚拟化，从虚拟化到云计算，再从云计算到云原生，孕育出诸多新生概念，无论如何变化，一定是向着有利于业务创新方向发展，开发人员越来越不需要关注底层的基础架构。&lt;/p&gt;
&lt;p&gt;云原生本身是一个非常广义的概念，主要包含：微服务架构，应用容器化、Serverless化以及敏捷的软件交付流程。所以很多人在谈论云原生时与Kubernetes划等号，是非常片面的。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>某股权交易中心业务迁移阿里云最佳实践</title>
    <link href="http://sunqi.site/2021/02/05/%E6%9F%90%E8%82%A1%E6%9D%83%E4%BA%A4%E6%98%93%E4%B8%AD%E5%BF%83%E4%B8%9A%E5%8A%A1%E8%BF%81%E7%A7%BB%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/"/>
    <id>http://sunqi.site/2021/02/05/%E6%9F%90%E8%82%A1%E6%9D%83%E4%BA%A4%E6%98%93%E4%B8%AD%E5%BF%83%E4%B8%9A%E5%8A%A1%E8%BF%81%E7%A7%BB%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/</id>
    <published>2021-02-05T09:35:56.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<h1 id="项目概述"><a href="#项目概述" class="headerlink" title="项目概述"></a>项目概述</h1><p>某股权交易中心是在深圳地区建设的市场化运作的区域性交易市场。由于业务发展需要，用户需要将主要业务全面上云。最终用户选择使用万博智云HyperMotion将业务系统迁移至阿里公有云平台，在保障用户业务连续性的前提下，实现业务系统全面上云。</p><h1 id="客户面临的挑战"><a href="#客户面临的挑战" class="headerlink" title="客户面临的挑战"></a>客户面临的挑战</h1><p>用户原有业务系统运行在运营商机房内，该机房将整体清退，主要应用系统已切换至备用机房。但备用机房规模较小、总体运维成本较高。由于公司发展需要，运维团队规模由原来的十人缩减为一人。为满足业务快速发展以及系统业务连续性要求，提升整体运维效率，计划将主要生产系统由本地机房迁移至阿里云。</p><p>用户采用传统的VMware与存储阵列的经典组合，业务系统由100多台虚拟机、10+TB数据量构成，用户需要将这100多台VMware虚拟机平滑的迁移至阿里云平台。</p><a id="more"></a><h1 id="为什么选择阿里云"><a href="#为什么选择阿里云" class="headerlink" title="为什么选择阿里云"></a>为什么选择阿里云</h1><p>用户希望将业务系统部署在领先的、高水准的云平台上，并且一定要求云平台为国产化自主可控的公有云平台。实现“一步到位”的信息化建设高起点，同时作为金融交易平台，用户需要得到全方位的技术保障和极为可靠的安全性和稳定性。</p><p>本次在竞标主要竞争是在阿里云和另外一家云商之间展开，由于是金融级别客户，用户重点从【安全产品】和【业务迁移】两个维度对两朵公有云产品及服务能力进行了深度评估。</p><p>经过深度评估，选定阿里云安骑士的高配版本和万博智云HyperMotion云迁移为解决方案。</p><h1 id="为什么选择万博智云"><a href="#为什么选择万博智云" class="headerlink" title="为什么选择万博智云"></a>为什么选择万博智云</h1><p>万博智云是国内最早且目前最优的云原生迁移工具研发的公司，通过与阿里云API接口及云原生资源高度自动化对接，将迁移缩减为简单的三步，满足用户高度自动化、智能化迁移需求。</p><p>同时通过迁移演练能力，满足了用户在切换至云端前从业务维度对系统进行多次生产演练验证的需求，实现了【灾备演练式的渐进迁移体验】。</p><p>通过HyperMotion云迁移工具，实现了：</p><ul><li>业务连续性迁移</li><li>批量/高效/全程可视化迁移</li><li>迁移后IP地址不变</li><li>上云前多次业务级别演练</li></ul><p>充分保障了用户业务上云后的连续性和可靠性。</p><h1 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h1><h2 id="网络解决方案"><a href="#网络解决方案" class="headerlink" title="网络解决方案"></a>网络解决方案</h2><p>用户业务上云后，期望保持与原有数据中心内业务系统IP地址保持一致，这就要求在公有云侧VPC需要使用与原有数据中心相同的IP地址规划。同时在上云后，由于云上的地址通常采用DHCP方式进行分配，这就要求在主机启动前就要将端口及IP进行分配，确保在云端启动的主机获得与原有业务系统完全一样的IP地址。</p><p>在该项目中，我们采用【阿里云云联网服务】将用户原有机房网络与云上VPC进行打通，为了避免地址冲突，用户进行数据同步的网络采用单独的地址段，在启动时，通过【HyperMotion指定IP地址】方式进行启动。</p><h2 id="业务连续性"><a href="#业务连续性" class="headerlink" title="业务连续性"></a>业务连续性</h2><p>根据迁移方法论中提到“6R”理论，【重新托管（Re-Host）】方式是上云的最短最高效路径，同时也是对用户原有业务影响最小的方案。</p><p>HyperMotion采用了块级别同步复制技术来实现“热迁移”：</p><ul><li>★源端无代理模式→在源端VMware环境下无入侵操作（不安装agent），对用户业务侧影响几乎为0，实现用户源端业务零停机或者少停机下实现业务系统上云的效果。</li><li>块级别数据的整体复制→用户的操作系统、应用、数据一起被同步到目标侧，无论是WEB应用、数据库或者中间件，都可以通过这种方式完整的迁移至云端，无需针对单独文件或者数据进行操作和配置。</li><li>★异构平台适配技术→通过异构平台智能适配转换驱动，实现跨平台无缝迁移</li><li>★云原生能力→调度云侧API以及逻辑流程，无须繁琐的人为操作，实现高度自动化的用户体验。</li><li>★灾备演练式渐进迁移</li><li>业务系统上云验证是迁移上云前最后一道防线，在云侧完整的对业务系统进行验证是最准确和有效的手段。在传统容灾场景中，通常以定期的灾备演练方式来保证灾备的可用性。</li></ul><p>在HyperMotion中创新的提供了【★迁移演练的能力】，方便用户在上云前通过灾备演练式的体验进行业务系统切换前的校验。HyperMotion通过对阿里云API进行深度整合，以全自动化的方式解决了主机启动、驱动修复、网络修复等多种上云后复杂的人为操作。同时HyperMotion还可以通过指定IP地址启动方式，保证业务系统与源端地址一致。迁移验证系统启动后，并不影响源端业务运行，同时增量数据可以继续同步至云侧。</p><p>本案例中充分发挥了该功能的优势，最大程度满足客户严苛的业务迁移需求。</p><h2 id="成本"><a href="#成本" class="headerlink" title="成本"></a>成本</h2><p>成本因素是迁移到公有云必须要考虑的问题之一，从开始的业务系统同步到迁移演练到最终的迁移上云，均涉及到资源的成本支出，如果无法做到合理的使用云原生资源就会造成大量的浪费。</p><p>HyperMotion创新的采用了云同步网关的概念，实现了多对一的方式进行同步。数据同步阶段，只利用较少的计算资源，而将数据存储于云硬盘中，降低成本消耗。真正的业务主机只在验证或最终切换阶段启动，实现成本最优的效果。</p><p>客户实际在迁移过程中耗时大概在两个月时间，期间将一百多台多台主机拉起进行了三次验证，每次在业务部门确认后，清理掉资源。最终在第四次拉起后，将业务负载全部切换至云侧。目前用户业务系统已经稳定超过半年以上时间。</p><p>以下是我们就该项目中实际消耗的资源&amp;成本 与 备选方案测算进行的比对：</p><p>用户【原有系统资源】统计：</p><p><img src="/images/pasted-130.png" alt="upload successful"></p><p>迁移【中间资源成本】对比：</p><p>项目迁移周期耗时两个月，通过对阿里云账单进行分析，统计出在迁移中间资源、成本、时间如下：</p><p><img src="/images/pasted-131.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;项目概述&quot;&gt;&lt;a href=&quot;#项目概述&quot; class=&quot;headerlink&quot; title=&quot;项目概述&quot;&gt;&lt;/a&gt;项目概述&lt;/h1&gt;&lt;p&gt;某股权交易中心是在深圳地区建设的市场化运作的区域性交易市场。由于业务发展需要，用户需要将主要业务全面上云。最终用户选择使用万博智云HyperMotion将业务系统迁移至阿里公有云平台，在保障用户业务连续性的前提下，实现业务系统全面上云。&lt;/p&gt;
&lt;h1 id=&quot;客户面临的挑战&quot;&gt;&lt;a href=&quot;#客户面临的挑战&quot; class=&quot;headerlink&quot; title=&quot;客户面临的挑战&quot;&gt;&lt;/a&gt;客户面临的挑战&lt;/h1&gt;&lt;p&gt;用户原有业务系统运行在运营商机房内，该机房将整体清退，主要应用系统已切换至备用机房。但备用机房规模较小、总体运维成本较高。由于公司发展需要，运维团队规模由原来的十人缩减为一人。为满足业务快速发展以及系统业务连续性要求，提升整体运维效率，计划将主要生产系统由本地机房迁移至阿里云。&lt;/p&gt;
&lt;p&gt;用户采用传统的VMware与存储阵列的经典组合，业务系统由100多台虚拟机、10+TB数据量构成，用户需要将这100多台VMware虚拟机平滑的迁移至阿里云平台。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>利用腾讯云开发免费搭建个人博客</title>
    <link href="http://sunqi.site/2021/02/02/%E5%88%A9%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E5%BC%80%E5%8F%91%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <id>http://sunqi.site/2021/02/02/%E5%88%A9%E7%94%A8%E8%85%BE%E8%AE%AF%E4%BA%91%E5%BC%80%E5%8F%91%E5%85%8D%E8%B4%B9%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</id>
    <published>2021-02-02T23:03:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>之前一直使用Github Pages搭建个人博客，随着Github访问越来越困难，个人博客国内访问速度越来越慢。之前也试过用cloudflare进行加速，但是收效甚微，所以才考虑将项目迁回到国内。一个偶然的机会，腾讯云开发进入我的视野，起因是他们的9.9元计划，不过后来由于我配置错误，这部分资源无法使用。但是经过研究，原来腾讯云开发提供了最基础的免费资源，恰好可以让我们搭建个人的Blog，经过将近一年多的使用过程中，非常好用，所以就记录下来，供大家参考。</p><a id="more"></a><h1 id="什么是腾讯云开发"><a href="#什么是腾讯云开发" class="headerlink" title="什么是腾讯云开发"></a>什么是腾讯云开发</h1><p>腾讯云开发是我一种非常推崇的开发理念，简单来说就是将Serverless进行了进一步封装，为开发者提供了更便捷的开发体验。目前云开发将轻量级业务中常见的数据库、存储（包括文件存储、对象存储）、云函数（计算资源）、基础运维（告警、监控、日志）进行了整合，同时云开发与微信小程序之间有个非常紧密的整合，能够快速帮助微信小程序构建服务端程序，基本可以承载很多基于微信场景的业务开发，比如电商等应用的开发，并且基于这样的基础架构，支撑千万级并发的需要。</p><p><img src="/images/pasted-126.png" alt="upload successful"></p><p>目前腾讯云开发，主要在广州和上海区域提供服务。</p><p><img src="/images/pasted-125.png" alt="upload successful"></p><p>腾讯云开发目前提供用户可以创建一个免费的环境，其中包含了存储、数据库等免费资源，但是相对于博客场景，主要还是静态资源的托管，每个月有1GB的存储空间，和5GB/月的流量，如果资源不够还可以购买额外的资源包。</p><p>更多的免费额度请参考<a href="https://cloud.tencent.com/document/product/876/47816" target="_blank" rel="noopener">https://cloud.tencent.com/document/product/876/47816</a></p><p><img src="/images/pasted-127.png" alt="upload successful"></p><h1 id="构建过程"><a href="#构建过程" class="headerlink" title="构建过程"></a>构建过程</h1><p>先说一下整体的构建思路：</p><ul><li>我们的博客源代码仍然托管在github上，这样不需要破坏现有逻辑</li><li>如果你有自己的域名，最好申请备案，因为云开发在绑定域名的时候必须要求已备案的域名，但是如果你就不想备案，也有一个Work Around方法，就是通过cloudflare进行跳转的方式实现了，后面会简单介绍</li><li>通过Travis CI自动构建，并上传至云开发中，这样就实现我们在提交代码后，自动进行博客发布的效果了</li></ul><h1 id="云开发购买"><a href="#云开发购买" class="headerlink" title="云开发购买"></a>云开发购买</h1><p>云开发购买的过程，这里不再赘述了，只需要在新建时选择免费资源即可。因为我已经购买过资源了，所以提示我再次购买。</p><p><img src="/images/pasted-128.png" alt="upload successful"></p><p>成功构建后，你会得到这样的环境id，这个id作为你后续使用cli命令行更新环境的参数使用。</p><p><img src="/images/pasted-129.png" alt="upload successful"></p><h1 id="Travis-CI配置文件"><a href="#Travis-CI配置文件" class="headerlink" title="Travis CI配置文件"></a>Travis CI配置文件</h1><p>相信很多人都使用Travis CI构建自己的Github Pages，确实非常方便，虽然Github也提供了自己的CI工具，但是我依然保留着使用Travis CI的习惯。我们无须调整之前的Github Pages的配置或者策略，只需要在你的master分支下，增加或者修改你的.travis.yml即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">sudo: false</span><br><span class="line">language: node_js</span><br><span class="line">node_js:</span><br><span class="line">  - 10 # use nodejs v10 LTS</span><br><span class="line">cache: npm</span><br><span class="line">branches:</span><br><span class="line">  only:</span><br><span class="line">    - master # build master branch only</span><br><span class="line">before_install:</span><br><span class="line">  - npm i -g @cloudbase&#x2F;cli</span><br><span class="line">  - git clone --depth&#x3D;1 https:&#x2F;&#x2F;github.com&#x2F;JoeyBling&#x2F;hexo-theme-yilia-plus.git themes&#x2F;yilia-plus</span><br><span class="line">after_success:</span><br><span class="line">  - cloudbase login --apiKeyId $TECENT_AK --apiKey $TECENT_KS</span><br><span class="line">  - cd public &amp;&amp; echo &#39;y&#39; | tcb hosting deploy -e your-env-id</span><br><span class="line">script:</span><br><span class="line">  - hexo generate # generate static files</span><br><span class="line">deploy:</span><br><span class="line">  repo: xiaoquqi&#x2F;xiaoquqi.github.io</span><br><span class="line">  target_branch: master</span><br><span class="line">  provider: pages</span><br><span class="line">  skip-cleanup: true</span><br><span class="line">  github-token: $GH_TOKEN</span><br><span class="line">  keep-history: true</span><br><span class="line">  on:</span><br><span class="line">    branch: master</span><br><span class="line">  local-dir: public</span><br></pre></td></tr></table></figure><p>在新的配置文件中，我保留了之前deploy到Github Pages的逻辑，主要增加的逻辑是在before_install开始前，安装cloudbase的cli。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">before_install:</span><br><span class="line">  - npm i -g @cloudbase&#x2F;cli</span><br></pre></td></tr></table></figure><p>在hexo generate成功后，增加部署的命令，这里需要在Travis CI中配置腾讯云的鉴权环境变量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">after_success:</span><br><span class="line">  - cloudbase login --apiKeyId $TECENT_AK --apiKey $TECENT_KS</span><br><span class="line">  - cd public &amp;&amp; echo &#39;y&#39; | tcb hosting deploy -e your-env-id</span><br></pre></td></tr></table></figure><p>目前cloudbase cli(简写：tcb)，有一个问题，如果超过1000个文件上传会有个提示，导致Travis CI认为没有返回任务失败，但是实际上已经提交上去了，这里已经给腾讯团队提交了一个需求，在cloudbase cli中增加一个force-yes的选项。</p><p>这样我们在提交代码后，就可以实现在腾讯云开发中自动发布我们博客的效果了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前一直使用Github Pages搭建个人博客，随着Github访问越来越困难，个人博客国内访问速度越来越慢。之前也试过用cloudflare进行加速，但是收效甚微，所以才考虑将项目迁回到国内。一个偶然的机会，腾讯云开发进入我的视野，起因是他们的9.9元计划，不过后来由于我配置错误，这部分资源无法使用。但是经过研究，原来腾讯云开发提供了最基础的免费资源，恰好可以让我们搭建个人的Blog，经过将近一年多的使用过程中，非常好用，所以就记录下来，供大家参考。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Serverless" scheme="http://sunqi.site/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7 zshrc快速配置</title>
    <link href="http://sunqi.site/2021/02/02/CentOS7-zshrc%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/"/>
    <id>http://sunqi.site/2021/02/02/CentOS7-zshrc%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/</id>
    <published>2021-02-02T09:15:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>大部分时间里，我还是习惯于ssh到远程的CentOS7服务器上工作，因为Mac配置了漂亮zsh的缘故，所以也想把我的CentOS7切换到zsh模式。这是最终配置好的效果：</p><p><img src="/images/pasted-124.png" alt="upload successful"></p><p>原理部分不再赘述，有兴趣可以参照MacOS的zsh配置篇。</p><p>CentOS7配置zsh与Mac上还是有一定区别的，因为版本要求，zsh需要自己安装编译，字体也需要自己安装，接下来是详细的步骤。</p><a id="more"></a><h1 id="安装zsh"><a href="#安装zsh" class="headerlink" title="安装zsh"></a>安装zsh</h1><p>虽然通过yum方式可以安装zsh，但是无法满足powerlevel10k的要求，所以先使用zsh源码进行编译后安装。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">WORKSPACE&#x3D;$HOME&#x2F;workspace&#x2F;zsh</span><br><span class="line">mkdir -p $WORKSPACE</span><br><span class="line"></span><br><span class="line">cd $WORKSPACE</span><br><span class="line">curl -o zsh.tar.xz https:&#x2F;&#x2F;jaist.dl.sourceforge.net&#x2F;project&#x2F;zsh&#x2F;zsh&#x2F;5.8&#x2F;zsh-5.8.tar.xz</span><br><span class="line">tar -xvf zsh-5.8.tar.xz</span><br><span class="line"></span><br><span class="line">cd zsh</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><p>zsh会安装在用户目录中/usr/local/bin/zsh中，将zsh设置为默认的系统shell，配置成功后，需要关闭Terminal重新登陆。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chsh -s &#x2F;usr&#x2F;local&#x2F;bin&#x2F;zsh</span><br></pre></td></tr></table></figure><h2 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h2><p>接下来的流程与MacOS上安装类似，由于以上各个项目帮我们做了大量的优化，所以让zsh的安装过程变得简单了很多，大体的流程为：</p><ul><li>安装oh-my-zsh，其实就是clone回来</li><li>安装powerlevel10k，其实也是clone回来</li><li>powerlevel10k的基本配置，根据我们喜欢进行定制</li><li>最后是zsh的配置，也就是修改.zshrc文件</li></ul><h1 id="oh-my-zsh安装"><a href="#oh-my-zsh安装" class="headerlink" title="oh-my-zsh安装"></a>oh-my-zsh安装</h1><p>官方的方法是通过curl或wget，执行github上的install.sh文件，但是由于raw.githubusercontent.com已经属于常年被墙的状态，所以并不推荐这种方式，这里采用的方式是将oh-my-zsh下载回来后，再执行install.sh。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export WORKSPACE&#x3D;$HOME&#x2F;workspace&#x2F;zsh</span><br><span class="line">mkdir -p $WORKSPACE</span><br><span class="line"></span><br><span class="line">cd $WORKSPACE</span><br><span class="line">git clone https:&#x2F;&#x2F;e.coding.net&#x2F;xiaoquqi&#x2F;github&#x2F;ohmyzsh.git</span><br></pre></td></tr></table></figure><p>安装脚本在ohmyzsh/tools/install.sh中，这里我们通过环境变量设置本地源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export REMOTE&#x3D;https:&#x2F;&#x2F;e.coding.net&#x2F;xiaoquqi&#x2F;github&#x2F;ohmyzsh.git</span><br><span class="line"></span><br><span class="line">$WORKSPACE&#x2F;ohmyzsh&#x2F;tools&#x2F;install.sh</span><br></pre></td></tr></table></figure><h1 id="powerlevel10k安装"><a href="#powerlevel10k安装" class="headerlink" title="powerlevel10k安装"></a>powerlevel10k安装</h1><p>powerlevel10k已经被gitee缓存了，所以我就没再做单独的缓存源，直接利用官方提供的命令获取。powerlevel10k会被clone到ohmyzsh的custom路径中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --depth&#x3D;1 https:&#x2F;&#x2F;gitee.com&#x2F;romkatv&#x2F;powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME&#x2F;.oh-my-zsh&#x2F;custom&#125;&#x2F;themes&#x2F;powerlevel10k</span><br></pre></td></tr></table></figure><p>替换默认的zsh主题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s&#x2F;^ZSH_THEME&#x3D;.*&#x2F;ZSH_THEME&#x3D;\&quot;powerlevel10k\&#x2F;powerlevel10k\&quot;&#x2F;g&quot; $HOME&#x2F;.zshrc</span><br></pre></td></tr></table></figure><p>在正式启用主题前，还需要对powerlevel下载字体的文件进行优化。由于是从github下载字体，所以powerlevel10k配置一定会失败，必须要进行替换后，才能安装正常。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s#^local -r font_base_url&#x3D;.*#local -r font_base_url&#x3D;&#39;https:&#x2F;&#x2F;xiaoquqi.coding.net&#x2F;p&#x2F;github&#x2F;d&#x2F;powerlevel10k-media&#x2F;git&#x2F;raw&#x2F;master&#39;#g&quot; $HOME&#x2F;.oh-my-zsh&#x2F;custom&#x2F;themes&#x2F;powerlevel10k&#x2F;internal&#x2F;wizard.zsh</span><br></pre></td></tr></table></figure><p>source zshrc会自动触发配置，按照向导和喜欢的样式来就好，这里就不再赘述了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~&#x2F;.zshrc</span><br></pre></td></tr></table></figure><p>如果想重新配置，也可以使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p10k configure</span><br></pre></td></tr></table></figure><h1 id="加载插件"><a href="#加载插件" class="headerlink" title="加载插件"></a>加载插件</h1><p>通过修改.zshrc中的plugins变量可以实现插件加载的效果，比如使用virtualenv插件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plugins&#x3D;(git virtualenv)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大部分时间里，我还是习惯于ssh到远程的CentOS7服务器上工作，因为Mac配置了漂亮zsh的缘故，所以也想把我的CentOS7切换到zsh模式。这是最终配置好的效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-124.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
&lt;p&gt;原理部分不再赘述，有兴趣可以参照MacOS的zsh配置篇。&lt;/p&gt;
&lt;p&gt;CentOS7配置zsh与Mac上还是有一定区别的，因为版本要求，zsh需要自己安装编译，字体也需要自己安装，接下来是详细的步骤。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="常用命令" scheme="http://sunqi.site/tags/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Mac iTerm2 zshrc快速配置</title>
    <link href="http://sunqi.site/2021/02/02/Mac-zshrc%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/"/>
    <id>http://sunqi.site/2021/02/02/Mac-zshrc%E5%BF%AB%E9%80%9F%E9%85%8D%E7%BD%AE/</id>
    <published>2021-02-02T03:26:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>zsh基本上已经成为Mac上的标配了，界面美观还有点缀的小图标，非常漂亮。但是网上配置zsh文章很多，配置方法也是五花八门，并且由于github被墙的原因，经过由于网络问题安装失败。经过反复测试，在国内的代码托管网站进行了Github部分关键项目定时缓存后，提高配置效率。这里写一篇自用的配置方法，留给有需要的人。</p><p>我的环境：iTerm2 + oh-my-zsh + powerlevel10k，这是我的配置效果：</p><p><img src="/images/pasted-123.png" alt="upload successful"></p><a id="more"></a><h1 id="原理解析"><a href="#原理解析" class="headerlink" title="原理解析"></a>原理解析</h1><p>我们开始配置前，还是有必要讲一下这几个项目的关系，以便了解其工作原理。</p><ul><li>iTerm2不用说了，MacOS上必备的Terminal工具，替代原有系统自带的工具。</li><li>ohmyzsh(<a href="https://github.com/ohmyzsh/ohmyzsh/" target="_blank" rel="noopener">https://github.com/ohmyzsh/ohmyzsh/</a>) 是一套基于zsh深度定制的插件及主题管理的框架，方便定制适合你的zsh环境。</li><li>Nerd Fonts(<a href="https://www.nerdfonts.com/" target="_blank" rel="noopener">https://www.nerdfonts.com/</a>) 我们在截图中看到的那些可爱的小图标就是来自这个项目，让我们原本枯燥的Terminal增添了几分乐趣。</li><li>powerlevel10k(<a href="https://github.com/romkatv/powerlevel10k" target="_blank" rel="noopener">https://github.com/romkatv/powerlevel10k</a>) 是一套zsh皮肤，也是目前我个人比较喜欢的一套皮肤，同时提供了较强的配置能力，包括字体下载，iTerm2的配置都自动完成了，所以也是目前使用最顺手的一套皮肤。</li></ul><h2 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h2><p>由于以上各个项目帮我们做了大量的优化，所以让zsh的安装过程变得简单了很多，大体的流程为：</p><ul><li>安装oh-my-zsh，其实就是clone回来</li><li>安装powerlevel10k，其实也是clone回来</li><li>powerlevel10k的基本配置，根据我们喜欢进行定制</li><li>最后是zsh的配置，也就是修改.zshrc文件</li></ul><h1 id="oh-my-zsh安装"><a href="#oh-my-zsh安装" class="headerlink" title="oh-my-zsh安装"></a>oh-my-zsh安装</h1><p>官方的方法是通过curl或wget，执行github上的install.sh文件，但是由于raw.githubusercontent.com已经属于常年被墙的状态，所以并不推荐这种方式，这里采用的方式是将oh-my-zsh下载回来后，再执行install.sh。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export WORKSPACE&#x3D;$HOME&#x2F;workspace&#x2F;zsh</span><br><span class="line">mkdir -p $WORKSPACE</span><br><span class="line"></span><br><span class="line">cd $WORKSPACE</span><br><span class="line">git clone https:&#x2F;&#x2F;e.coding.net&#x2F;xiaoquqi&#x2F;github&#x2F;ohmyzsh.git</span><br></pre></td></tr></table></figure><p>安装脚本在ohmyzsh/tools/install.sh中，这里我们通过环境变量设置本地源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export REMOTE&#x3D;https:&#x2F;&#x2F;e.coding.net&#x2F;xiaoquqi&#x2F;github&#x2F;ohmyzsh.git</span><br><span class="line"></span><br><span class="line">$WORKSPACE&#x2F;ohmyzsh&#x2F;tools&#x2F;install.sh</span><br></pre></td></tr></table></figure><h1 id="powerlevel10k安装"><a href="#powerlevel10k安装" class="headerlink" title="powerlevel10k安装"></a>powerlevel10k安装</h1><p>powerlevel10k已经被gitee缓存了，所以我就没再做单独的缓存源，直接利用官方提供的命令获取。powerlevel10k会被clone到ohmyzsh的custom路径中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone --depth&#x3D;1 https:&#x2F;&#x2F;gitee.com&#x2F;romkatv&#x2F;powerlevel10k.git $&#123;ZSH_CUSTOM:-$HOME&#x2F;.oh-my-zsh&#x2F;custom&#125;&#x2F;themes&#x2F;powerlevel10k</span><br></pre></td></tr></table></figure><p>替换默认的zsh主题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#39;&#39; &quot;s&#x2F;^ZSH_THEME&#x3D;.*&#x2F;ZSH_THEME&#x3D;\&quot;powerlevel10k\&#x2F;powerlevel10k\&quot;&#x2F;g&quot; $HOME&#x2F;.zshrc</span><br></pre></td></tr></table></figure><p>在正式启用主题前，还需要对powerlevel下载字体的文件进行优化。由于是从github下载字体，所以powerlevel10k配置一定会失败，必须要进行替换后，才能安装正常。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i &#39;&#39; &quot;s#^local -r font_base_url&#x3D;.*#local -r font_base_url&#x3D;&#39;https:&#x2F;&#x2F;xiaoquqi.coding.net&#x2F;p&#x2F;github&#x2F;d&#x2F;powerlevel10k-media&#x2F;git&#x2F;raw&#x2F;master&#39;#g&quot; $HOME&#x2F;.oh-my-zsh&#x2F;custom&#x2F;themes&#x2F;powerlevel10k&#x2F;internal&#x2F;wizard.zsh</span><br></pre></td></tr></table></figure><p>source zshrc会自动触发配置，按照向导和喜欢的样式来就好，这里就不再赘述了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source ~&#x2F;.zshrc</span><br></pre></td></tr></table></figure><p>如果想重新配置，也可以使用命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p10k configure</span><br></pre></td></tr></table></figure><h1 id="加载插件"><a href="#加载插件" class="headerlink" title="加载插件"></a>加载插件</h1><p>通过修改.zshrc中的plugins变量可以实现插件加载的效果，比如使用virtualenv插件。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plugins&#x3D;(git virtualenv)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;zsh基本上已经成为Mac上的标配了，界面美观还有点缀的小图标，非常漂亮。但是网上配置zsh文章很多，配置方法也是五花八门，并且由于github被墙的原因，经过由于网络问题安装失败。经过反复测试，在国内的代码托管网站进行了Github部分关键项目定时缓存后，提高配置效率。这里写一篇自用的配置方法，留给有需要的人。&lt;/p&gt;
&lt;p&gt;我的环境：iTerm2 + oh-my-zsh + powerlevel10k，这是我的配置效果：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/pasted-123.png&quot; alt=&quot;upload successful&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="常用命令" scheme="http://sunqi.site/tags/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>如何在微信开发者工具中使用vim编辑模式</title>
    <link href="http://sunqi.site/2021/01/26/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E4%B8%AD%E4%BD%BF%E7%94%A8vim%E7%BC%96%E8%BE%91%E6%A8%A1%E5%BC%8F/"/>
    <id>http://sunqi.site/2021/01/26/%E5%A6%82%E4%BD%95%E5%9C%A8%E5%BE%AE%E4%BF%A1%E5%BC%80%E5%8F%91%E8%80%85%E5%B7%A5%E5%85%B7%E4%B8%AD%E4%BD%BF%E7%94%A8vim%E7%BC%96%E8%BE%91%E6%A8%A1%E5%BC%8F/</id>
    <published>2021-01-26T23:52:10.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>随着云计算技术的发展特别是无服务化的发展，在业务系统的研发上，前端和后端的边界逐步被打破。微信小程序便是这一方面的典型代表，特别是结合了腾讯Serverless云开发的套件后，小程序融会贯通成为业务开发非常重要的载体。今年疫情期间，基于小程序开发的健康码充分发挥了小程序这一方面的特点。小程序上手开发难度不高，基本都是基于Javascript生态构建，对于前端开发或者后端开发来说，无疑都是福音，让大家真正的做一次全栈开发。</p><p>作为一名10多年的开发人员，vim是我最常使用的编辑器，但是在微信开发者工具中并没有直接提供vim的开发模式。经过不断的探索，终于发现微信开发者工具对VS Code插件的兼容模式，于是按照文档将VS Code vim插件安装在微信开发者工具中。果然，我熟悉的vim模式又回来了，这篇文章就为大家简单分享一下。</p><a id="more"></a><h1 id="在VS-Code安装vim插件"><a href="#在VS-Code安装vim插件" class="headerlink" title="在VS Code安装vim插件"></a>在VS Code安装vim插件</h1><p>首先在VS Code中安装vim模拟器，如图所示，我安装的是1.18.5版本。我使用的是mac系统，安装完成后，插件会存放在用户HOME目录下的$HOME/.vscode/extensions/vscodevim.vim-1.18.5中。</p><p><img src="/images/pasted-116.png" alt="upload successful"></p><h1 id="在微信开发者工具安装VS-Code插件"><a href="#在微信开发者工具安装VS-Code插件" class="headerlink" title="在微信开发者工具安装VS Code插件"></a>在微信开发者工具安装VS Code插件</h1><p>1、在微信开发者工具中点击“设置”-&gt;”扩展设置”</p><p><img src="/images/pasted-117.png" alt="upload successful"></p><p>2、在打开的窗口中选择“编辑器自定义扩展”，因为我已经安装过了，所以截图中已经包含了vscode.vim插件</p><p><img src="/images/pasted-118.png" alt="upload successful"></p><p>3、点击上方的“打开扩展文件夹”，此时会打开微信开发者插件目录，而你要做的就是将vscode插件拷贝过去。</p><p><img src="/images/pasted-119.png" alt="upload successful"></p><p>但是由于从Finder中无法直接访问隐藏目录，先在左侧选择HOME目录。</p><p><img src="/images/pasted-121.png" alt="upload successful"></p><p>使用“前往文件夹”选项，填入.vscode/extensions。将.vscode/extensions/vscodevim.vim-1.18.5拷贝之刚才打开的微信开发者工具的扩展目录中。</p><p><img src="/images/pasted-120.png" alt="upload successful"></p><p>4、重启微信开发者工具后，就能在“编辑器自定义扩展”中看到vim插件，启动插件后，再次退出重启，此时编辑器里已经可以使用vim模式了。</p><p><img src="/images/pasted-122.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;随着云计算技术的发展特别是无服务化的发展，在业务系统的研发上，前端和后端的边界逐步被打破。微信小程序便是这一方面的典型代表，特别是结合了腾讯Serverless云开发的套件后，小程序融会贯通成为业务开发非常重要的载体。今年疫情期间，基于小程序开发的健康码充分发挥了小程序这一方面的特点。小程序上手开发难度不高，基本都是基于Javascript生态构建，对于前端开发或者后端开发来说，无疑都是福音，让大家真正的做一次全栈开发。&lt;/p&gt;
&lt;p&gt;作为一名10多年的开发人员，vim是我最常使用的编辑器，但是在微信开发者工具中并没有直接提供vim的开发模式。经过不断的探索，终于发现微信开发者工具对VS Code插件的兼容模式，于是按照文档将VS Code vim插件安装在微信开发者工具中。果然，我熟悉的vim模式又回来了，这篇文章就为大家简单分享一下。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>使用镜像源加速Github Clone速度</title>
    <link href="http://sunqi.site/2021/01/25/%E4%BD%BF%E7%94%A8%E9%95%9C%E5%83%8F%E6%BA%90%E5%8A%A0%E9%80%9FGithub-Clone%E9%80%9F%E5%BA%A6/"/>
    <id>http://sunqi.site/2021/01/25/%E4%BD%BF%E7%94%A8%E9%95%9C%E5%83%8F%E6%BA%90%E5%8A%A0%E9%80%9FGithub-Clone%E9%80%9F%E5%BA%A6/</id>
    <published>2021-01-25T01:11:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>Github被屏蔽已经不是什么太新鲜的事情了，但是对开发人员下载速度确实造成很大的困扰，所以需要使用镜像源来加速下载速度。但是，我在clone的时候又不想每次破坏原有的链接，那有没有什么自动的方法来帮助我们来修改呢？</p><a id="more"></a><h1 id="设定gitconfig自动实现替换"><a href="#设定gitconfig自动实现替换" class="headerlink" title="设定gitconfig自动实现替换"></a>设定gitconfig自动实现替换</h1><p>通过在HOME目录下的.gitconfig文件可以实现自动的对github.com进行替换的目的，具体的方式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global url.&quot;https:&#x2F;&#x2F;gitclone.com&#x2F;&quot;.insteadOf https:&#x2F;&#x2F;github.com</span><br></pre></td></tr></table></figure><p>在$HOME/.gitconfig会发现增加了如下行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[url &quot;https:&#x2F;&#x2F;gitclone.com&#x2F;&quot;]</span><br><span class="line">insteadOf &#x3D; https:&#x2F;&#x2F;github.com</span><br></pre></td></tr></table></figure><h1 id="其他镜像源"><a href="#其他镜像源" class="headerlink" title="其他镜像源"></a>其他镜像源</h1><p>目前国内提供github镜像源还包括以下地址，但是通过网站测速（<a href="https://tool.chinaz.com/sitespeed）来看，目前相对于北京最稳定和快速的是gitclone.com，所以可以根据不同地域灵活进行选择以下地址：" target="_blank" rel="noopener">https://tool.chinaz.com/sitespeed）来看，目前相对于北京最稳定和快速的是gitclone.com，所以可以根据不同地域灵活进行选择以下地址：</a></p><ul><li>fastgit.org: <a href="https://doc.fastgit.org/" target="_blank" rel="noopener">https://doc.fastgit.org/</a></li><li>gitclone.com: <a href="https://gitclone.com/" target="_blank" rel="noopener">https://gitclone.com/</a></li><li>gitee: <a href="https://gitee.com/mirrors" target="_blank" rel="noopener">https://gitee.com/mirrors</a></li><li>cnpmjs.org: <a href="https://github.com.cnpmjs.org/" target="_blank" rel="noopener">https://github.com.cnpmjs.org/</a></li></ul><h1 id="文件下载"><a href="#文件下载" class="headerlink" title="文件下载"></a>文件下载</h1><p>还有一种情况是要从github下载某个文件，由于raw.githubusercontent.com属于长期被屏蔽状态，所以基本通过wget进行下载，比如要下载的文件为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -O https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;xiaoquqi&#x2F;dockprom&#x2F;master&#x2F;docker-compose.vmware.exporters.yml</span><br></pre></td></tr></table></figure><p>可以替换为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;raw.staticdn.net&#x2F;xiaoquqi&#x2F;dockprom&#x2F;master&#x2F;docker-compose.vmware.exporters.yml</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Github被屏蔽已经不是什么太新鲜的事情了，但是对开发人员下载速度确实造成很大的困扰，所以需要使用镜像源来加速下载速度。但是，我在clone的时候又不想每次破坏原有的链接，那有没有什么自动的方法来帮助我们来修改呢？&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="Git" scheme="http://sunqi.site/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>利用Docker快速搭建Prometheus监控及告警平台</title>
    <link href="http://sunqi.site/2020/12/25/%E5%88%A9%E7%94%A8Docker%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAPrometheus%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%91%8A%E8%AD%A6%E5%B9%B3%E5%8F%B0/"/>
    <id>http://sunqi.site/2020/12/25/%E5%88%A9%E7%94%A8Docker%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BAPrometheus%E7%9B%91%E6%8E%A7%E5%8F%8A%E5%91%8A%E8%AD%A6%E5%B9%B3%E5%8F%B0/</id>
    <published>2020-12-25T13:32:48.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>开源项目出现让IT产业得到了蓬勃发展的机会，大批的社区贡献者通过向开源社区贡献代码实现自我价值。企业通过使用开源项目，增加了对核心技术的掌控能力。虽然开源项目从功能性上是基本可用的，但是需要从用户体验、运维层面投入人力，本文目的就是帮助读者利用Docker快速构建一套基于Prometheus的监控及告警平台，能够实现对用户环境基本监控，本文将持续更新，收集好用的exporter及Grafana Dashboard。</p><p>目前本文涉及的监控内容：</p><ul><li>主机监控</li><li>容器监控</li><li>Ceph监控</li><li>VMware监控</li></ul><a id="more"></a><h1 id="项目说明"><a href="#项目说明" class="headerlink" title="项目说明"></a>项目说明</h1><p>我们假设读者已经使用CentOS搭建了容器环境，并配置了国内源的前提下。如果没有设置请参考<a href="http://sunqi.site/2020/07/31/CentOS-7%E5%88%9D%E5%A7%8B%E5%8C%96%E8%84%9A%E6%9C%AC/">《CentOS 7和Docker初始化安装》</a>。</p><p>Prometheus快速构建的docker compose原始项目来自<a href="https://github.com/stefanprodan/dockprom" target="_blank" rel="noopener">stefanprodan/dockprom</a>，但是由于原项目中的cAdvisor使用了Google源，所以Fork的项目修改为国内源<a href="https://github.com/xiaoquqi/dockprom" target="_blank" rel="noopener">xiaoquqi/dockprom</a>。</p><p>原项目中包含的组件：</p><ul><li>Prometheus (metrics database) http://<host-ip>:9090</li><li>Prometheus-Pushgateway (push acceptor for ephemeral and batch jobs) http://<host-ip>:9091</li><li>AlertManager (alerts management) http://<host-ip>:9093</li><li>Grafana (visualize metrics) http://<host-ip>:3000</li><li>Caddy (reverse proxy and basic auth provider for prometheus and alertmanager)</li></ul><p>默认包含的采集器：</p><ul><li>NodeExporter (host metrics collector)</li><li>cAdvisor (containers metrics collector)</li></ul><p>在此基础上增加的内容：</p><ul><li>Ceph exporter</li><li>VMware exporter</li><li>钉钉告警webhook</li><li>轻量级http服务，用于内网分发docker-compse.exporter.yml</li></ul><h1 id="环境快速构建"><a href="#环境快速构建" class="headerlink" title="环境快速构建"></a>环境快速构建</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;xiaoquqi&#x2F;dockprom</span><br><span class="line">cd dockprom</span><br><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure><p>启动完成后，用浏览器访问：</p><ul><li>Prometheus: <a href="http://yourip:9090" target="_blank" rel="noopener">http://yourip:9090</a></li><li>Grafana: <a href="http://yourip:3000" target="_blank" rel="noopener">http://yourip:3000</a></li></ul><p>默认的用户名/密码为: admin/admin，如果需要修改可以在启动之前修改docker-compose.yml文件。</p><p>访问Prometheus，查看metrics是否被正确采集。如果有采集器有红色字样，根据提示查看具体的错误原因，大部分的错误都是因为配置问题，或者网络不通造成的。</p><p><img src="/images/pasted-109.png" alt="upload successful"></p><h1 id="Grafana配置"><a href="#Grafana配置" class="headerlink" title="Grafana配置"></a>Grafana配置</h1><p>访问Grafana的控制面板，其中已经内置了一些模板，也可以选择Import导入Grafana模板库的模板，数据源选择已经配置好的Prometheus即可。</p><p><img src="/images/pasted-110.png" alt="upload successful"></p><h1 id="主机监控"><a href="#主机监控" class="headerlink" title="主机监控"></a>主机监控</h1><p>默认安装情况下，主机层面仅监控了本机，如果需要增加新的监控主机，需要进行以下两步：</p><ul><li>为主机安装node exporter</li><li>修改Prometheus配置文件，并重启服务</li></ul><h2 id="1、安装node-exporter"><a href="#1、安装node-exporter" class="headerlink" title="1、安装node exporter"></a>1、安装node exporter</h2><p>在项目中，内置了一个单独的docker-compose.exporters.yml，如果目标主机安装了容器，可以直接将该yaml文件拷贝至目标节点后，启动监控服务即可。当然也可以通过软件包安装方式，本文不再赘述。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f docker-compose.exporters.yml up -d</span><br></pre></td></tr></table></figure><p>安装完成后，访问metrics接口，即代表安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;localhost:9100&#x2F;metrics</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;14&quot;&#125; 2.8795339e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;15&quot;&#125; 2.3535384e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;16&quot;&#125; 3.4674675e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;17&quot;&#125; 2.5727501e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;18&quot;&#125; 2.5931391e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;19&quot;&#125; 2.67231846e+08</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;2&quot;&#125; 4.3448998e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;20&quot;&#125; 3.0684276e+07</span><br><span class="line">node_softnet_processed_total&#123;cpu&#x3D;&quot;21&quot;&#125; 3.0587632e+07</span><br></pre></td></tr></table></figure><h2 id="2、修改Prometheus配置文件"><a href="#2、修改Prometheus配置文件" class="headerlink" title="2、修改Prometheus配置文件"></a>2、修改Prometheus配置文件</h2><p>回到Prometheus节点，找到dockerprom/prometheus/prometheus.yml进行如下修改，在nodeexporter段的targets增加新的监控节点后重启服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># A scrape configuration containing exactly one endpoint to scrape.</span><br><span class="line">scrape_configs:</span><br><span class="line">  - job_name: &#39;nodeexporter&#39;</span><br><span class="line">    scrape_interval: 5s</span><br><span class="line">    static_configs:</span><br><span class="line">      - targets: [&#39;nodeexporter:9100&#39;, &#39;newip:9100&#39;]</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><h1 id="告警配置"><a href="#告警配置" class="headerlink" title="告警配置"></a>告警配置</h1><p>其实监控并不是最终的目的，往往告警才是监控系统成功与否的关键，在实际运维中对于根因分析和告警收敛是有非常强烈的需求的，本文中暂时还没对此做深入的分析，仅仅提供了常规的告警手段。告警的配置方法有两种方式，一种是通过Prometheus AlertManager，另外一种也可以通过在Grafana上直接进行配置。</p><p>对于告警方式支持多种方式，例如我们常用的邮件或者钉钉等，当然你也可以实现你自己的方式，这里我们使用钉钉的WEBHOOK作为告警方式。</p><h2 id="1-钉钉webhook配置"><a href="#1-钉钉webhook配置" class="headerlink" title="1. 钉钉webhook配置"></a>1. 钉钉webhook配置</h2><p>默认已经启动了钉钉容器，只需要修改dingtalk/config.yaml即可。Targets下面有各种示例，比如配置一个最简单的钉钉告警：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">targets:</span><br><span class="line">  devops:</span><br><span class="line">    url: https:&#x2F;&#x2F;oapi.dingtalk.com&#x2F;robot&#x2F;send?access_token&#x3D;xxxxx</span><br></pre></td></tr></table></figure><p>这里的devops是自定义的，但是和后面要填入alertmanager的链接地址有关，比如本例中alertmanager回调地址就是http://<yourip>:8060/dingtalk/devops/send</p><h2 id="2-修改AlertManager配置"><a href="#2-修改AlertManager配置" class="headerlink" title="2. 修改AlertManager配置"></a>2. 修改AlertManager配置</h2><p>  修改alertmanager/config.yml</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">  route:</span><br><span class="line">    receiver: &#39;dingtalk&#39;</span><br><span class="line"></span><br><span class="line">receivers:</span><br><span class="line">  - name: &#39;dingtalk&#39;</span><br><span class="line">    webhook_configs:</span><br><span class="line">    - send_resolved: true</span><br><span class="line">      url: http:&#x2F;&#x2F;&lt;yourip&gt;:8060&#x2F;dingtalk&#x2F;devops&#x2F;send</span><br></pre></td></tr></table></figure><p>  这里不要用localhost，因为部署在容器内。</p><h2 id="3-修改Prometheus配置文件"><a href="#3-修改Prometheus配置文件" class="headerlink" title="3. 修改Prometheus配置文件"></a>3. 修改Prometheus配置文件</h2><p>  修改alert.rules，尝试修改一些规则测试告警，例如：</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- name: host</span><br><span class="line">rules:</span><br><span class="line">- alert: high_cpu_load</span><br><span class="line">  expr: node_load1 &gt; 0.2</span><br><span class="line">  for: 1s</span><br><span class="line">  labels:</span><br><span class="line">    severity: warning</span><br><span class="line">  annotations:</span><br><span class="line">    summary: &quot;Server under high load&quot;</span><br><span class="line">    description: &quot;Docker host is under high load, the avg load 1m is at &#123;&#123; $value&#125;&#125;. Reported by instance &#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125;.&quot;</span><br></pre></td></tr></table></figure><p>此时可以通过AlertManager查看http://<yourip>:9093/#/alerts，检查是否有告警产生。</p><p><img src="/images/pasted-111.png" alt="upload successful"></p><p>如果告警产生了，但是无法触发钉钉，可以通过检查alertmanager容器进行debug，例如上述提到的localhost问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">level&#x3D;warn ts&#x3D;2020-12-29T07:21:56.345Z caller&#x3D;notify.go:674 component&#x3D;dispatcher receiver&#x3D;dingtalk integration&#x3D;webhook[0] msg&#x3D;&quot;Notify attempt failed, will retry later&quot; attempts&#x3D;1 err&#x3D;&quot;Post \&quot;http:&#x2F;&#x2F;localhost:8060&#x2F;dingtalk&#x2F;devops&#x2F;send\&quot;: dial tcp 127.0.0.1:8060: connect: connection refused&quot;</span><br><span class="line">level&#x3D;error ts&#x3D;2020-12-29T07:26:56.344Z caller&#x3D;dispatch.go:309 component&#x3D;dispatcher msg&#x3D;&quot;Notify for alerts failed&quot; num_alerts&#x3D;1 err&#x3D;&quot;dingtalk&#x2F;webhook[0]: notify retry canceled after 16 attempts: Post \&quot;http:&#x2F;&#x2F;localhost:8060&#x2F;dingtalk&#x2F;devops&#x2F;send\&quot;: dial tcp 127.0.0.1:8060: connect: connection refused&quot;</span><br></pre></td></tr></table></figure><h1 id="Ceph监控"><a href="#Ceph监控" class="headerlink" title="Ceph监控"></a>Ceph监控</h1><p>确保Ceph配置文件已经在/etc/ceph目录下，并且能够正常访问Ceph集群。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f docker-compose.ceph.exporters.yml up -d</span><br></pre></td></tr></table></figure><p>通过访问http://<yourip>:9128/metrics验证是否能够正常获取数据。</p><p>在prometheus/prometheus.yml文件中增加一个新的Job</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  ......</span><br><span class="line">  - job_name: &#39;ceph-exporter&#39;</span><br><span class="line">    scrape_interval: 5s</span><br><span class="line">    honor_labels: true</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#39;192.168.10.201:9128&#39;]</span><br><span class="line">      labels:</span><br><span class="line">        instance: Ceph Cluster</span><br></pre></td></tr></table></figure><p>最后重启prometheus容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><p>在Grafana中导入三个模板：</p><ul><li>Ceph Cluster Overview: <a href="https://grafana.com/dashboards/917" target="_blank" rel="noopener">https://grafana.com/dashboards/917</a></li><li>Ceph Pools Overview: <a href="https://grafana.com/dashboards/926" target="_blank" rel="noopener">https://grafana.com/dashboards/926</a></li><li>Ceph OSD Overview: <a href="https://grafana.com/dashboards/923" target="_blank" rel="noopener">https://grafana.com/dashboards/923</a></li></ul><p>Ceph Cluster效果：</p><p><img src="/images/pasted-113.png" alt="upload successful"></p><p>Ceph Pool效果：</p><p><img src="/images/pasted-114.png" alt="upload successful"></p><p>Ceph OSD效果：</p><p><img src="/images/pasted-115.png" alt="upload successful"></p><h1 id="VMware监控"><a href="#VMware监控" class="headerlink" title="VMware监控"></a>VMware监控</h1><p>首先修改docker-compose.vmware.exporters.yml中vcenter的连接信息：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">services:</span><br><span class="line">  vmware-exporter:</span><br><span class="line">    image: pryorda&#x2F;vmware_exporter:v0.11.1</span><br><span class="line">    container_name: vmware-exporter</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    ports:</span><br><span class="line">       - &#39;9272:9272&#39;</span><br><span class="line">    expose:</span><br><span class="line">       - 9272</span><br><span class="line">    environment:</span><br><span class="line">      VSPHERE_HOST: &quot;VC_HOST&quot;</span><br><span class="line">      VSPHERE_IGNORE_SSL: &quot;True&quot;</span><br><span class="line">      VSPHERE_USER: &quot;VC_USERNAME&quot;</span><br><span class="line">      VSPHERE_PASSWORD: &quot;VC_PASSWORD&quot;</span><br><span class="line">    labels:</span><br><span class="line">      org.label-schema.group: &quot;monitoring&quot;</span><br></pre></td></tr></table></figure><p>启动VMware exporter：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f docker-compose.vmware.exporters.yml up -d</span><br></pre></td></tr></table></figure><p>通过访问http://<yourip>:9272/metrics验证是否能够正常获取数据。</p><p>在prometheus/prometheus.yml文件中增加一个新的Job</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scrape_configs:</span><br><span class="line">  ......</span><br><span class="line">  - job_name: &#39;vmware_vcenter&#39;</span><br><span class="line">    metrics_path: &#39;&#x2F;metrics&#39;</span><br><span class="line">    scrape_timeout: 15s</span><br><span class="line">    static_configs:</span><br><span class="line">    - targets: [&#39;192.168.10.13:9272&#39;]</span><br></pre></td></tr></table></figure><p>最后重启prometheus容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart prometheus</span><br></pre></td></tr></table></figure><p>在Grafana中导入模板：<a href="https://grafana.com/grafana/dashboards/11243" target="_blank" rel="noopener">https://grafana.com/grafana/dashboards/11243</a></p><p>效果如下：</p><p><img src="/images/pasted-112.png" alt="upload successful"></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;开源项目出现让IT产业得到了蓬勃发展的机会，大批的社区贡献者通过向开源社区贡献代码实现自我价值。企业通过使用开源项目，增加了对核心技术的掌控能力。虽然开源项目从功能性上是基本可用的，但是需要从用户体验、运维层面投入人力，本文目的就是帮助读者利用Docker快速构建一套基于Prometheus的监控及告警平台，能够实现对用户环境基本监控，本文将持续更新，收集好用的exporter及Grafana Dashboard。&lt;/p&gt;
&lt;p&gt;目前本文涉及的监控内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主机监控&lt;/li&gt;
&lt;li&gt;容器监控&lt;/li&gt;
&lt;li&gt;Ceph监控&lt;/li&gt;
&lt;li&gt;VMware监控&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>我需要一款什么样的网盘？</title>
    <link href="http://sunqi.site/2020/12/14/%E6%88%91%E9%9C%80%E8%A6%81%E4%B8%80%E6%AC%BE%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E7%BD%91%E7%9B%98%EF%BC%9F/"/>
    <id>http://sunqi.site/2020/12/14/%E6%88%91%E9%9C%80%E8%A6%81%E4%B8%80%E6%AC%BE%E4%BB%80%E4%B9%88%E6%A0%B7%E7%9A%84%E7%BD%91%E7%9B%98%EF%BC%9F/</id>
    <published>2020-12-14T13:56:00.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<p>大概是在8月份的时候，收到阿里要做网盘的消息，那篇文章以“免费”、“不限速”这样的噱头来吸引读者的眼球，直击目前网盘的痛点，当时确实赚足了流量。不过两个月过后，阿里的网盘仍然是犹抱琵琶半遮面的感觉，始终让人看不清楚阿里网盘的端倪。十月底的时候，依靠阿里MVP这一“天时”，搞到了阿里云盘的内测码，并进行了深度体验，所以这篇文章主要是两个目的：第一，是交个作业，毕竟“拿人内测码，与人评测”；第二，网盘我用了不少，也从我的需求角度来讲一下，我对网盘的需求到底是什么，希望能引起读者的一些共鸣。</p><a id="more"></a><h1 id="阿里云盘or网盘——傻傻分不清楚"><a href="#阿里云盘or网盘——傻傻分不清楚" class="headerlink" title="阿里云盘or网盘——傻傻分不清楚"></a>阿里云盘or网盘——傻傻分不清楚</h1><p>我相信很多关注了阿里网盘的朋友都会有一个问题，到底哪个是阿里真的网盘？我们通过公开渠道，至少能找到阿里云有至少三款“云盘”或者“网盘”。</p><p><img src="/images/pasted-97.png" alt="upload successful"></p><p><img src="/images/pasted-98.png" alt="upload successful"></p><p><img src="/images/pasted-99.png" alt="upload successful"></p><p>幸运的一点，我除了通过阿里MVP渠道获取到Teambition开发的网盘，同时还获取了阿里云盘的内测码，所以有机会对这两款都进行了充分体验。</p><h2 id="Teambiton网盘"><a href="#Teambiton网盘" class="headerlink" title="Teambiton网盘"></a>Teambiton网盘</h2><p>2019年初阿里耗资1亿美金收购了团队协作平台Teambition，通过收购及整合兼并，阿里不断扩大自身在To B领域的影响力。在推出网盘前，Teambition已经推出了代码托管平台codeUp和Flow，为企业构建完整的DevOps流程垫定了基础。网盘也是顺应这一趋势，阿里也继续丰富着自己的To B版图。</p><p>不过与我们理解的传统网盘有所区别，目前网盘是紧耦合在原有的Teambition体系内，更像是Teambition的一个扩展功能，而不能独立使用，这一点从网页版和手机侧的设计就能看出来。所以，也许Teambition网盘的目标客户也许并不是传统的网盘用户，更像是解决企业成员间文件存储和分享的问题。</p><p>目前Teambition暂不支持企业网盘，还需要切换至个人账户。但是在我测试过程中，有个小Bug，我明明在登陆后是个人账户，但是仍然看到的是企业网盘暂未开放的提示信息。需要先切换到企业，再切换回个人后才能看到。</p><p><img src="/images/pasted-100.png" alt="upload successful"></p><p>先来看一下整体的界面风格，从内测版本的截图看，Teambition的网盘目前还处于非常简单的状态，界面上展现的功能并不多，我认为类似最早期对象存储的基本功能。</p><p><img src="/images/pasted-101.png" alt="upload successful"></p><p>由于目前还处于内测阶段，所以基本不会对上传和下载速度做任何限制，不知道在商用化之后免费权益到底如何？我家的宽带是联通300Mbps，上传之前对网速进行了基本测试，上传的时候我使用的是浏览器直接上传的方式，我的iMac使用网线和路由器直接进行连接。</p><p><img src="/images/pasted-103.png" alt="upload successful"></p><p>我是晚上做的测试，上传了一个4.66GB的MP4文件，上传速度基本稳定在了400KB/s。</p><p><img src="/images/pasted-104.png" alt="upload successful"></p><p>这个和我最早期的一次测试结果是有出入的，感觉速度没有这么慢，并且中途失败了好几次，于是第二天早晨的时候，在失败后进行了重传。这时候速度基本上能把网络的上行速度跑满。</p><p><img src="/images/pasted-107.png" alt="upload successful"></p><p>另外，对于网盘很重要的分享功能也并未开放，只能作为用户自有的网络存储空间。</p><p><img src="/images/pasted-105.png" alt="upload successful"></p><p>手机侧的功能也基本与网页版本相似，并且必须要借助Teambition APP使用，暂时没有提供任何自动备份的功能。</p><p><img src="/images/pasted-106.png" alt="upload successful"></p><h2 id="阿里云盘"><a href="#阿里云盘" class="headerlink" title="阿里云盘"></a>阿里云盘</h2><p>经过与阿里内部确认，阿里的云盘和Teambition是完全独立的两个团队，也就是这是两端独立的产品，所以这也让我怀疑我当初看到的文章到底是在讲网盘还是云盘的？</p><p>阿里的云盘更接近传统对网盘的认知，这一点从用户体验上就能感觉到。与网盘不同的是，阿里云盘相对来说比较独立，之前只开放了手机版本，目前已经可以从网页上进行登陆了。目前只能通过网页版进行内测资格的申请，而所有操作也只能在手机侧完成。阿里云盘的域名是aliyundrive.com。</p><p>目前的客户端方面只提供了手机侧的，对我来说比较重要的客户端的还没有看到。从上传的感受来说，云盘的稳定性要好于网盘，网速基本上稳定在5MB/s，中间没有出现任何断线情况。</p><p><img src="/images/pasted-108.png" alt="upload successful"></p><h1 id="我需要什么样的网盘产品？"><a href="#我需要什么样的网盘产品？" class="headerlink" title="我需要什么样的网盘产品？"></a>我需要什么样的网盘产品？</h1><p>回答这个问题，先要从我用了哪两款付费网盘产品说起。目前我使用的两款付费网盘的产品，一款是苹果的iCloud，一款是百度的网盘。iCloud的费用一个月是21元/月200GB家庭共享空间，而百度网盘超级会员一个月是18元/月空间，空间达到了5TB，但是无法家庭共享。</p><p>可能有人会问为什么每个月要花将近40元在付费网盘呢？为什么不使用同一种网盘呢？这主要源自我最主要的几个需求：</p><p>一、解决不同设备之间的文件同步问题。我目前使用的手机是iPhone、办公电脑是Mac Pro，而家里使用的是iMac。因为经常要在家里工作，而又懒着背笔记本回家，所以重要文件在不同电脑的传输对我来说就非常重要了。另外，因为有时候需要出去交流，所以会从手机侧查看文件，那么手机与PC之间的文件互通也变得非常重要了。百度网盘之前在Mac侧会有个同步盘的应用，但是后来不再维护了，并且同步盘之前在同步过程中经常发生同步冲突，而莫名其妙产生了多个文件的问题。后来还试过类似OneDrive等网盘，都有类似的问题。最终发现只有苹果自身的方案才能最完美的符合我的要求。<br>二、费用成本问题。虽然苹果的方案很完美，但是也是最贵的，苹果的付费储存空间方案跨度太大，200GB之后就是2TB，价格直接从21元/月涨到了68元/月。因为会拍摄一些视频资料，所以对空间消耗比加大，无奈之下，只得选择了百度网盘作为补充，一方面是之前有很多文件都存在了百度网盘上，另外一方面付费后也不受下载限速的影响了，算是作为一种二级存储的方案使用。近期，准备购置百度的智能音箱，还能直接播放网盘内宝宝的音频。<br>三、照片、视频自动备份功能。虽然iCloud也能对照片、视频进行自动备份，但是有了孩子之后发现照片和视频成倍增加，真是不禁用，这时百度网盘的照片、视频自动备份就派上了用场。</p><p>其实，百度网盘还有一些类似照片整理、搜索等功能也非常强大，但是相比前两点并非刚需，所以只是偶尔会用到。</p><p>虽然这种组合使用方式在一定程度基本满足了我的日常需求，只是要定期的将部分数据导入百度网盘略显繁琐。但是另外一个网盘的需求依然困扰着我，就是对于微信的备份功能。虽然钉钉在这一点上要明显好于微信，但是谁让微信是第一社交软件呢？平时的沟通还是在微信，经常遇到一些文件不随手存下来就被微信清理掉的情况。虽然腾讯也有自己的微盘，但是就是不支持微信的自动备份功能，如果支持我估计我会立马付费购买。</p><p>总结一下我对网盘的几个需求：第一，空间足够大，上传下载不限速；第二、设备之间能够互相同步；第三、微信聊天记录和附件的自动备份功能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大概是在8月份的时候，收到阿里要做网盘的消息，那篇文章以“免费”、“不限速”这样的噱头来吸引读者的眼球，直击目前网盘的痛点，当时确实赚足了流量。不过两个月过后，阿里的网盘仍然是犹抱琵琶半遮面的感觉，始终让人看不清楚阿里网盘的端倪。十月底的时候，依靠阿里MVP这一“天时”，搞到了阿里云盘的内测码，并进行了深度体验，所以这篇文章主要是两个目的：第一，是交个作业，毕竟“拿人内测码，与人评测”；第二，网盘我用了不少，也从我的需求角度来讲一下，我对网盘的需求到底是什么，希望能引起读者的一些共鸣。&lt;/p&gt;
    
    </summary>
    
    
    
      <category term="趋势分析" scheme="http://sunqi.site/tags/%E8%B6%8B%E5%8A%BF%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>Docker构建服务器空间占满问题</title>
    <link href="http://sunqi.site/2020/11/13/Docker%E6%9E%84%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A9%BA%E9%97%B4%E5%8D%A0%E6%BB%A1%E9%97%AE%E9%A2%98/"/>
    <id>http://sunqi.site/2020/11/13/Docker%E6%9E%84%E5%BB%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A9%BA%E9%97%B4%E5%8D%A0%E6%BB%A1%E9%97%AE%E9%A2%98/</id>
    <published>2020-11-13T06:19:41.000Z</published>
    <updated>2021-04-20T02:14:09.996Z</updated>
    
    <content type="html"><![CDATA[<h1 id="现象描述"><a href="#现象描述" class="headerlink" title="现象描述"></a>现象描述</h1><p>今天Jenkins构建突然出现问题，检查Jenkins Job日志发现no space left，于是登录到Jenkins Build服务器上，发现容器所在的/var/lib空间被完全满了。</p><a id="more"></a><p><img src="/images/pasted-94.png" alt="upload successful"></p><h1 id="排查过程"><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h1><h2 id="检查容器空间"><a href="#检查容器空间" class="headerlink" title="检查容器空间"></a>检查容器空间</h2><p>首先从容器层面检查一下空间占用情况：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker system df</span><br></pre></td></tr></table></figure><p>发现有容器的占用空间达到了1个多TB的空间。</p><p><img src="/images/pasted-95.png" alt="upload successful"></p><h2 id="清理无用的容器和镜像"><a href="#清理无用的容器和镜像" class="headerlink" title="清理无用的容器和镜像"></a>清理无用的容器和镜像</h2><p>先用prune进行一下清理，为了保险起见，过滤一下时间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker system prune -a -f --filter &quot;until &#x3D; 1h&quot;</span><br></pre></td></tr></table></figure><p>清理完成后，空间仍然没有释放，于是继续排查。</p><h2 id="检查-var-lib下的空间占用"><a href="#检查-var-lib下的空间占用" class="headerlink" title="检查/var/lib下的空间占用"></a>检查/var/lib下的空间占用</h2><p>通过检查发现/var/lib/docker/overlay2中的66d44a19ee93a191cc0585efac45e10696edfd0381d0dc96d9646080337f629e目录空间占用巨大，进入后发现其中有tmp目录没有及时清理。由于没有Jenkins任务在执行，所以手动清理了/tmp/tmp*的目录，空间被立即释放了。</p><p><img src="/images/pasted-96.png" alt="upload successful"></p><p>那么此时问题清晰了，这一层属于Jenkins，进入容器后发现Jenkins的/tmp目录没有被及时清理，属于Build逻辑有缺陷造成了，及时修复Pipeline的Jenkinsfile后，该问题不再出现。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;现象描述&quot;&gt;&lt;a href=&quot;#现象描述&quot; class=&quot;headerlink&quot; title=&quot;现象描述&quot;&gt;&lt;/a&gt;现象描述&lt;/h1&gt;&lt;p&gt;今天Jenkins构建突然出现问题，检查Jenkins Job日志发现no space left，于是登录到Jenkins Build服务器上，发现容器所在的/var/lib空间被完全满了。&lt;/p&gt;
    
    </summary>
    
    
    
  </entry>
  
</feed>
